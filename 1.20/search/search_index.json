{"config":{"lang":["en"],"separator":"[\\s\\-]+"},"docs":[{"title":"TriggerMesh Concepts","text":"<p>The TriggerMesh Cloud Native Integration Platform allows you to integrate applications by defining sources and targets which are seen as the start and the end of what we call \"Bridges\". While data and events flow through the Bridge, they are defined using an API object and may undergo filtering, splitting, and/or transformations.</p>         TriggerMesh Bridges Concepts    <p>Bridges define how we connect our applications and services, and they may consist of the following concepts:</p> <ul> <li>Sources are the origin of data and events. These may be on-premises or cloud-based. Examples include databases, message queues, logs, and events from applications or services.</li> <li>Targets are the destination for the processed events or data. Examples include databases, message queues, monitoring systems, and cloud services.</li> <li>Filters determine which events to process based on their content. These may be the basis for dropping unwanted events or for creating rules engines for event processing.</li> <li>Splitters breaks events into multiple events which may then be processed individually.</li> <li>Transformations are a set of modifications to incoming events. Examples include annotating incoming events with timestamps, dropping fields, or rearranging data to fit an expected format.</li> <li>Functions implement custom event flow logic and may act as a source, transformation, or target. Functions support Python, NodeJS, and Ruby runtimes.</li> <li>TriggerMesh Integration Language (TIL) is a user-friendly configuration language for writing your Bridges as integrations as code. TIL is based off of the HCL syntax and should be familiar to users of Terraform.</li> <li>Scaling explain how TriggerMesh components scale under load.</li> </ul>","location":"concepts/"},{"title":"TriggerMesh APIs","text":"<p>TriggerMesh is composed of a set of APIs representing:</p> <ul> <li>Event sources</li> <li>Event targets</li> <li>Event Routing components</li> <li>Declarative event Transformation</li> <li>Event processing using Function</li> </ul>","location":"apis/apis/"},{"title":"Repository structure","text":"<p>All APIs are available in the TriggerMesh GitHub repository <code>triggermesh/triggermesh</code> under the <code>pkg/apis</code> directory</p>  <p>Info</p> <p>This documentation is automatically generated using this code which is a slightly modified version of what the Knative project uses.</p>","location":"apis/apis/#repository-structure"},{"title":"Awseventbridge target","text":"<p>Packages:</p> <ul> <li> targets.triggermesh.io/v1alpha1 </li> </ul>","location":"apis/awseventbridge-target/"},{"title":"targets.triggermesh.io/v1alpha1","text":"<p> <p>Package v1alpha1 contains API Schema definitions for the targets/v1alpha1 API group.</p> </p> <p>Resource Types:</p> <ul><li> AWSEventBridgeTarget </li></ul>","location":"apis/awseventbridge-target/#targets.triggermesh.io/v1alpha1"},{"title":"AWSEventBridgeTarget","text":"<p> <p>AWSEventBridgeTarget is the Schema for the event target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AWSEventBridgeTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AWSEventBridgeTargetSpec          <code>accountID</code>  string    <p>ID of the AWS account to send events to.</p>     <code>region</code>  string    <p>Name of the AWS region where the partner event source is located.</p>        <code>status</code>   AWSEventBridgeTargetStatus","location":"apis/awseventbridge-target/#targets.triggermesh.io/v1alpha1.AWSEventBridgeTarget"},{"title":"AWSEventBridgeTargetSpec","text":"<p> (Appears on: AWSEventBridgeTarget) </p> <p> <p>AWSEventBridgeTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>accountID</code>  string    <p>ID of the AWS account to send events to.</p>     <code>region</code>  string    <p>Name of the AWS region where the partner event source is located.</p>","location":"apis/awseventbridge-target/#targets.triggermesh.io/v1alpha1.AWSEventBridgeTargetSpec"},{"title":"AWSEventBridgeTargetStatus","text":"<p> (Appears on: AWSEventBridgeTarget) </p> <p> <p>AWSEventBridgeTargetStatus defines the observed state of the event target.</p> </p>    Field Description      <code>Status</code>  knative.dev/pkg/apis/duck/v1.Status    <p> (Members of <code>Status</code> are embedded into this type.) </p>     <code>AddressStatus</code>  knative.dev/pkg/apis/duck/v1.AddressStatus    <p> (Members of <code>AddressStatus</code> are embedded into this type.) </p>     <code>partnerEventSource</code>   PartnerEventSource     <p>Description of the partner event source associated with the target.</p>","location":"apis/awseventbridge-target/#targets.triggermesh.io/v1alpha1.AWSEventBridgeTargetStatus"},{"title":"PartnerEventSource","text":"<p> (Appears on: AWSEventBridgeTargetStatus) </p> <p> <p>PartnerEventSource contains details about a partner event source.</p> </p>    Field Description      <code>name</code>  string    <p>Name of the partner event source</p>     <code>state</code>  string    <p>State of the partner event source</p>      <p> Generated with <code>gen-crd-api-reference-docs</code> on git commit <code>c4da90f</code>. </p>","location":"apis/awseventbridge-target/#targets.triggermesh.io/v1alpha1.PartnerEventSource"},{"title":"Functions","text":"<p>Package:</p> <ul> <li> extensions.triggermesh.io/v1alpha1 </li> </ul>","location":"apis/extensions/"},{"title":"extensions.triggermesh.io/v1alpha1","text":"<p> <p>Package v1alpha1 contains API Schema definitions for the extensions/v1alpha1 API group.</p> </p> <p>Resource Types:</p> <ul><li> Function </li></ul>","location":"apis/extensions/#extensions.triggermesh.io/v1alpha1"},{"title":"Function","text":"<p> <p>Function is an addressable object that executes function code.</p> </p>    Field Description      <code>apiVersion</code> string  <code> extensions.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>Function</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   FunctionSpec          <code>runtime</code>  string        <code>entrypoint</code>  string        <code>code</code>  string        <code>responseIsEvent</code>  bool        <code>eventStore</code>   EventStoreConnection         <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p> <p>Support sending to an event sink instead of replying, as well as setting the CloudEvents \u2018type\u2019 and \u2018source\u2019 attributes using CloudEventOverrides (hack).</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   FunctionStatus","location":"apis/extensions/#extensions.triggermesh.io/v1alpha1.Function"},{"title":"EventStoreConnection","text":"<p> (Appears on: FunctionSpec) </p> <p> <p>EventStoreConnection contains the data to connect to an EventStore instance</p> </p>    Field Description      <code>uri</code>  string    <p>URI is the gRPC location to the EventStore</p>","location":"apis/extensions/#extensions.triggermesh.io/v1alpha1.EventStoreConnection"},{"title":"FunctionConfigMapIdentity","text":"<p> (Appears on: FunctionStatus) </p> <p> <p>FunctionConfigMapIdentity represents the identity of the ConfigMap containing the code of a Function.</p> </p>    Field Description      <code>name</code>  string        <code>resourceVersion</code>  string","location":"apis/extensions/#extensions.triggermesh.io/v1alpha1.FunctionConfigMapIdentity"},{"title":"FunctionSpec","text":"<p> (Appears on: Function) </p> <p> <p>FunctionSpec holds the desired state of the Function Specification</p> </p>    Field Description      <code>runtime</code>  string        <code>entrypoint</code>  string        <code>code</code>  string        <code>responseIsEvent</code>  bool        <code>eventStore</code>   EventStoreConnection         <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p> <p>Support sending to an event sink instead of replying, as well as setting the CloudEvents \u2018type\u2019 and \u2018source\u2019 attributes using CloudEventOverrides (hack).</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/extensions/#extensions.triggermesh.io/v1alpha1.FunctionSpec"},{"title":"FunctionStatus","text":"<p> (Appears on: Function) </p> <p> <p>FunctionStatus defines the observed state of the Function.</p> </p>    Field Description      <code>Status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status     <p> (Members of <code>Status</code> are embedded into this type.) </p>     <code>configMap</code>   FunctionConfigMapIdentity          <p> Generated with <code>gen-crd-api-reference-docs</code> on git commit <code>b22c2e53</code>. </p>","location":"apis/extensions/#extensions.triggermesh.io/v1alpha1.FunctionStatus"},{"title":"Transformation","text":"<p>Package:</p> <ul> <li> flow.triggermesh.io/v1alpha1 </li> </ul>","location":"apis/flow/"},{"title":"flow.triggermesh.io/v1alpha1","text":"<p> <p>Package v1alpha1 contains API Schema definitions for the flow/v1alpha1 API group.</p> </p> <p>Resource Types:</p> <ul><li> DataWeaveTransformation </li><li> JQTransformation </li><li> Synchronizer </li><li> Transformation </li><li> XMLToJSONTransformation </li><li> XSLTTransformation </li></ul>","location":"apis/flow/#flow.triggermesh.io/v1alpha1"},{"title":"DataWeaveTransformation","text":"<p> <p>DataWeaveTransformation is the Schema for an DataWeave transformation target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> flow.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>DataWeaveTransformation</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   DataWeaveTransformationSpec          <code>dwSpell</code>   ValueFromField     (Optional) <p>DataWeave spell that will be used by default for transformation.</p>     <code>allowPerEventDwSpell</code>  bool    (Optional) <p>Whether the default DwSpell can be overriden at each event</p>     <code>inputContentType</code>  string    (Optional) <p>Content type for the incoming transformation.</p>     <code>outputContentType</code>  string    (Optional) <p>Content type for transformation Output.</p>     <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p> <p>Support sending to an event sink instead of replying.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/flow/#flow.triggermesh.io/v1alpha1.DataWeaveTransformation"},{"title":"JQTransformation","text":"<p> </p>    Field Description      <code>apiVersion</code> string  <code> flow.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>JQTransformation</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     (Optional) Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   JQTransformationSpec          <code>query</code>  string    <p>The query that gets passed to the JQ library</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p> <p>Support sending to an event sink instead of replying.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/flow/#flow.triggermesh.io/v1alpha1.JQTransformation"},{"title":"Synchronizer","text":"<p> <p>Synchronizer is the Schema for the Synchronizer target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> flow.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>Synchronizer</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   SynchronizerSpec          <code>correlationKey</code>   Correlation         <code>response</code>   Response         <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p> <p>Support sending to an event sink instead of replying.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/flow/#flow.triggermesh.io/v1alpha1.Synchronizer"},{"title":"Transformation","text":"<p> <p>Transformation allows to declaratively perform data transformations on CloudEvents.</p> </p>    Field Description      <code>apiVersion</code> string  <code> flow.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>Transformation</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   TransformationSpec          <code>context</code>   []Transform     <p>Context contains Transformations that must be applied on CE Context</p>     <code>data</code>   []Transform     <p>Data contains Transformations that must be applied on CE Data</p>     <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p> <p>Support sending to an event sink instead of replying.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/flow/#flow.triggermesh.io/v1alpha1.Transformation"},{"title":"XMLToJSONTransformation","text":"<p> <p>XMLToJSONTransformation is the schema for the event transformer.</p> </p>    Field Description      <code>apiVersion</code> string  <code> flow.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>XMLToJSONTransformation</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   XMLToJSONTransformationSpec          <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p> <p>Support sending to an event sink instead of replying.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/flow/#flow.triggermesh.io/v1alpha1.XMLToJSONTransformation"},{"title":"XSLTTransformation","text":"<p> <p>XSLTTransformation is the Schema for an XSLT transformation target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> flow.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>XSLTTransformation</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   XSLTTransformationSpec          <code>xslt</code>   ValueFromField     (Optional) <p>XSLT document that will be used by default for transformation. Can be omited if the XSLT is informed at each event.</p>     <code>allowPerEventXSLT</code>  bool    (Optional) <p>Whether the default XSLT can be overriden at each event</p>     <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p> <p>Support sending to an event sink instead of replying.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/flow/#flow.triggermesh.io/v1alpha1.XSLTTransformation"},{"title":"Correlation","text":"<p> (Appears on: SynchronizerSpec) </p> <p> <p>Correlation holds the request-response matching parameters.</p> </p>    Field Description      <code>attribute</code>  string        <code>length</code>  int","location":"apis/flow/#flow.triggermesh.io/v1alpha1.Correlation"},{"title":"DataWeaveTransformationSpec","text":"<p> (Appears on: DataWeaveTransformation) </p> <p> <p>DataWeaveTransformationSpec defines the desired state of the component.</p> </p>    Field Description      <code>dwSpell</code>   ValueFromField     (Optional) <p>DataWeave spell that will be used by default for transformation.</p>     <code>allowPerEventDwSpell</code>  bool    (Optional) <p>Whether the default DwSpell can be overriden at each event</p>     <code>inputContentType</code>  string    (Optional) <p>Content type for the incoming transformation.</p>     <code>outputContentType</code>  string    (Optional) <p>Content type for transformation Output.</p>     <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p> <p>Support sending to an event sink instead of replying.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/flow/#flow.triggermesh.io/v1alpha1.DataWeaveTransformationSpec"},{"title":"EventOptions","text":"<p> (Appears on: JQTransformationSpec,  XMLToJSONTransformationSpec) </p> <p> <p>EventOptions modifies CloudEvents management at Targets.</p> </p>    Field Description      <code>payloadPolicy</code>  github.com/triggermesh/triggermesh/pkg/targets/adapter/cloudevents.PayloadPolicy    (Optional) <p>PayloadPolicy indicates if replies from the target should include a payload if available. Possible values are:</p> <ul> <li>always: will return a with the reply payload if avaliable.</li> <li>errors: will only reply with payload in case of an error.</li> <li>never: will not reply with payload.</li> </ul>","location":"apis/flow/#flow.triggermesh.io/v1alpha1.EventOptions"},{"title":"JQTransformationSpec","text":"<p> (Appears on: JQTransformation) </p> <p> <p>JQTransformationSpec defines the desired state of the component.</p> </p>    Field Description      <code>query</code>  string    <p>The query that gets passed to the JQ library</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p> <p>Support sending to an event sink instead of replying.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/flow/#flow.triggermesh.io/v1alpha1.JQTransformationSpec"},{"title":"Path","text":"<p> (Appears on: Transform) </p> <p> <p>Path is a key-value pair that represents JSON object path</p> </p>    Field Description      <code>key</code>  string        <code>value</code>  string","location":"apis/flow/#flow.triggermesh.io/v1alpha1.Path"},{"title":"Response","text":"<p> (Appears on: SynchronizerSpec) </p> <p> <p>Response defines the response handling configuration.</p> </p>    Field Description      <code>timeout</code>   github.com/triggermesh/triggermesh/pkg/apis.Duration","location":"apis/flow/#flow.triggermesh.io/v1alpha1.Response"},{"title":"SynchronizerSpec","text":"<p> (Appears on: Synchronizer) </p> <p> <p>SynchronizerSpec defines the desired state of the component.</p> </p>    Field Description      <code>correlationKey</code>   Correlation         <code>response</code>   Response         <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p> <p>Support sending to an event sink instead of replying.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/flow/#flow.triggermesh.io/v1alpha1.SynchronizerSpec"},{"title":"Transform","text":"<p> (Appears on: TransformationSpec) </p> <p> <p>Transform describes transformation schemes for different CE types.</p> </p>    Field Description      <code>operation</code>  string        <code>paths</code>   []Path","location":"apis/flow/#flow.triggermesh.io/v1alpha1.Transform"},{"title":"TransformationSpec","text":"<p> (Appears on: Transformation) </p> <p> <p>TransformationSpec defines the desired state of the component.</p> </p>    Field Description      <code>context</code>   []Transform     <p>Context contains Transformations that must be applied on CE Context</p>     <code>data</code>   []Transform     <p>Data contains Transformations that must be applied on CE Data</p>     <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p> <p>Support sending to an event sink instead of replying.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/flow/#flow.triggermesh.io/v1alpha1.TransformationSpec"},{"title":"ValueFromField","text":"<p> (Appears on: DataWeaveTransformationSpec,  XSLTTransformationSpec) </p> <p> <p>ValueFromField is a struct field that can have its value either defined explicitly or sourced from another entity.</p> </p>    Field Description      <code>value</code>  string    (Optional) <p>Field value.</p>     <code>valueFromSecret</code>   Kubernetes core/v1.SecretKeySelector     (Optional) <p>Field value from a Kubernetes Secret.</p>     <code>valueFromConfigMap</code>   Kubernetes core/v1.ConfigMapKeySelector     (Optional) <p>Field value from a Kubernetes ConfigMap.</p>","location":"apis/flow/#flow.triggermesh.io/v1alpha1.ValueFromField"},{"title":"XMLToJSONTransformationSpec","text":"<p> (Appears on: XMLToJSONTransformation) </p> <p> <p>XMLToJSONTransformationSpec defines the desired state of the component.</p> </p>    Field Description      <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p> <p>Support sending to an event sink instead of replying.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/flow/#flow.triggermesh.io/v1alpha1.XMLToJSONTransformationSpec"},{"title":"XSLTTransformationSpec","text":"<p> (Appears on: XSLTTransformation) </p> <p> <p>XSLTTransformationSpec defines the desired state of the component.</p> </p>    Field Description      <code>xslt</code>   ValueFromField     (Optional) <p>XSLT document that will be used by default for transformation. Can be omited if the XSLT is informed at each event.</p>     <code>allowPerEventXSLT</code>  bool    (Optional) <p>Whether the default XSLT can be overriden at each event</p>     <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p> <p>Support sending to an event sink instead of replying.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>      <p> Generated with <code>gen-crd-api-reference-docs</code> on git commit <code>b22c2e53</code>. </p>","location":"apis/flow/#flow.triggermesh.io/v1alpha1.XSLTTransformationSpec"},{"title":"Routing","text":"<p>Package:</p> <ul> <li> routing.triggermesh.io/v1alpha1 </li> </ul>","location":"apis/routing/"},{"title":"routing.triggermesh.io/v1alpha1","text":"<p> <p>Package v1alpha1 contains API Schema definitions for the routing/v1alpha1 API group.</p> </p> <p>Resource Types:</p> <ul><li> Filter </li><li> Splitter </li></ul>","location":"apis/routing/#routing.triggermesh.io/v1alpha1"},{"title":"Filter","text":"<p> <p>Filter is an addressable object that filters incoming events according to provided Common Language Expression</p> </p>    Field Description      <code>apiVersion</code> string  <code> routing.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>Filter</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   FilterSpec          <code>expression</code>  string        <code>sink</code>   knative.dev/pkg/apis/duck/v1.Destination     <p>Sink is a reference to an object that will resolve to a domain name to use as the sink.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/routing/#routing.triggermesh.io/v1alpha1.Filter"},{"title":"Splitter","text":"<p> <p>Splitter is an addressable object that splits incoming events according to provided specification.</p> </p>    Field Description      <code>apiVersion</code> string  <code> routing.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>Splitter</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   SplitterSpec          <code>path</code>  string        <code>ceContext</code>   CloudEventContext         <code>sink</code>   knative.dev/pkg/apis/duck/v1.Destination         <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/routing/#routing.triggermesh.io/v1alpha1.Splitter"},{"title":"CloudEventContext","text":"<p> (Appears on: SplitterSpec) </p> <p> <p>CloudEventContext declares context attributes that will be propagated to resulting events.</p> </p>    Field Description      <code>type</code>  string        <code>source</code>  string        <code>extensions</code>  map[string]string","location":"apis/routing/#routing.triggermesh.io/v1alpha1.CloudEventContext"},{"title":"FilterSpec","text":"<p> (Appears on: Filter) </p> <p> <p>FilterSpec defines the desired state of the component.</p> </p>    Field Description      <code>expression</code>  string        <code>sink</code>   knative.dev/pkg/apis/duck/v1.Destination     <p>Sink is a reference to an object that will resolve to a domain name to use as the sink.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/routing/#routing.triggermesh.io/v1alpha1.FilterSpec"},{"title":"SplitterSpec","text":"<p> (Appears on: Splitter) </p> <p> <p>SplitterSpec defines the desired state of the component.</p> </p>    Field Description      <code>path</code>  string        <code>ceContext</code>   CloudEventContext         <code>sink</code>   knative.dev/pkg/apis/duck/v1.Destination         <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>      <p> Generated with <code>gen-crd-api-reference-docs</code> on git commit <code>b22c2e53</code>. </p>","location":"apis/routing/#routing.triggermesh.io/v1alpha1.SplitterSpec"},{"title":"Sources","text":"<p>Package:</p> <ul> <li> sources.triggermesh.io/v1alpha1 </li> </ul>","location":"apis/sources/"},{"title":"sources.triggermesh.io/v1alpha1","text":"<p> <p>Package v1alpha1 contains API Schema definitions for the sources/v1alpha1 API group.</p> </p> <p>Resource Types:</p> <ul><li> AWSCloudWatchLogsSource </li><li> AWSCloudWatchSource </li><li> AWSCodeCommitSource </li><li> AWSCognitoIdentitySource </li><li> AWSCognitoUserPoolSource </li><li> AWSDynamoDBSource </li><li> AWSEventBridgeSource </li><li> AWSKinesisSource </li><li> AWSPerformanceInsightsSource </li><li> AWSS3Source </li><li> AWSSNSSource </li><li> AWSSQSSource </li><li> AzureActivityLogsSource </li><li> AzureBlobStorageSource </li><li> AzureEventGridSource </li><li> AzureEventHubSource </li><li> AzureIOTHubSource </li><li> AzureQueueStorageSource </li><li> AzureServiceBusQueueSource </li><li> AzureServiceBusTopicSource </li><li> CloudEventsSource </li><li> GoogleCloudAuditLogsSource </li><li> GoogleCloudBillingSource </li><li> GoogleCloudIoTSource </li><li> GoogleCloudPubSubSource </li><li> GoogleCloudSourceRepositoriesSource </li><li> GoogleCloudStorageSource </li><li> HTTPPollerSource </li><li> IBMMQSource </li><li> KafkaSource </li><li> OCIMetricsSource </li><li> SalesforceSource </li><li> SlackSource </li><li> TwilioSource </li><li> WebhookSource </li><li> ZendeskSource </li></ul>","location":"apis/sources/#sources.triggermesh.io/v1alpha1"},{"title":"AWSCloudWatchLogsSource","text":"<p> <p>AWSCloudWatchLogsSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AWSCloudWatchLogsSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AWSCloudWatchLogsSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>arn</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     <p>ARN of the Log Group to source data from. https://docs.aws.amazon.com/service-authorization/latest/reference/list_amazoncloudwatchlogs.html#amazoncloudwatchlogs-resources-for-iam-policies</p>     <code>pollingInterval</code>   github.com/triggermesh/triggermesh/pkg/apis.Duration     (Optional) <p>Duration which defines how often logs should be pulled from Amazon CloudWatch Logs. Expressed as a duration string, which format is documented at https://pkg.go.dev/time#ParseDuration.</p> <p>Defaults to 5m</p>     <code>auth</code>   AWSAuth     <p>Authentication method to interact with the Amazon CloudWatch Logs API.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AWSCloudWatchLogsSource"},{"title":"AWSCloudWatchSource","text":"<p> <p>AWSCloudWatchSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AWSCloudWatchSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AWSCloudWatchSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>region</code>  string    <p>Code of the AWS region to source metrics from. Available region codes are documented at https://docs.aws.amazon.com/general/latest/gr/rande.html#regional-endpoints.</p>     <code>pollingInterval</code>   github.com/triggermesh/triggermesh/pkg/apis.Duration     (Optional) <p>Duration which defines how often metrics should be pulled from Amazon CloudWatch. Expressed as a duration string, which format is documented at https://pkg.go.dev/time#ParseDuration.</p> <p>Defaults to 5m</p>     <code>metricQueries</code>   []AWSCloudWatchMetricQuery     (Optional) <p>List of queries that determine what metrics will be sourced from Amazon CloudWatch.</p>     <code>auth</code>   AWSAuth     <p>Authentication method to interact with the Amazon CloudWatch API.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AWSCloudWatchSource"},{"title":"AWSCodeCommitSource","text":"<p> <p>AWSCodeCommitSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AWSCodeCommitSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AWSCodeCommitSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>arn</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     <p>Repository ARN https://docs.aws.amazon.com/IAM/latest/UserGuide/list_awscodecommit.html#awscodecommit-resources-for-iam-policies</p>     <code>branch</code>  string    <p>Name of the Git branch this source observes.</p>     <code>eventTypes</code>  []string    <p>List of event types that should be processed by the source. Valid values: [push, pull_request]</p>     <code>auth</code>   AWSAuth     <p>Authentication method to interact with the Amazon CodeCommit API.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AWSCodeCommitSource"},{"title":"AWSCognitoIdentitySource","text":"<p> <p>AWSCognitoIdentitySource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AWSCognitoIdentitySource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AWSCognitoIdentitySourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>arn</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     <p>Identity Pool ARN https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazoncognitoidentity.html#amazoncognitoidentity-resources-for-iam-policies</p>     <code>auth</code>   AWSAuth     <p>Authentication method to interact with the Amazon Cognito API.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AWSCognitoIdentitySource"},{"title":"AWSCognitoUserPoolSource","text":"<p> <p>AWSCognitoUserPoolSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AWSCognitoUserPoolSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AWSCognitoUserPoolSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>arn</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     <p>User Pool ARN https://docs.aws.amazon.com/service-authorization/latest/reference/list_amazoncognitouserpools.html#amazoncognitouserpools-resources-for-iam-policies</p>     <code>auth</code>   AWSAuth     <p>Authentication method to interact with the Amazon Cognito API.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AWSCognitoUserPoolSource"},{"title":"AWSDynamoDBSource","text":"<p> <p>AWSDynamoDBSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AWSDynamoDBSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AWSDynamoDBSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>arn</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     <p>Table ARN https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazondynamodb.html#amazondynamodb-resources-for-iam-policies</p>     <code>auth</code>   AWSAuth     <p>Authentication method to interact with the Amazon DynamoDB API.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AWSDynamoDBSource"},{"title":"AWSEventBridgeSource","text":"<p> <p>AWSEventBridgeSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AWSEventBridgeSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AWSEventBridgeSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>arn</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     <p>EventBridge event bus ARN https://docs.aws.amazon.com/service-authorization/latest/reference/list_amazoneventbridge.html#amazoneventbridge-resources-for-iam-policies</p>     <code>eventPattern</code>  string    (Optional) <p>Event pattern used to select events that this source should subscribe to. If not specified, the event rule is created with a catch-all pattern. https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-event-patterns.html</p>     <code>destination</code>   AWSEventBridgeSourceDestination     (Optional) <p>The intermediate destination of notifications originating from the Amazon EventBridge event bus, before they are retrieved by this event source. If omitted, an Amazon SQS queue is automatically created and associated with the EventBridge event rule.</p>     <code>auth</code>   AWSAuth     <p>Authentication method to interact with the Amazon S3 and SQS APIs.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   AWSEventBridgeSourceStatus","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AWSEventBridgeSource"},{"title":"AWSKinesisSource","text":"<p> <p>AWSKinesisSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AWSKinesisSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AWSKinesisSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>arn</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     <p>Stream ARN https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazonkinesis.html#amazonkinesis-resources-for-iam-policies</p>     <code>auth</code>   AWSAuth     <p>Authentication method to interact with the Amazon Kinesis API.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AWSKinesisSource"},{"title":"AWSPerformanceInsightsSource","text":"<p> <p>AWSPerformanceInsightsSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AWSPerformanceInsightsSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AWSPerformanceInsightsSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>arn</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     <p>ARN of the RDS instance to receive metrics for. https://docs.aws.amazon.com/service-authorization/latest/reference/list_amazonrds.html#amazonrds-resources-for-iam-policies</p>     <code>pollingInterval</code>   github.com/triggermesh/triggermesh/pkg/apis.Duration     <p>Duration which defines how often metrics should be pulled from Amazon Performance Insights. Expressed as a duration string, which format is documented at https://pkg.go.dev/time#ParseDuration.</p>     <code>metrics</code>  []string    <p>List of queries that determine what metrics will be sourced from Amazon Performance Insights.</p> <p>Each item represents the \u2018metric\u2019 attribute of a MetricQuery. https://docs.aws.amazon.com/performance-insights/latest/APIReference/API_MetricQuery.html</p>     <code>auth</code>   AWSAuth     <p>Authentication method to interact with the Amazon RDS and Performance Insights APIs.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AWSPerformanceInsightsSource"},{"title":"AWSS3Source","text":"<p> <p>AWSS3Source is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AWSS3Source</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AWSS3SourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>arn</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     <p>Bucket ARN https://docs.aws.amazon.com/service-authorization/latest/reference/list_amazons3.html#amazons3-resources-for-iam-policies</p> <p>Although not technically supported by S3, the ARN provided via this attribute may include a region and an account ID. When this information is provided, it is used to set an accurate identity-based access policy between the S3 bucket and the reconciled SQS queue, unless an existing queue is provided via the QueueARN attribute.</p>     <code>eventTypes</code>  []string    <p>List of event types that the source should subscribe to. Accepted values: https://docs.aws.amazon.com/AmazonS3/latest/API/API_QueueConfiguration.html https://docs.aws.amazon.com/AmazonS3/latest/userguide/notification-how-to-event-types-and-destinations.html</p>     <code>destination</code>   AWSS3SourceDestination     (Optional) <p>The intermediate destination of notifications originating from the Amazon S3 bucket, before they are retrieved by this event source. If omitted, an Amazon SQS queue is automatically created and associated with the bucket.</p>     <code>auth</code>   AWSAuth     <p>Authentication method to interact with the Amazon S3 and SQS APIs.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   AWSS3SourceStatus","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AWSS3Source"},{"title":"AWSSNSSource","text":"<p> <p>AWSSNSSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AWSSNSSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AWSSNSSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>arn</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     <p>Topic ARN https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazonsns.html#amazonsns-resources-for-iam-policies</p>     <code>subscriptionAttributes</code>  map[string]*string    (Optional) <p>Attributes to set on the Subscription that is used for receiving messages from the topic. For a list of supported subscription attributes, please refer to the following resources: * https://docs.aws.amazon.com/sns/latest/api/API_SetSubscriptionAttributes.html * https://docs.aws.amazon.com/sns/latest/dg/sns-how-it-works.html</p>     <code>auth</code>   AWSAuth     <p>Authentication method to interact with the Amazon SNS API.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   AWSSNSSourceStatus","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AWSSNSSource"},{"title":"AWSSQSSource","text":"<p> <p>AWSSQSSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AWSSQSSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AWSSQSSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>arn</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     <p>Queue ARN https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazonsqs.html#amazonsqs-resources-for-iam-policies</p>     <code>receiveOptions</code>   AWSSQSSourceReceiveOptions     (Optional) <p>Options that control the behavior of message receivers.</p>     <code>messageProcessor</code>  string    (Optional) <p>Name of the message processor to use for converting SQS messages to CloudEvents. Supported values are \u201cdefault\u201d and \u201cs3\u201d.</p>     <code>auth</code>   AWSAuth     <p>Authentication method to interact with the Amazon SQS API.</p>     <code>endpoint</code>   AWSEndpoint     (Optional) <p>Customizations of the AWS REST API endpoint.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AWSSQSSource"},{"title":"AzureActivityLogsSource","text":"<p> <p>AzureActivityLogsSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AzureActivityLogsSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AzureActivityLogsSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>subscriptionID</code>  string    <p>The ID of the Azure subscription which activity logs to subscribe to.</p>     <code>destination</code>   AzureActivityLogsSourceDestination     <p>The intermediate destination of activity logs, before they are retrieved by this event source.</p>     <code>categories</code>  []string    (Optional) <p>Categories of Activity Logs to collect.</p> <p>All available categories are selected when this attribute is empty. https://docs.microsoft.com/en-us/azure/azure-monitor/platform/activity-log-schema#categories</p>     <code>auth</code>   AzureAuth     <p>Authentication method to interact with the Azure Monitor REST API. This event source only supports the ServicePrincipal authentication.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   AzureActivityLogsSourceStatus","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AzureActivityLogsSource"},{"title":"AzureBlobStorageSource","text":"<p> <p>AzureBlobStorageSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AzureBlobStorageSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AzureBlobStorageSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>storageAccountID</code>   AzureResourceID     <p>Resource ID of the Storage Account to receive events for.</p> <p>Format: /subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.Storage/storageAccounts/{storageAccountName}</p> <p>Besides the Storage Account name itself, the resource ID contains the subscription ID and resource group name which all together uniquely identify the Storage Account within Azure.</p>     <code>eventTypes</code>  []string    (Optional) <p>Types of events to subscribe to.</p> <p>The list of available event types can be found at https://docs.microsoft.com/en-us/azure/event-grid/event-schema-blob-storage</p> <p>When this attribute is not set, the source automatically subscribes to the following event types: - Microsoft.Storage.BlobCreated - Microsoft.Storage.BlobDeleted</p>     <code>endpoint</code>   AzureEventGridSourceEndpoint     <p>The intermediate destination of events subscribed via Event Grid, before they are retrieved by this event source.</p>     <code>auth</code>   AzureAuth     <p>Authentication method to interact with the Azure REST API. This event source only supports the ServicePrincipal authentication.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   AzureBlobStorageSourceStatus","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AzureBlobStorageSource"},{"title":"AzureEventGridSource","text":"<p> <p>AzureEventGridSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AzureEventGridSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AzureEventGridSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>scope</code>   AzureResourceID     <p>The resource ID the event subscription applies to.</p> <p>Can be - an Azure subscription: /subscriptions/{subscriptionId} - a resource group: /subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName} - a top-level resource from a resource provider (including Event Grid topic): /subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/{resourceProviderNamespace}/{resourceType}/{resourceName}</p>     <code>eventTypes</code>  []string    (Optional) <p>Types of events to subscribe to.</p> <p>If not specified, Azure automatically selects all available event types for the provided Scope.</p> <p>For a list of all available event types, please refer to the list of Azure services that support system topics at https://docs.microsoft.com/en-us/azure/event-grid/system-topics</p>     <code>endpoint</code>   AzureEventGridSourceEndpoint     <p>The intermediate destination of events subscribed via Event Grid, before they are retrieved by this event source.</p>     <code>auth</code>   AzureAuth     <p>Authentication method to interact with the Azure REST API. This event source only supports the ServicePrincipal authentication.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   AzureEventGridSourceStatus","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AzureEventGridSource"},{"title":"AzureEventHubSource","text":"<p> <p>AzureEventHubSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AzureEventHubSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AzureEventHubSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>eventHubID</code>   AzureResourceID     <p>Resource ID of the Event Hubs instance.</p> <p>Expected format: - /subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.EventHub/namespaces/{namespaceName}/eventhubs/{eventHubName}</p>     <code>auth</code>   AzureAuth     <p>Authentication method to interact with the Azure Event Hubs API.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AzureEventHubSource"},{"title":"AzureIOTHubSource","text":"<p> <p>AzureIOTHubSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AzureIOTHubSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AzureIOTHubSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>auth</code>   AzureAuth     <p>AzureAuth contains multiple authentication methods for Azure services.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AzureIOTHubSource"},{"title":"AzureQueueStorageSource","text":"<p> <p>AzureQueueStorageSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AzureQueueStorageSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AzureQueueStorageSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>accountName</code>  string        <code>queueName</code>  string        <code>accountKey</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AzureQueueStorageSource"},{"title":"AzureServiceBusQueueSource","text":"<p> <p>AzureServiceBusQueueSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AzureServiceBusQueueSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AzureServiceBusQueueSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>queueID</code>   AzureResourceID     <p>The resource ID the Service Bus Queue to subscribe to.</p> <p>Expected format: - /subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.ServiceBus/namespaces/{namespaceName}/queues/{queueName}</p>     <code>auth</code>   AzureAuth     <p>Authentication method to interact with Azure Service Bus.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AzureServiceBusQueueSource"},{"title":"AzureServiceBusTopicSource","text":"<p> <p>AzureServiceBusTopicSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AzureServiceBusTopicSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AzureServiceBusTopicSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>topicID</code>   AzureResourceID     <p>The resource ID the Service Bus Topic to subscribe to.</p> <p>Expected format: - /subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.ServiceBus/namespaces/{namespaceName}/topics/{topicName}</p>     <code>auth</code>   AzureAuth     <p>Authentication method to interact with the Azure REST API. This event source only supports the ServicePrincipal authentication.</p>     <code>webSocketsEnable</code>  bool    (Optional) <p>WebSocketsEnable</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   AzureServiceBusTopicSourceStatus","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AzureServiceBusTopicSource"},{"title":"CloudEventsSource","text":"<p> <p>CloudEventsSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>CloudEventsSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   CloudEventsSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>credentials</code>   HTTPCredentials     (Optional) <p>Credentials to connect to this source.</p>     <code>path</code>  string    (Optional) <p>Path under which requests are accepted.</p>     <code>rateLimiter</code>   RateLimiter     (Optional) <p>RateLimiter for incoming events per adapter instance. A single CloudEventsSource object can create multiple adapter instances, the rate limiting configuration being applied to each of them individually.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/sources/#sources.triggermesh.io/v1alpha1.CloudEventsSource"},{"title":"GoogleCloudAuditLogsSource","text":"<p> <p>GoogleCloudAuditLogsSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>GoogleCloudAuditLogsSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   GoogleCloudAuditLogsSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>serviceName</code>  string    <p>The GCP service this instance should source audit logs from. Required. example: compute.googleapis.com</p>     <code>methodName</code>  string    <p>The name of the service method or operation. For API calls, this should be the name of the API method. Required. beta.compute.instances.insert</p>     <code>resourceName</code>  string    <p>The resource or collection that is the target of the operation. The name is a scheme-less URI, not including the API service name. example: \u201cprojects/PROJECT_ID/zones/us-central1-a/instances\u201d</p>     <code>pubsub</code>   GoogleCloudSourcePubSubSpec     <p>Settings related to the Pub/Sub resources associated with the Audit Logs event sink.</p>     <code>serviceAccountKey</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     <p>Service account key in JSON format. https://cloud.google.com/iam/docs/creating-managing-service-account-keys</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   GoogleCloudAuditLogsSourceStatus","location":"apis/sources/#sources.triggermesh.io/v1alpha1.GoogleCloudAuditLogsSource"},{"title":"GoogleCloudBillingSource","text":"<p> <p>GoogleCloudBillingSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>GoogleCloudBillingSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   GoogleCloudBillingSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>billingAccountId</code>  string    <p>The identifier for the Cloud Billing account owning the budget.</p>     <code>budgetId</code>  string    <p>The identifier for the Cloud Billing budget. You can locate the budget\u2019s ID in your budget under Manage notifications. The ID is displayed after you select Connect a Pub/Sub topic to this budget.</p>     <code>pubsub</code>   GoogleCloudSourcePubSubSpec     <p>Settings related to the Pub/Sub resources associated with the Billing budget event sink.</p>     <code>serviceAccountKey</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     <p>Service account key in JSON format. https://cloud.google.com/iam/docs/creating-managing-service-account-keys</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   GoogleCloudBillingSourceStatus","location":"apis/sources/#sources.triggermesh.io/v1alpha1.GoogleCloudBillingSource"},{"title":"GoogleCloudIoTSource","text":"<p> <p>GoogleCloudIoTSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>GoogleCloudIoTSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   GoogleCloudIoTSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>registry</code>   GCloudIoTResourceName     <p>Resource name of the Cloud IoT Registry to receive messages from.</p>     <code>pubsub</code>   GoogleCloudSourcePubSubSpec     <p>Settings related to the Pub/Sub resources associated with the Cloud IoT Registry.</p>     <code>serviceAccountKey</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     <p>Service account key in JSON format. https://cloud.google.com/iam/docs/creating-managing-service-account-keys</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   GoogleCloudIoTSourceStatus","location":"apis/sources/#sources.triggermesh.io/v1alpha1.GoogleCloudIoTSource"},{"title":"GoogleCloudPubSubSource","text":"<p> <p>GoogleCloudPubSubSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>GoogleCloudPubSubSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   GoogleCloudPubSubSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>topic</code>   GCloudResourceName     <p>Full resource name of the Pub/Sub topic to subscribe to, in the format \u201cprojects/{project_name}/topics/{topic_name}\u201d.</p>     <code>subscriptionID</code>  string    (Optional) <p>ID of the subscription to use to pull messages from the topic.</p> <p>If supplied, this subscription must 1) exist and 2) belong to the provided topic. Otherwise, a pull subscription to that topic is created on behalf of the user.</p>     <code>serviceAccountKey</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     <p>Service account key in JSON format. https://cloud.google.com/iam/docs/creating-managing-service-account-keys</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   GoogleCloudPubSubSourceStatus","location":"apis/sources/#sources.triggermesh.io/v1alpha1.GoogleCloudPubSubSource"},{"title":"GoogleCloudSourceRepositoriesSource","text":"<p> <p>GoogleCloudSourceRepositoriesSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>GoogleCloudSourceRepositoriesSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   GoogleCloudSourceRepositoriesSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>repository</code>   GCloudResourceName     <p>Name of the Cloud repo to receive notifications from.</p>     <code>pubsub</code>   GoogleCloudSourcePubSubSpec     <p>Settings related to the Pub/Sub resources associated with the repo events.</p>     <code>publishServiceAccount</code>  string    (Optional) <p>Email address of the service account used for publishing notifications to Pub/Sub. This service account needs to be in the same project as the repo, and to have the \u2018pubsub.topics.publish\u2019 IAM permission associated with it. It can (but doesn\u2019t have to) be the same service account as the \u2018ServiceAccountKey\u2019 attribute.</p> <p>If unspecified, it defaults to the Compute Engine default service account.</p>     <code>serviceAccountKey</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     <p>Service account key in JSON format. https://cloud.google.com/iam/docs/creating-managing-service-account-keys</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   GoogleCloudSourceRepositoriesSourceStatus","location":"apis/sources/#sources.triggermesh.io/v1alpha1.GoogleCloudSourceRepositoriesSource"},{"title":"GoogleCloudStorageSource","text":"<p> <p>GoogleCloudStorageSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>GoogleCloudStorageSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   GoogleCloudStorageSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>bucket</code>  string    <p>Name of the Cloud Storage bucket to receive change notifications from.</p>     <code>pubsub</code>   GoogleCloudSourcePubSubSpec     <p>Settings related to the Pub/Sub resources associated with the bucket.</p>     <code>eventTypes</code>  []string    (Optional) <p>Types of events to subscribe to.</p> <p>The list of available event types can be found at https://cloud.google.com/storage/docs/pubsub-notifications#events</p> <p>All types are selected when this attribute is not set.</p>     <code>serviceAccountKey</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     <p>Service account key in JSON format. https://cloud.google.com/iam/docs/creating-managing-service-account-keys</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   GoogleCloudStorageSourceStatus","location":"apis/sources/#sources.triggermesh.io/v1alpha1.GoogleCloudStorageSource"},{"title":"HTTPPollerSource","text":"<p> <p>HTTPPollerSource is the schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>HTTPPollerSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   HTTPPollerSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p> <p>inherits duck/v1 SourceSpec, which currently provides: * Sink - a reference to an object that will resolve to a domain name or a URI directly to use as the sink. * CloudEventOverrides - defines overrides to control the output format and modifications of the event sent to the sink.</p>     <code>eventType</code>  string    <p>Value of the CloudEvents \u2018type\u2019 attribute to set on ingested events. https://github.com/cloudevents/spec/blob/v1.0.1/spec.md#type</p>     <code>eventSource</code>  string    (Optional) <p>Value of the CloudEvents \u2018source\u2019 attribute to set on ingested events. https://github.com/cloudevents/spec/blob/v1.0.1/spec.md#source-1</p>     <code>endpoint</code>   knative.dev/pkg/apis.URL     <p>HTTP/S URL of the endpoint to poll data from.</p>     <code>method</code>  string    <p>HTTP request method to use in requests to the specified \u2018endpoint\u2019. https://developer.mozilla.org/en-US/docs/Web/HTTP/Methods</p>     <code>skipVerify</code>  bool    (Optional) <p>Controls whether the HTTP client verifies the server\u2019s certificate chain and host name when communicating over TLS.</p>     <code>caCertificate</code>  string    (Optional) <p>CA certificate in X.509 format the HTTP client should use to verify the identity of remote servers when communicating over TLS.</p>     <code>basicAuthUsername</code>  string    (Optional) <p>User name to set in HTTP requests that require HTTP Basic authentication.</p>     <code>basicAuthPassword</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     (Optional) <p>Password to set in HTTP requests that require HTTP Basic authentication.</p>     <code>headers</code>  map[string]string    (Optional) <p>HTTP headers to include in HTTP requests.</p>     <code>interval</code>   github.com/triggermesh/triggermesh/pkg/apis.Duration     <p>Duration which defines how often the HTTP/S endpoint should be polled. Expressed as a duration string, which format is documented at https://pkg.go.dev/time#ParseDuration.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/sources/#sources.triggermesh.io/v1alpha1.HTTPPollerSource"},{"title":"IBMMQSource","text":"<p> <p>IBMMQSource is the Schema the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>IBMMQSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   IBMMQSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>connectionName</code>  string        <code>queueManager</code>  string        <code>queueName</code>  string        <code>channelName</code>  string        <code>delivery</code>   Delivery         <code>credentials</code>   Credentials         <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/sources/#sources.triggermesh.io/v1alpha1.IBMMQSource"},{"title":"KafkaSource","text":"<p> <p>KafkaSource is the Schema for the KafkaSource.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>KafkaSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   KafkaSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>bootstrapServers</code>  []string    <p>BootstrapServers holds the name of the Kafka Bootstrap server.</p>     <code>topics</code>  []string    <p>Topics holds the name of the Kafka Topics.</p>     <code>groupID</code>  string    <p>GroupID holds the name of the Kafka Group ID.</p>     <code>auth</code>   KafkaSourceAuth     <p>Auth contains Authentication method used to interact with Kafka.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/sources/#sources.triggermesh.io/v1alpha1.KafkaSource"},{"title":"OCIMetricsSource","text":"<p> <p>OCIMetricsSource is the schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>OCIMetricsSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   OCIMetricsSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p> <p>inherits duck/v1 SourceSpec, which currently provides: * Sink - a reference to an object that will resolve to a domain name or a URI directly to use as the sink. * CloudEventOverrides - defines overrides to control the output format and modifications of the event sent to the sink.</p>     <code>oracleApiPrivateKey</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     <p>Oracle User API private key</p>     <code>oracleApiPrivateKeyPassphrase</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     <p>Oracle User API private key passphrase</p>     <code>oracleApiPrivateKeyFingerprint</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     <p>Oracle User API cert fingerprint</p>     <code>oracleTenancy</code>  string    <p>Oracle Tenancy OCID</p>     <code>oracleUser</code>  string    <p>Oracle User OCID associated with the API key</p>     <code>oracleRegion</code>  string    <p>Oracle Cloud Region</p>     <code>metricsPollingFrequency</code>  string    (Optional) <p>OCI Metrics Polling Frequency</p>     <code>metrics</code>   []OCIMetrics     <p>Array of metrics</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/sources/#sources.triggermesh.io/v1alpha1.OCIMetricsSource"},{"title":"SalesforceSource","text":"<p> <p>SalesforceSource is the Schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>SalesforceSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   SalesforceSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>auth</code>   SalesforceAuth     <p>Authentication method to interact with the Salesforce API.</p>     <code>apiVersion</code>  string    (Optional) <p>APIVersion at Salesforce.</p>     <code>subscription</code>   SalesforceSubscription     <p>Subscription to a Salesforce channel</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/sources/#sources.triggermesh.io/v1alpha1.SalesforceSource"},{"title":"SlackSource","text":"<p> <p>SlackSource is the schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>SlackSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   SlackSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p> <p>inherits duck/v1 SourceSpec, which currently provides: * Sink - a reference to an object that will resolve to a domain name or a URI directly to use as the sink. * CloudEventOverrides - defines overrides to control the output format and modifications of the event sent to the sink.</p>     <code>signingSecret</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     (Optional) <p>SigningSecret can be set to the value of Slack request signing secret to authenticate callbacks. See: https://api.slack.com/authentication/verifying-requests-from-slack</p>     <code>appID</code>  string    (Optional) <p>AppID identifies the Slack application generating this event. It helps identifying the App sourcing events when multiple Slack applications shared an endpoint. See: https://api.slack.com/events-api</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/sources/#sources.triggermesh.io/v1alpha1.SlackSource"},{"title":"TwilioSource","text":"<p> <p>TwilioSource is the schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>TwilioSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   TwilioSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/sources/#sources.triggermesh.io/v1alpha1.TwilioSource"},{"title":"WebhookSource","text":"<p> <p>WebhookSource is the schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>WebhookSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   WebhookSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p> <p>inherits duck/v1 SourceSpec, which currently provides: * Sink - a reference to an object that will resolve to a domain name or a URI directly to use as the sink. * CloudEventOverrides - defines overrides to control the output format and modifications of the event sent to the sink.</p>     <code>eventType</code>  string    <p>Value of the CloudEvents \u2018type\u2019 attribute to set on ingested events. https://github.com/cloudevents/spec/blob/v1.0.1/spec.md#type</p>     <code>eventSource</code>  string    (Optional) <p>Value of the CloudEvents \u2018source\u2019 attribute to set on ingested events. https://github.com/cloudevents/spec/blob/v1.0.1/spec.md#source-1</p>     <code>eventExtensionAttributes</code>   WebhookEventExtensionAttributes     (Optional) <p>Options to transform HTTP request data into CloudEvent extensions. https://github.com/cloudevents/spec/blob/main/cloudevents/spec.md#extension-context-attributes</p>     <code>basicAuthUsername</code>  string    (Optional) <p>User name HTTP clients must set to authenticate with the webhook using HTTP Basic authentication.</p>     <code>basicAuthPassword</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     (Optional) <p>Password HTTP clients must set to authenticate with the webhook using HTTP Basic authentication.</p>     <code>corsAllowOrigin</code>  string    (Optional) <p>Specifies the CORS Origin to use in pre-flight headers.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/sources/#sources.triggermesh.io/v1alpha1.WebhookSource"},{"title":"ZendeskSource","text":"<p> <p>ZendeskSource is the schema for the event source.</p> </p>    Field Description      <code>apiVersion</code> string  <code> sources.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>ZendeskSource</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   ZendeskSourceSpec          <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p> <p>inherits duck/v1 SourceSpec, which currently provides: * Sink - a reference to an object that will resolve to a domain name or a URI directly to use as the sink. * CloudEventOverrides - defines overrides to control the output format and modifications of the event sent to the sink.</p>     <code>token</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     <p>Token identifies the API token used for creating the proper credentials to interface with Zendesk allowing the source to auto-register the webhook to authenticate callbacks.</p>     <code>email</code>  string    <p>Email identifies the email used for creating the proper credentials to interface with Zendesk allowing the source to auto-register the webhook to authenticate callbacks.</p>     <code>webhookPassword</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     <p>WebhookPassword used for basic authentication for events sent from Zendesk to the adapter.</p>     <code>webhookUsername</code>  string    <p>WebhookUsername used for basic authentication for events sent from Zendesk to the adapter.</p>     <code>subdomain</code>  string    <p>Subdomain identifies Zendesk subdomain</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   ZendeskSourceStatus","location":"apis/sources/#sources.triggermesh.io/v1alpha1.ZendeskSource"},{"title":"AWSAuth","text":"<p> (Appears on: AWSCloudWatchLogsSourceSpec,  AWSCloudWatchSourceSpec,  AWSCodeCommitSourceSpec,  AWSCognitoIdentitySourceSpec,  AWSCognitoUserPoolSourceSpec,  AWSDynamoDBSourceSpec,  AWSEventBridgeSourceSpec,  AWSKinesisSourceSpec,  AWSPerformanceInsightsSourceSpec,  AWSS3SourceSpec,  AWSSNSSourceSpec,  AWSSQSSourceSpec) </p> <p> <p>AWSAuth contains multiple authentication methods for AWS services.</p> </p>    Field Description      <code>credentials</code>   AWSSecurityCredentials     (Optional) <p>Security credentials allow AWS to authenticate and authorize requests based on a signature composed of an access key ID and a corresponding secret access key. See https://docs.aws.amazon.com/general/latest/gr/aws-security-credentials.html</p>     <code>iamRole</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     (Optional) <p>(Amazon EKS only) The ARN of an IAM role which can be impersonated to obtain AWS permissions. See https://docs.aws.amazon.com/eks/latest/userguide/iam-roles-for-service-accounts.html</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AWSAuth"},{"title":"AWSCloudWatchLogsSourceSpec","text":"<p> (Appears on: AWSCloudWatchLogsSource) </p> <p> <p>AWSCloudWatchLogsSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>arn</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     <p>ARN of the Log Group to source data from. https://docs.aws.amazon.com/service-authorization/latest/reference/list_amazoncloudwatchlogs.html#amazoncloudwatchlogs-resources-for-iam-policies</p>     <code>pollingInterval</code>   github.com/triggermesh/triggermesh/pkg/apis.Duration     (Optional) <p>Duration which defines how often logs should be pulled from Amazon CloudWatch Logs. Expressed as a duration string, which format is documented at https://pkg.go.dev/time#ParseDuration.</p> <p>Defaults to 5m</p>     <code>auth</code>   AWSAuth     <p>Authentication method to interact with the Amazon CloudWatch Logs API.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AWSCloudWatchLogsSourceSpec"},{"title":"AWSCloudWatchMetric","text":"<p> (Appears on: AWSCloudWatchMetricStat) </p> <p> <p>AWSCloudWatchMetric is a metric definition.</p> </p>    Field Description      <code>dimensions</code>   []AWSCloudWatchMetricDimension         <code>metricName</code>  string        <code>namespace</code>  string","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AWSCloudWatchMetric"},{"title":"AWSCloudWatchMetricDimension","text":"<p> (Appears on: AWSCloudWatchMetric) </p> <p> <p>AWSCloudWatchMetricDimension represents the dimensions of a metric.</p> </p>    Field Description      <code>name</code>  string        <code>value</code>  string","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AWSCloudWatchMetricDimension"},{"title":"AWSCloudWatchMetricQuery","text":"<p> (Appears on: AWSCloudWatchSourceSpec) </p> <p> <p>AWSCloudWatchMetricQuery represents a CloudWatch MetricDataQuery. https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_MetricDataQuery.html</p> </p>    Field Description      <code>name</code>  string    <p>Unique short name that identifies the query.</p>     <code>expression</code>  string    (Optional) <p>Math expression to be performed on the metric data.</p>     <code>metric</code>   AWSCloudWatchMetricStat     (Optional) <p>Representation of a metric with statistics, period, and units, but no math expression.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AWSCloudWatchMetricQuery"},{"title":"AWSCloudWatchMetricStat","text":"<p> (Appears on: AWSCloudWatchMetricQuery) </p> <p> <p>AWSCloudWatchMetricStat is a representation of a metric with statistics, period, and units, but no math expression.</p> </p>    Field Description      <code>metric</code>   AWSCloudWatchMetric         <code>period</code>  int64    <p>Definition of the metric</p>     <code>stat</code>  string    <p>metric resolution in seconds</p>     <code>unit</code>  string    <p>statistic type to use</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AWSCloudWatchMetricStat"},{"title":"AWSCloudWatchSourceSpec","text":"<p> (Appears on: AWSCloudWatchSource) </p> <p> <p>AWSCloudWatchSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>region</code>  string    <p>Code of the AWS region to source metrics from. Available region codes are documented at https://docs.aws.amazon.com/general/latest/gr/rande.html#regional-endpoints.</p>     <code>pollingInterval</code>   github.com/triggermesh/triggermesh/pkg/apis.Duration     (Optional) <p>Duration which defines how often metrics should be pulled from Amazon CloudWatch. Expressed as a duration string, which format is documented at https://pkg.go.dev/time#ParseDuration.</p> <p>Defaults to 5m</p>     <code>metricQueries</code>   []AWSCloudWatchMetricQuery     (Optional) <p>List of queries that determine what metrics will be sourced from Amazon CloudWatch.</p>     <code>auth</code>   AWSAuth     <p>Authentication method to interact with the Amazon CloudWatch API.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AWSCloudWatchSourceSpec"},{"title":"AWSCodeCommitSourceSpec","text":"<p> (Appears on: AWSCodeCommitSource) </p> <p> <p>AWSCodeCommitSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>arn</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     <p>Repository ARN https://docs.aws.amazon.com/IAM/latest/UserGuide/list_awscodecommit.html#awscodecommit-resources-for-iam-policies</p>     <code>branch</code>  string    <p>Name of the Git branch this source observes.</p>     <code>eventTypes</code>  []string    <p>List of event types that should be processed by the source. Valid values: [push, pull_request]</p>     <code>auth</code>   AWSAuth     <p>Authentication method to interact with the Amazon CodeCommit API.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AWSCodeCommitSourceSpec"},{"title":"AWSCognitoIdentitySourceSpec","text":"<p> (Appears on: AWSCognitoIdentitySource) </p> <p> <p>AWSCognitoIdentitySourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>arn</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     <p>Identity Pool ARN https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazoncognitoidentity.html#amazoncognitoidentity-resources-for-iam-policies</p>     <code>auth</code>   AWSAuth     <p>Authentication method to interact with the Amazon Cognito API.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AWSCognitoIdentitySourceSpec"},{"title":"AWSCognitoUserPoolSourceSpec","text":"<p> (Appears on: AWSCognitoUserPoolSource) </p> <p> <p>AWSCognitoUserPoolSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>arn</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     <p>User Pool ARN https://docs.aws.amazon.com/service-authorization/latest/reference/list_amazoncognitouserpools.html#amazoncognitouserpools-resources-for-iam-policies</p>     <code>auth</code>   AWSAuth     <p>Authentication method to interact with the Amazon Cognito API.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AWSCognitoUserPoolSourceSpec"},{"title":"AWSDynamoDBSourceSpec","text":"<p> (Appears on: AWSDynamoDBSource) </p> <p> <p>AWSDynamoDBSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>arn</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     <p>Table ARN https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazondynamodb.html#amazondynamodb-resources-for-iam-policies</p>     <code>auth</code>   AWSAuth     <p>Authentication method to interact with the Amazon DynamoDB API.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AWSDynamoDBSourceSpec"},{"title":"AWSEndpoint","text":"<p> (Appears on: AWSSQSSourceSpec) </p> <p> <p>AWSEndpoint contains parameters which are used to override the destination of REST API calls to AWS services. It allows, for example, to target API-compatible alternatives to the public AWS cloud (Localstack, Minio, ElasticMQ, \u2026).</p> </p>    Field Description      <code>url</code>   knative.dev/pkg/apis.URL     <p>URL of the endpoint.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AWSEndpoint"},{"title":"AWSEventBridgeSourceDestination","text":"<p> (Appears on: AWSEventBridgeSourceSpec) </p> <p> <p>AWSEventBridgeSourceDestination contains possible intermediate destinations for the event bus\u2019 events.</p> </p>    Field Description      <code>sqs</code>   AWSEventBridgeSourceDestinationSQS     (Optional) <p>Amazon SQS destination.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AWSEventBridgeSourceDestination"},{"title":"AWSEventBridgeSourceDestinationSQS","text":"<p> (Appears on: AWSEventBridgeSourceDestination) </p> <p> <p>AWSEventBridgeSourceDestinationSQS contains properties of an Amazon SQS queue to use as destination for the event bus\u2019 events.</p> </p>    Field Description      <code>queueARN</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     <p>SQS Queue ARN https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazonsqs.html#amazonsqs-resources-for-iam-policies</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AWSEventBridgeSourceDestinationSQS"},{"title":"AWSEventBridgeSourceSpec","text":"<p> (Appears on: AWSEventBridgeSource) </p> <p> <p>AWSEventBridgeSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>arn</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     <p>EventBridge event bus ARN https://docs.aws.amazon.com/service-authorization/latest/reference/list_amazoneventbridge.html#amazoneventbridge-resources-for-iam-policies</p>     <code>eventPattern</code>  string    (Optional) <p>Event pattern used to select events that this source should subscribe to. If not specified, the event rule is created with a catch-all pattern. https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-event-patterns.html</p>     <code>destination</code>   AWSEventBridgeSourceDestination     (Optional) <p>The intermediate destination of notifications originating from the Amazon EventBridge event bus, before they are retrieved by this event source. If omitted, an Amazon SQS queue is automatically created and associated with the EventBridge event rule.</p>     <code>auth</code>   AWSAuth     <p>Authentication method to interact with the Amazon S3 and SQS APIs.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AWSEventBridgeSourceSpec"},{"title":"AWSEventBridgeSourceStatus","text":"<p> (Appears on: AWSEventBridgeSource) </p> <p> <p>AWSEventBridgeSourceStatus defines the observed state of the event source.</p> </p>    Field Description      <code>Status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status     <p> (Members of <code>Status</code> are embedded into this type.) </p>     <code>ruleARN</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN         <code>queueARN</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AWSEventBridgeSourceStatus"},{"title":"AWSKinesisSourceSpec","text":"<p> (Appears on: AWSKinesisSource) </p> <p> <p>AWSKinesisSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>arn</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     <p>Stream ARN https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazonkinesis.html#amazonkinesis-resources-for-iam-policies</p>     <code>auth</code>   AWSAuth     <p>Authentication method to interact with the Amazon Kinesis API.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AWSKinesisSourceSpec"},{"title":"AWSPerformanceInsightsSourceSpec","text":"<p> (Appears on: AWSPerformanceInsightsSource) </p> <p> <p>AWSPerformanceInsightsSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>arn</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     <p>ARN of the RDS instance to receive metrics for. https://docs.aws.amazon.com/service-authorization/latest/reference/list_amazonrds.html#amazonrds-resources-for-iam-policies</p>     <code>pollingInterval</code>   github.com/triggermesh/triggermesh/pkg/apis.Duration     <p>Duration which defines how often metrics should be pulled from Amazon Performance Insights. Expressed as a duration string, which format is documented at https://pkg.go.dev/time#ParseDuration.</p>     <code>metrics</code>  []string    <p>List of queries that determine what metrics will be sourced from Amazon Performance Insights.</p> <p>Each item represents the \u2018metric\u2019 attribute of a MetricQuery. https://docs.aws.amazon.com/performance-insights/latest/APIReference/API_MetricQuery.html</p>     <code>auth</code>   AWSAuth     <p>Authentication method to interact with the Amazon RDS and Performance Insights APIs.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AWSPerformanceInsightsSourceSpec"},{"title":"AWSS3SourceDestination","text":"<p> (Appears on: AWSS3SourceSpec) </p> <p> <p>AWSS3SourceDestination contains possible intermediate destinations for bucket notifications.</p> </p>    Field Description      <code>sqs</code>   AWSS3SourceDestinationSQS     (Optional) <p>Amazon SQS destination.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AWSS3SourceDestination"},{"title":"AWSS3SourceDestinationSQS","text":"<p> (Appears on: AWSS3SourceDestination) </p> <p> <p>AWSS3SourceDestinationSQS contains properties of an Amazon SQS queue to use as destination for bucket notifications.</p> </p>    Field Description      <code>queueARN</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     <p>SQS Queue ARN https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazonsqs.html#amazonsqs-resources-for-iam-policies</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AWSS3SourceDestinationSQS"},{"title":"AWSS3SourceSpec","text":"<p> (Appears on: AWSS3Source) </p> <p> <p>AWSS3SourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>arn</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     <p>Bucket ARN https://docs.aws.amazon.com/service-authorization/latest/reference/list_amazons3.html#amazons3-resources-for-iam-policies</p> <p>Although not technically supported by S3, the ARN provided via this attribute may include a region and an account ID. When this information is provided, it is used to set an accurate identity-based access policy between the S3 bucket and the reconciled SQS queue, unless an existing queue is provided via the QueueARN attribute.</p>     <code>eventTypes</code>  []string    <p>List of event types that the source should subscribe to. Accepted values: https://docs.aws.amazon.com/AmazonS3/latest/API/API_QueueConfiguration.html https://docs.aws.amazon.com/AmazonS3/latest/userguide/notification-how-to-event-types-and-destinations.html</p>     <code>destination</code>   AWSS3SourceDestination     (Optional) <p>The intermediate destination of notifications originating from the Amazon S3 bucket, before they are retrieved by this event source. If omitted, an Amazon SQS queue is automatically created and associated with the bucket.</p>     <code>auth</code>   AWSAuth     <p>Authentication method to interact with the Amazon S3 and SQS APIs.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AWSS3SourceSpec"},{"title":"AWSS3SourceStatus","text":"<p> (Appears on: AWSS3Source) </p> <p> <p>AWSS3SourceStatus defines the observed state of the event source.</p> </p>    Field Description      <code>Status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status     <p> (Members of <code>Status</code> are embedded into this type.) </p>     <code>queueARN</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AWSS3SourceStatus"},{"title":"AWSSNSSourceSpec","text":"<p> (Appears on: AWSSNSSource) </p> <p> <p>AWSSNSSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>arn</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     <p>Topic ARN https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazonsns.html#amazonsns-resources-for-iam-policies</p>     <code>subscriptionAttributes</code>  map[string]*string    (Optional) <p>Attributes to set on the Subscription that is used for receiving messages from the topic. For a list of supported subscription attributes, please refer to the following resources: * https://docs.aws.amazon.com/sns/latest/api/API_SetSubscriptionAttributes.html * https://docs.aws.amazon.com/sns/latest/dg/sns-how-it-works.html</p>     <code>auth</code>   AWSAuth     <p>Authentication method to interact with the Amazon SNS API.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AWSSNSSourceSpec"},{"title":"AWSSNSSourceStatus","text":"<p> (Appears on: AWSSNSSource) </p> <p> <p>AWSSNSSourceStatus defines the observed state of the event source.</p> </p>    Field Description      <code>Status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status     <p> (Members of <code>Status</code> are embedded into this type.) </p>     <code>subscriptionARN</code>  string","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AWSSNSSourceStatus"},{"title":"AWSSQSSourceReceiveOptions","text":"<p> (Appears on: AWSSQSSourceSpec) </p> <p> <p>AWSSQSSourceReceiveOptions defines options that control the behavior of Amazon SQS message receivers.</p> </p>    Field Description      <code>visibilityTimeout</code>   github.com/triggermesh/triggermesh/pkg/apis.Duration     (Optional) <p>Period of time during which Amazon SQS prevents other consumers from receiving and processing a message that has been received via ReceiveMessage. Expressed as a duration string, which format is documented at https://pkg.go.dev/time#ParseDuration.</p> <p>If not defined, the overall visibility timeout for the queue is used.</p> <p>For more details, please refer to the Amazon SQS Developer Guide at https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-visibility-timeout.html.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AWSSQSSourceReceiveOptions"},{"title":"AWSSQSSourceSpec","text":"<p> (Appears on: AWSSQSSource) </p> <p> <p>AWSSQSSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>arn</code>   github.com/triggermesh/triggermesh/pkg/apis.ARN     <p>Queue ARN https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazonsqs.html#amazonsqs-resources-for-iam-policies</p>     <code>receiveOptions</code>   AWSSQSSourceReceiveOptions     (Optional) <p>Options that control the behavior of message receivers.</p>     <code>messageProcessor</code>  string    (Optional) <p>Name of the message processor to use for converting SQS messages to CloudEvents. Supported values are \u201cdefault\u201d and \u201cs3\u201d.</p>     <code>auth</code>   AWSAuth     <p>Authentication method to interact with the Amazon SQS API.</p>     <code>endpoint</code>   AWSEndpoint     (Optional) <p>Customizations of the AWS REST API endpoint.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AWSSQSSourceSpec"},{"title":"AWSSecurityCredentials","text":"<p> (Appears on: AWSAuth) </p> <p> <p>AWSSecurityCredentials represents a set of AWS security credentials.</p> </p>    Field Description      <code>accessKeyID</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>secretAccessKey</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AWSSecurityCredentials"},{"title":"AzureActivityLogsSourceDestination","text":"<p> (Appears on: AzureActivityLogsSourceSpec) </p> <p> <p>AzureActivityLogsSourceDestination contains possible intermediate destinations for activity logs.</p> </p>    Field Description      <code>eventHubs</code>   AzureActivityLogsSourceDestinationEventHubs","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AzureActivityLogsSourceDestination"},{"title":"AzureActivityLogsSourceDestinationEventHubs","text":"<p> (Appears on: AzureActivityLogsSourceDestination) </p> <p> <p>AzureActivityLogsSourceDestinationEventHubs contains properties of an Event Hubs namespace to use as intermediate destination for events.</p> </p>    Field Description      <code>namespaceID</code>   AzureResourceID     <p>Resource ID of the Event Hubs namespace.</p> <p>The expected format is /subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.EventHub/namespaces/{namespaceName}</p>     <code>hubName</code>  string    (Optional) <p>Name of the Event Hubs instance within the selected namespace. If omitted, Azure automatically creates an Event Hub with the name \u2018insights-activity-logs\u2019 inside the selected namespace.</p>     <code>sasPolicy</code>  string    (Optional) <p>Name of a SAS policy with Manage permissions inside the Event Hubs namespace referenced in the EventHubID field.</p> <p>Defaults to \u201cRootManageSharedAccessKey\u201d.</p> <p>References: * https://docs.microsoft.com/en-us/rest/api/eventhub/2017-04-01/authorization%20rules%20-%20namespaces/getauthorizationrule * https://docs.microsoft.com/en-us/azure/event-hubs/authorize-access-shared-access-signature</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AzureActivityLogsSourceDestinationEventHubs"},{"title":"AzureActivityLogsSourceSpec","text":"<p> (Appears on: AzureActivityLogsSource) </p> <p> <p>AzureActivityLogsSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>subscriptionID</code>  string    <p>The ID of the Azure subscription which activity logs to subscribe to.</p>     <code>destination</code>   AzureActivityLogsSourceDestination     <p>The intermediate destination of activity logs, before they are retrieved by this event source.</p>     <code>categories</code>  []string    (Optional) <p>Categories of Activity Logs to collect.</p> <p>All available categories are selected when this attribute is empty. https://docs.microsoft.com/en-us/azure/azure-monitor/platform/activity-log-schema#categories</p>     <code>auth</code>   AzureAuth     <p>Authentication method to interact with the Azure Monitor REST API. This event source only supports the ServicePrincipal authentication.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AzureActivityLogsSourceSpec"},{"title":"AzureActivityLogsSourceStatus","text":"<p> (Appears on: AzureActivityLogsSource) </p> <p> <p>AzureActivityLogsSourceStatus defines the observed state of the event source.</p> </p>    Field Description      <code>Status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status     <p> (Members of <code>Status</code> are embedded into this type.) </p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AzureActivityLogsSourceStatus"},{"title":"AzureAuth","text":"<p> (Appears on: AzureActivityLogsSourceSpec,  AzureBlobStorageSourceSpec,  AzureEventGridSourceSpec,  AzureEventHubSourceSpec,  AzureIOTHubSourceSpec,  AzureServiceBusQueueSourceSpec,  AzureServiceBusTopicSourceSpec) </p> <p> <p>AzureAuth contains multiple authentication methods for Azure services.</p> </p>    Field Description      <code>servicePrincipal</code>   AzureServicePrincipal     <p>Service principals provide a way to create a non-interactive account associated with your identity to which you grant only the privileges your app needs to run. See https://docs.microsoft.com/en-us/azure/active-directory/develop/app-objects-and-service-principals</p>     <code>sasToken</code>   AzureSASToken     <p>A shared access signature (SAS) provides secure delegated access to resources in a storage account. See https://docs.microsoft.com/en-us/azure/storage/common/storage-sas-overview</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AzureAuth"},{"title":"AzureBlobStorageSourceSpec","text":"<p> (Appears on: AzureBlobStorageSource) </p> <p> <p>AzureBlobStorageSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>storageAccountID</code>   AzureResourceID     <p>Resource ID of the Storage Account to receive events for.</p> <p>Format: /subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.Storage/storageAccounts/{storageAccountName}</p> <p>Besides the Storage Account name itself, the resource ID contains the subscription ID and resource group name which all together uniquely identify the Storage Account within Azure.</p>     <code>eventTypes</code>  []string    (Optional) <p>Types of events to subscribe to.</p> <p>The list of available event types can be found at https://docs.microsoft.com/en-us/azure/event-grid/event-schema-blob-storage</p> <p>When this attribute is not set, the source automatically subscribes to the following event types: - Microsoft.Storage.BlobCreated - Microsoft.Storage.BlobDeleted</p>     <code>endpoint</code>   AzureEventGridSourceEndpoint     <p>The intermediate destination of events subscribed via Event Grid, before they are retrieved by this event source.</p>     <code>auth</code>   AzureAuth     <p>Authentication method to interact with the Azure REST API. This event source only supports the ServicePrincipal authentication.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AzureBlobStorageSourceSpec"},{"title":"AzureBlobStorageSourceStatus","text":"<p> (Appears on: AzureBlobStorageSource) </p> <p> <p>AzureBlobStorageSourceStatus defines the observed state of the event source.</p> </p>    Field Description      <code>Status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status     <p> (Members of <code>Status</code> are embedded into this type.) </p>     <code>eventHubID</code>   AzureResourceID     <p>Resource ID of the Event Hubs instance that is currently receiving events from the Azure Event Grid subscription.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AzureBlobStorageSourceStatus"},{"title":"AzureEventGridSourceDestinationEventHubs","text":"<p> (Appears on: AzureEventGridSourceEndpoint) </p> <p> <p>AzureEventGridSourceDestinationEventHubs contains properties of an Event Hubs namespace to use as intermediate destination for events.</p> </p>    Field Description      <code>namespaceID</code>   AzureResourceID     <p>Resource ID of the Event Hubs namespace.</p> <p>The expected format is /subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.EventHub/namespaces/{namespaceName}</p>     <code>hubName</code>  string    (Optional) <p>Name of the Event Hubs instance within the selected namespace. If omitted, an Event Hubs instance is created on behalf of the user.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AzureEventGridSourceDestinationEventHubs"},{"title":"AzureEventGridSourceEndpoint","text":"<p> (Appears on: AzureBlobStorageSourceSpec,  AzureEventGridSourceSpec) </p> <p> <p>AzureEventGridSourceEndpoint contains possible intermediate destinations for events.</p> </p>    Field Description      <code>eventHubs</code>   AzureEventGridSourceDestinationEventHubs","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AzureEventGridSourceEndpoint"},{"title":"AzureEventGridSourceSpec","text":"<p> (Appears on: AzureEventGridSource) </p> <p> <p>AzureEventGridSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>scope</code>   AzureResourceID     <p>The resource ID the event subscription applies to.</p> <p>Can be - an Azure subscription: /subscriptions/{subscriptionId} - a resource group: /subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName} - a top-level resource from a resource provider (including Event Grid topic): /subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/{resourceProviderNamespace}/{resourceType}/{resourceName}</p>     <code>eventTypes</code>  []string    (Optional) <p>Types of events to subscribe to.</p> <p>If not specified, Azure automatically selects all available event types for the provided Scope.</p> <p>For a list of all available event types, please refer to the list of Azure services that support system topics at https://docs.microsoft.com/en-us/azure/event-grid/system-topics</p>     <code>endpoint</code>   AzureEventGridSourceEndpoint     <p>The intermediate destination of events subscribed via Event Grid, before they are retrieved by this event source.</p>     <code>auth</code>   AzureAuth     <p>Authentication method to interact with the Azure REST API. This event source only supports the ServicePrincipal authentication.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AzureEventGridSourceSpec"},{"title":"AzureEventGridSourceStatus","text":"<p> (Appears on: AzureEventGridSource) </p> <p> <p>AzureEventGridSourceStatus defines the observed state of the event source.</p> </p>    Field Description      <code>Status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status     <p> (Members of <code>Status</code> are embedded into this type.) </p>     <code>eventSubscriptionID</code>   AzureResourceID     <p>Resource ID of the Event Grid subscription that is currently registered for the user-provided scope.</p>     <code>eventHubID</code>   AzureResourceID     <p>Resource ID of the Event Hubs instance that is currently receiving events from the Azure Event Grid subscription.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AzureEventGridSourceStatus"},{"title":"AzureEventHubSourceSpec","text":"<p> (Appears on: AzureEventHubSource) </p> <p> <p>AzureEventHubSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>eventHubID</code>   AzureResourceID     <p>Resource ID of the Event Hubs instance.</p> <p>Expected format: - /subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.EventHub/namespaces/{namespaceName}/eventhubs/{eventHubName}</p>     <code>auth</code>   AzureAuth     <p>Authentication method to interact with the Azure Event Hubs API.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AzureEventHubSourceSpec"},{"title":"AzureIOTHubSourceSpec","text":"<p> (Appears on: AzureIOTHubSource) </p> <p> <p>AzureIOTHubSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>auth</code>   AzureAuth     <p>AzureAuth contains multiple authentication methods for Azure services.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AzureIOTHubSourceSpec"},{"title":"AzureQueueStorageSourceSpec","text":"<p> (Appears on: AzureQueueStorageSource) </p> <p> <p>AzureQueueStorageSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>accountName</code>  string        <code>queueName</code>  string        <code>accountKey</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AzureQueueStorageSourceSpec"},{"title":"AzureResourceID","text":"<p> (Appears on: AzureActivityLogsSourceDestinationEventHubs,  AzureBlobStorageSourceSpec,  AzureBlobStorageSourceStatus,  AzureEventGridSourceDestinationEventHubs,  AzureEventGridSourceSpec,  AzureEventGridSourceStatus,  AzureEventHubSourceSpec,  AzureServiceBusQueueSourceSpec,  AzureServiceBusTopicSourceSpec,  AzureServiceBusTopicSourceStatus) </p> <p> <p>AzureResourceID represents a resource ID for an Azure resource.</p> </p>    Field Description      <code>SubscriptionID</code>  string        <code>ResourceGroup</code>  string        <code>ResourceProvider</code>  string        <code>Namespace</code>  string        <code>ResourceType</code>  string        <code>ResourceName</code>  string        <code>SubResourceType</code>  string        <code>SubResourceName</code>  string","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AzureResourceID"},{"title":"AzureSASToken","text":"<p> (Appears on: AzureAuth) </p> <p> <p>AzureSASToken represents an Azure SAS token.</p> </p>    Field Description      <code>keyName</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>keyValue</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>connectionString</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AzureSASToken"},{"title":"AzureServiceBusQueueSourceSpec","text":"<p> (Appears on: AzureServiceBusQueueSource) </p> <p> <p>AzureServiceBusQueueSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>queueID</code>   AzureResourceID     <p>The resource ID the Service Bus Queue to subscribe to.</p> <p>Expected format: - /subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.ServiceBus/namespaces/{namespaceName}/queues/{queueName}</p>     <code>auth</code>   AzureAuth     <p>Authentication method to interact with Azure Service Bus.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AzureServiceBusQueueSourceSpec"},{"title":"AzureServiceBusTopicSourceSpec","text":"<p> (Appears on: AzureServiceBusTopicSource) </p> <p> <p>AzureServiceBusTopicSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>topicID</code>   AzureResourceID     <p>The resource ID the Service Bus Topic to subscribe to.</p> <p>Expected format: - /subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.ServiceBus/namespaces/{namespaceName}/topics/{topicName}</p>     <code>auth</code>   AzureAuth     <p>Authentication method to interact with the Azure REST API. This event source only supports the ServicePrincipal authentication.</p>     <code>webSocketsEnable</code>  bool    (Optional) <p>WebSocketsEnable</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AzureServiceBusTopicSourceSpec"},{"title":"AzureServiceBusTopicSourceStatus","text":"<p> (Appears on: AzureServiceBusTopicSource) </p> <p> <p>AzureServiceBusTopicSourceStatus defines the observed state of the event source.</p> </p>    Field Description      <code>Status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status     <p> (Members of <code>Status</code> are embedded into this type.) </p>     <code>subscriptionID</code>   AzureResourceID     <p>Resource ID of the Service Bus Subscription that is currently used by the event source for consuming events from the configured Service Bus Topic.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AzureServiceBusTopicSourceStatus"},{"title":"AzureServicePrincipal","text":"<p> (Appears on: AzureAuth) </p> <p> <p>AzureServicePrincipal represents an AAD Service Principal.</p> </p>    Field Description      <code>tenantID</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>clientID</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>clientSecret</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField","location":"apis/sources/#sources.triggermesh.io/v1alpha1.AzureServicePrincipal"},{"title":"CloudEventsSourceSpec","text":"<p> (Appears on: CloudEventsSource) </p> <p> <p>CloudEventsSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>credentials</code>   HTTPCredentials     (Optional) <p>Credentials to connect to this source.</p>     <code>path</code>  string    (Optional) <p>Path under which requests are accepted.</p>     <code>rateLimiter</code>   RateLimiter     (Optional) <p>RateLimiter for incoming events per adapter instance. A single CloudEventsSource object can create multiple adapter instances, the rate limiting configuration being applied to each of them individually.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.CloudEventsSourceSpec"},{"title":"Credentials","text":"<p> (Appears on: IBMMQSourceSpec) </p> <p> <p>Credentials holds the auth details.</p> </p>    Field Description      <code>username</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>password</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>tls</code>   TLSSpec","location":"apis/sources/#sources.triggermesh.io/v1alpha1.Credentials"},{"title":"Delivery","text":"<p> (Appears on: IBMMQSourceSpec) </p> <p> <p>Delivery defines the source\u2019s message delivery behavior.</p> </p>    Field Description      <code>deadLetterQueue</code>  string        <code>retry</code>  int        <code>deadLetterQueueManager</code>  string    <p>currently not used</p>     <code>backoffDelay</code>  int","location":"apis/sources/#sources.triggermesh.io/v1alpha1.Delivery"},{"title":"GCloudIoTResourceName","text":"<p> (Appears on: GoogleCloudIoTSourceSpec) </p> <p> <p>GCloudIoTResourceName represents a fully qualified IoT resource name, as described at https://pkg.go.dev/google.golang.org/api/cloudiot/v1#DeviceRegistry.Name</p> <p>Examples of such resource names include: - projects/{project_name}/locations/{location_name}/registries/{registry_name}</p> </p>    Field Description      <code>Project</code>  string        <code>Location</code>  string        <code>Collection</code>  string        <code>Resource</code>  string","location":"apis/sources/#sources.triggermesh.io/v1alpha1.GCloudIoTResourceName"},{"title":"GCloudResourceName","text":"<p> (Appears on: GoogleCloudAuditLogsSourceStatus,  GoogleCloudBillingSourceStatus,  GoogleCloudIoTSourceStatus,  GoogleCloudPubSubSourceSpec,  GoogleCloudPubSubSourceStatus,  GoogleCloudSourcePubSubSpec,  GoogleCloudSourceRepositoriesSourceSpec,  GoogleCloudSourceRepositoriesSourceStatus,  GoogleCloudStorageSourceStatus) </p> <p> <p>GCloudResourceName represents a fully qualified resource name, as described at https://cloud.google.com/apis/design/resource_names</p> <p>Examples of such resource names include: - projects/{project_name}/topics/{topic_name} - projects/{project_name}/repos/{repo_name} - projects/{project_name}/subscriptions/{subscription_name}</p> </p>    Field Description      <code>Project</code>  string        <code>Collection</code>  string        <code>Resource</code>  string","location":"apis/sources/#sources.triggermesh.io/v1alpha1.GCloudResourceName"},{"title":"GoogleCloudAuditLogsSourceSpec","text":"<p> (Appears on: GoogleCloudAuditLogsSource) </p> <p> <p>GoogleCloudAuditLogsSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>serviceName</code>  string    <p>The GCP service this instance should source audit logs from. Required. example: compute.googleapis.com</p>     <code>methodName</code>  string    <p>The name of the service method or operation. For API calls, this should be the name of the API method. Required. beta.compute.instances.insert</p>     <code>resourceName</code>  string    <p>The resource or collection that is the target of the operation. The name is a scheme-less URI, not including the API service name. example: \u201cprojects/PROJECT_ID/zones/us-central1-a/instances\u201d</p>     <code>pubsub</code>   GoogleCloudSourcePubSubSpec     <p>Settings related to the Pub/Sub resources associated with the Audit Logs event sink.</p>     <code>serviceAccountKey</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     <p>Service account key in JSON format. https://cloud.google.com/iam/docs/creating-managing-service-account-keys</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.GoogleCloudAuditLogsSourceSpec"},{"title":"GoogleCloudAuditLogsSourceStatus","text":"<p> (Appears on: GoogleCloudAuditLogsSource) </p> <p> <p>GoogleCloudAuditLogsSourceStatus defines the observed state of the event source.</p> </p>    Field Description      <code>Status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status     <p> (Members of <code>Status</code> are embedded into this type.) </p>     <code>auditLogsSink</code>  string    <p>ID of the AuditLogSink used to publish audit log messages.</p>     <code>topic</code>   GCloudResourceName     <p>Resource name of the target Pub/Sub topic.</p>     <code>subscription</code>   GCloudResourceName     <p>Resource name of the managed Pub/Sub subscription associated with the managed topic.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.GoogleCloudAuditLogsSourceStatus"},{"title":"GoogleCloudBillingSourceSpec","text":"<p> (Appears on: GoogleCloudBillingSource) </p> <p> <p>GoogleCloudBillingSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>billingAccountId</code>  string    <p>The identifier for the Cloud Billing account owning the budget.</p>     <code>budgetId</code>  string    <p>The identifier for the Cloud Billing budget. You can locate the budget\u2019s ID in your budget under Manage notifications. The ID is displayed after you select Connect a Pub/Sub topic to this budget.</p>     <code>pubsub</code>   GoogleCloudSourcePubSubSpec     <p>Settings related to the Pub/Sub resources associated with the Billing budget event sink.</p>     <code>serviceAccountKey</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     <p>Service account key in JSON format. https://cloud.google.com/iam/docs/creating-managing-service-account-keys</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.GoogleCloudBillingSourceSpec"},{"title":"GoogleCloudBillingSourceStatus","text":"<p> (Appears on: GoogleCloudBillingSource) </p> <p> <p>GoogleCloudBillingSourceStatus defines the observed state of the event source.</p> </p>    Field Description      <code>Status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status     <p> (Members of <code>Status</code> are embedded into this type.) </p>     <code>topic</code>   GCloudResourceName     <p>Resource name of the target Pub/Sub topic.</p>     <code>subscription</code>   GCloudResourceName     <p>Resource name of the managed Pub/Sub subscription associated with the managed topic.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.GoogleCloudBillingSourceStatus"},{"title":"GoogleCloudIoTSourceSpec","text":"<p> (Appears on: GoogleCloudIoTSource) </p> <p> <p>GoogleCloudIoTSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>registry</code>   GCloudIoTResourceName     <p>Resource name of the Cloud IoT Registry to receive messages from.</p>     <code>pubsub</code>   GoogleCloudSourcePubSubSpec     <p>Settings related to the Pub/Sub resources associated with the Cloud IoT Registry.</p>     <code>serviceAccountKey</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     <p>Service account key in JSON format. https://cloud.google.com/iam/docs/creating-managing-service-account-keys</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.GoogleCloudIoTSourceSpec"},{"title":"GoogleCloudIoTSourceStatus","text":"<p> (Appears on: GoogleCloudIoTSource) </p> <p> <p>GoogleCloudIoTSourceStatus defines the observed state of the event source.</p> </p>    Field Description      <code>Status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status     <p> (Members of <code>Status</code> are embedded into this type.) </p>     <code>topic</code>   GCloudResourceName     <p>Resource name of the target Pub/Sub topic.</p>     <code>subscription</code>   GCloudResourceName     <p>Resource name of the managed Pub/Sub subscription associated with the managed topic.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.GoogleCloudIoTSourceStatus"},{"title":"GoogleCloudPubSubSourceSpec","text":"<p> (Appears on: GoogleCloudPubSubSource) </p> <p> <p>GoogleCloudPubSubSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>topic</code>   GCloudResourceName     <p>Full resource name of the Pub/Sub topic to subscribe to, in the format \u201cprojects/{project_name}/topics/{topic_name}\u201d.</p>     <code>subscriptionID</code>  string    (Optional) <p>ID of the subscription to use to pull messages from the topic.</p> <p>If supplied, this subscription must 1) exist and 2) belong to the provided topic. Otherwise, a pull subscription to that topic is created on behalf of the user.</p>     <code>serviceAccountKey</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     <p>Service account key in JSON format. https://cloud.google.com/iam/docs/creating-managing-service-account-keys</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.GoogleCloudPubSubSourceSpec"},{"title":"GoogleCloudPubSubSourceStatus","text":"<p> (Appears on: GoogleCloudPubSubSource) </p> <p> <p>GoogleCloudPubSubSourceStatus defines the observed state of the event source.</p> </p>    Field Description      <code>Status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status     <p> (Members of <code>Status</code> are embedded into this type.) </p>     <code>subscription</code>   GCloudResourceName","location":"apis/sources/#sources.triggermesh.io/v1alpha1.GoogleCloudPubSubSourceStatus"},{"title":"GoogleCloudSourcePubSubSpec","text":"<p> (Appears on: GoogleCloudAuditLogsSourceSpec,  GoogleCloudBillingSourceSpec,  GoogleCloudIoTSourceSpec,  GoogleCloudSourceRepositoriesSourceSpec,  GoogleCloudStorageSourceSpec) </p> <p> <p>GoogleCloudSourcePubSubSpec defines the attributes related to the configuration of Pub/Sub resources.</p> </p>    Field Description      <code>topic</code>   GCloudResourceName     (Optional) <p>Full resource name of the Pub/Sub topic where messages/notifications originating from the configured Google Cloud resource are sent to, before being retrieved by this event source. If not supplied, a topic is created on behalf of the user, in the GCP project referenced by the Project attribute.</p> <p>The expected format is described at https://cloud.google.com/pubsub/docs/admin#resource_names: \u201cprojects/{project_name}/topics/{topic_name}\u201d</p>     <code>project</code>  string    (Optional) <p>Name of the GCP project where Pub/Sub resources associated with the configured Google Cloud resource are to be created.</p> <p>Mutually exclusive with Topic which, if supplied, already contains the project name.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.GoogleCloudSourcePubSubSpec"},{"title":"GoogleCloudSourceRepositoriesSourceSpec","text":"<p> (Appears on: GoogleCloudSourceRepositoriesSource) </p> <p> <p>GoogleCloudSourceRepositoriesSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>repository</code>   GCloudResourceName     <p>Name of the Cloud repo to receive notifications from.</p>     <code>pubsub</code>   GoogleCloudSourcePubSubSpec     <p>Settings related to the Pub/Sub resources associated with the repo events.</p>     <code>publishServiceAccount</code>  string    (Optional) <p>Email address of the service account used for publishing notifications to Pub/Sub. This service account needs to be in the same project as the repo, and to have the \u2018pubsub.topics.publish\u2019 IAM permission associated with it. It can (but doesn\u2019t have to) be the same service account as the \u2018ServiceAccountKey\u2019 attribute.</p> <p>If unspecified, it defaults to the Compute Engine default service account.</p>     <code>serviceAccountKey</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     <p>Service account key in JSON format. https://cloud.google.com/iam/docs/creating-managing-service-account-keys</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.GoogleCloudSourceRepositoriesSourceSpec"},{"title":"GoogleCloudSourceRepositoriesSourceStatus","text":"<p> (Appears on: GoogleCloudSourceRepositoriesSource) </p> <p> <p>GoogleCloudSourceRepositoriesSourceStatus defines the observed state of the event source.</p> </p>    Field Description      <code>Status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status     <p> (Members of <code>Status</code> are embedded into this type.) </p>     <code>topic</code>   GCloudResourceName     <p>Resource name of the target Pub/Sub topic.</p>     <code>subscription</code>   GCloudResourceName     <p>Resource name of the managed Pub/Sub subscription associated with the managed topic.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.GoogleCloudSourceRepositoriesSourceStatus"},{"title":"GoogleCloudStorageSourceSpec","text":"<p> (Appears on: GoogleCloudStorageSource) </p> <p> <p>GoogleCloudStorageSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>bucket</code>  string    <p>Name of the Cloud Storage bucket to receive change notifications from.</p>     <code>pubsub</code>   GoogleCloudSourcePubSubSpec     <p>Settings related to the Pub/Sub resources associated with the bucket.</p>     <code>eventTypes</code>  []string    (Optional) <p>Types of events to subscribe to.</p> <p>The list of available event types can be found at https://cloud.google.com/storage/docs/pubsub-notifications#events</p> <p>All types are selected when this attribute is not set.</p>     <code>serviceAccountKey</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     <p>Service account key in JSON format. https://cloud.google.com/iam/docs/creating-managing-service-account-keys</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.GoogleCloudStorageSourceSpec"},{"title":"GoogleCloudStorageSourceStatus","text":"<p> (Appears on: GoogleCloudStorageSource) </p> <p> <p>GoogleCloudStorageSourceStatus defines the observed state of the event source.</p> </p>    Field Description      <code>Status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status     <p> (Members of <code>Status</code> are embedded into this type.) </p>     <code>notificationID</code>  string    <p>ID of the managed Cloud Storage bucket notification configuration.</p>     <code>topic</code>   GCloudResourceName     <p>Resource name of the target Pub/Sub topic.</p>     <code>subscription</code>   GCloudResourceName     <p>Resource name of the managed Pub/Sub subscription associated with the managed topic.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.GoogleCloudStorageSourceStatus"},{"title":"HTTPBasicAuth","text":"<p> (Appears on: HTTPCredentials) </p> <p> <p>HTTPBasicAuth credentials.</p> </p>    Field Description      <code>username</code>  string        <code>password</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField","location":"apis/sources/#sources.triggermesh.io/v1alpha1.HTTPBasicAuth"},{"title":"HTTPCredentials","text":"<p> (Appears on: CloudEventsSourceSpec) </p> <p> <p>HTTPCredentials to be used when receiving requests.</p> </p>    Field Description      <code>basicAuths</code>   []HTTPBasicAuth","location":"apis/sources/#sources.triggermesh.io/v1alpha1.HTTPCredentials"},{"title":"HTTPPollerSourceSpec","text":"<p> (Appears on: HTTPPollerSource) </p> <p> <p>HTTPPollerSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p> <p>inherits duck/v1 SourceSpec, which currently provides: * Sink - a reference to an object that will resolve to a domain name or a URI directly to use as the sink. * CloudEventOverrides - defines overrides to control the output format and modifications of the event sent to the sink.</p>     <code>eventType</code>  string    <p>Value of the CloudEvents \u2018type\u2019 attribute to set on ingested events. https://github.com/cloudevents/spec/blob/v1.0.1/spec.md#type</p>     <code>eventSource</code>  string    (Optional) <p>Value of the CloudEvents \u2018source\u2019 attribute to set on ingested events. https://github.com/cloudevents/spec/blob/v1.0.1/spec.md#source-1</p>     <code>endpoint</code>   knative.dev/pkg/apis.URL     <p>HTTP/S URL of the endpoint to poll data from.</p>     <code>method</code>  string    <p>HTTP request method to use in requests to the specified \u2018endpoint\u2019. https://developer.mozilla.org/en-US/docs/Web/HTTP/Methods</p>     <code>skipVerify</code>  bool    (Optional) <p>Controls whether the HTTP client verifies the server\u2019s certificate chain and host name when communicating over TLS.</p>     <code>caCertificate</code>  string    (Optional) <p>CA certificate in X.509 format the HTTP client should use to verify the identity of remote servers when communicating over TLS.</p>     <code>basicAuthUsername</code>  string    (Optional) <p>User name to set in HTTP requests that require HTTP Basic authentication.</p>     <code>basicAuthPassword</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     (Optional) <p>Password to set in HTTP requests that require HTTP Basic authentication.</p>     <code>headers</code>  map[string]string    (Optional) <p>HTTP headers to include in HTTP requests.</p>     <code>interval</code>   github.com/triggermesh/triggermesh/pkg/apis.Duration     <p>Duration which defines how often the HTTP/S endpoint should be polled. Expressed as a duration string, which format is documented at https://pkg.go.dev/time#ParseDuration.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.HTTPPollerSourceSpec"},{"title":"IBMMQSourceSpec","text":"<p> (Appears on: IBMMQSource) </p> <p> <p>IBMMQSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>connectionName</code>  string        <code>queueManager</code>  string        <code>queueName</code>  string        <code>channelName</code>  string        <code>delivery</code>   Delivery         <code>credentials</code>   Credentials         <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.IBMMQSourceSpec"},{"title":"KafkaSourceAuth","text":"<p> (Appears on: KafkaSourceSpec) </p> <p> <p>KafkaSourceAuth contains Authentication method used to interact with Kafka.</p> </p>    Field Description      <code>kerberos</code>   KafkaSourceKerberos         <code>tls</code>   KafkaSourceTLSAuth         <code>saslEnable</code>  bool    <p>SASL Enable</p>     <code>tlsEnable</code>  bool    (Optional) <p>TLS Enable</p>     <code>securityMechanism</code>  string    (Optional) <p>SecurityMechanisms holds the assignment of the specific SASL mechanisms.</p>     <code>username</code>  string    (Optional) <p>Username Kafka account User</p>     <code>password</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     (Optional) <p>Password Kafka account Password</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.KafkaSourceAuth"},{"title":"KafkaSourceKerberos","text":"<p> (Appears on: KafkaSourceAuth) </p> <p> <p>KafkaSourceKerberos contains kerberos credentials.</p> </p>    Field Description      <code>username</code>  string        <code>password</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>realm</code>  string        <code>serviceName</code>  string        <code>configPath</code>  string        <code>keytabPath</code>  string        <code>config</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>keytab</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField","location":"apis/sources/#sources.triggermesh.io/v1alpha1.KafkaSourceKerberos"},{"title":"KafkaSourceSpec","text":"<p> (Appears on: KafkaSource) </p> <p> <p>KafkaSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>bootstrapServers</code>  []string    <p>BootstrapServers holds the name of the Kafka Bootstrap server.</p>     <code>topics</code>  []string    <p>Topics holds the name of the Kafka Topics.</p>     <code>groupID</code>  string    <p>GroupID holds the name of the Kafka Group ID.</p>     <code>auth</code>   KafkaSourceAuth     <p>Auth contains Authentication method used to interact with Kafka.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.KafkaSourceSpec"},{"title":"KafkaSourceTLSAuth","text":"<p> (Appears on: KafkaSourceAuth) </p> <p> <p>KafkaSourceTLSAuth contains kerberos credentials.</p> </p>    Field Description      <code>ca</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>clientCert</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>clientKey</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>skipVerify</code>  bool","location":"apis/sources/#sources.triggermesh.io/v1alpha1.KafkaSourceTLSAuth"},{"title":"Keystore","text":"<p> (Appears on: TLSSpec) </p> <p> <p>Keystore represents Key Database components.</p> </p>    Field Description      <code>keyDatabase</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>passwordStash</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField","location":"apis/sources/#sources.triggermesh.io/v1alpha1.Keystore"},{"title":"OCIMetrics","text":"<p> (Appears on: OCIMetricsSourceSpec) </p> <p> <p>OCIMetrics represents OCI metrics structure.</p> </p>    Field Description      <code>name</code>  string    <p>Human description for the metrics entry</p>     <code>metricsNamespace</code>  string    <p>Namespace for the query metric to use</p>     <code>metricsQuery</code>  string    <p>OCI Metrics Query See https://docs.cloud.oracle.com/en-us/iaas/api/#/en/monitoring/20180401/MetricData</p>     <code>oracleCompartment</code>  string    <p>Oracle Compartment OCID</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.OCIMetrics"},{"title":"OCIMetricsSourceSpec","text":"<p> (Appears on: OCIMetricsSource) </p> <p> <p>OCIMetricsSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p> <p>inherits duck/v1 SourceSpec, which currently provides: * Sink - a reference to an object that will resolve to a domain name or a URI directly to use as the sink. * CloudEventOverrides - defines overrides to control the output format and modifications of the event sent to the sink.</p>     <code>oracleApiPrivateKey</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     <p>Oracle User API private key</p>     <code>oracleApiPrivateKeyPassphrase</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     <p>Oracle User API private key passphrase</p>     <code>oracleApiPrivateKeyFingerprint</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     <p>Oracle User API cert fingerprint</p>     <code>oracleTenancy</code>  string    <p>Oracle Tenancy OCID</p>     <code>oracleUser</code>  string    <p>Oracle User OCID associated with the API key</p>     <code>oracleRegion</code>  string    <p>Oracle Cloud Region</p>     <code>metricsPollingFrequency</code>  string    (Optional) <p>OCI Metrics Polling Frequency</p>     <code>metrics</code>   []OCIMetrics     <p>Array of metrics</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.OCIMetricsSourceSpec"},{"title":"RateLimiter","text":"<p> (Appears on: CloudEventsSourceSpec) </p> <p> <p>RateLimiter parameters.</p> </p>    Field Description      <code>requestsPerSecond</code>  int    <p>RequestsPerSecond is used to limit the number of requests that a single instance of the CloudEventsSource adapter can accept.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.RateLimiter"},{"title":"SalesforceAuth","text":"<p> (Appears on: SalesforceSourceSpec) </p> <p> <p>SalesforceAuth contains Salesforce credentials.</p> </p>    Field Description      <code>clientID</code>  string        <code>server</code>  string        <code>user</code>  string        <code>certKey</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField","location":"apis/sources/#sources.triggermesh.io/v1alpha1.SalesforceAuth"},{"title":"SalesforceSourceSpec","text":"<p> (Appears on: SalesforceSource) </p> <p> <p>SalesforceSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>auth</code>   SalesforceAuth     <p>Authentication method to interact with the Salesforce API.</p>     <code>apiVersion</code>  string    (Optional) <p>APIVersion at Salesforce.</p>     <code>subscription</code>   SalesforceSubscription     <p>Subscription to a Salesforce channel</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.SalesforceSourceSpec"},{"title":"SalesforceSubscription","text":"<p> (Appears on: SalesforceSourceSpec) </p> <p> <p>SalesforceSubscription to connect to.</p> </p>    Field Description      <code>channel</code>  string        <code>replayID</code>  int","location":"apis/sources/#sources.triggermesh.io/v1alpha1.SalesforceSubscription"},{"title":"SlackSourceSpec","text":"<p> (Appears on: SlackSource) </p> <p> <p>SlackSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p> <p>inherits duck/v1 SourceSpec, which currently provides: * Sink - a reference to an object that will resolve to a domain name or a URI directly to use as the sink. * CloudEventOverrides - defines overrides to control the output format and modifications of the event sent to the sink.</p>     <code>signingSecret</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     (Optional) <p>SigningSecret can be set to the value of Slack request signing secret to authenticate callbacks. See: https://api.slack.com/authentication/verifying-requests-from-slack</p>     <code>appID</code>  string    (Optional) <p>AppID identifies the Slack application generating this event. It helps identifying the App sourcing events when multiple Slack applications shared an endpoint. See: https://api.slack.com/events-api</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.SlackSourceSpec"},{"title":"TLSSpec","text":"<p> (Appears on: Credentials) </p> <p> <p>TLSSpec holds the IBM MQ TLS authentication parameters.</p> </p>    Field Description      <code>cipher</code>  string        <code>clientAuthRequired</code>  bool        <code>certLabel</code>  string        <code>keyRepository</code>   Keystore","location":"apis/sources/#sources.triggermesh.io/v1alpha1.TLSSpec"},{"title":"TwilioSourceSpec","text":"<p> (Appears on: TwilioSource) </p> <p> <p>TwilioSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.TwilioSourceSpec"},{"title":"WebhookEventExtensionAttributes","text":"<p> (Appears on: WebhookSourceSpec) </p> <p> <p>WebhookEventExtensionAttributes sets the policy for converting HTTP data into.</p> </p>    Field Description      <code>from</code>  []string    (Optional) <p>From informs HTTP elements that will be converted into CloudEvents attributes</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.WebhookEventExtensionAttributes"},{"title":"WebhookSourceSpec","text":"<p> (Appears on: WebhookSource) </p> <p> <p>WebhookSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p> <p>inherits duck/v1 SourceSpec, which currently provides: * Sink - a reference to an object that will resolve to a domain name or a URI directly to use as the sink. * CloudEventOverrides - defines overrides to control the output format and modifications of the event sent to the sink.</p>     <code>eventType</code>  string    <p>Value of the CloudEvents \u2018type\u2019 attribute to set on ingested events. https://github.com/cloudevents/spec/blob/v1.0.1/spec.md#type</p>     <code>eventSource</code>  string    (Optional) <p>Value of the CloudEvents \u2018source\u2019 attribute to set on ingested events. https://github.com/cloudevents/spec/blob/v1.0.1/spec.md#source-1</p>     <code>eventExtensionAttributes</code>   WebhookEventExtensionAttributes     (Optional) <p>Options to transform HTTP request data into CloudEvent extensions. https://github.com/cloudevents/spec/blob/main/cloudevents/spec.md#extension-context-attributes</p>     <code>basicAuthUsername</code>  string    (Optional) <p>User name HTTP clients must set to authenticate with the webhook using HTTP Basic authentication.</p>     <code>basicAuthPassword</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     (Optional) <p>Password HTTP clients must set to authenticate with the webhook using HTTP Basic authentication.</p>     <code>corsAllowOrigin</code>  string    (Optional) <p>Specifies the CORS Origin to use in pre-flight headers.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.WebhookSourceSpec"},{"title":"ZendeskSourceSpec","text":"<p> (Appears on: ZendeskSource) </p> <p> <p>ZendeskSourceSpec defines the desired state of the event source.</p> </p>    Field Description      <code>SourceSpec</code>   knative.dev/pkg/apis/duck/v1.SourceSpec     <p> (Members of <code>SourceSpec</code> are embedded into this type.) </p> <p>inherits duck/v1 SourceSpec, which currently provides: * Sink - a reference to an object that will resolve to a domain name or a URI directly to use as the sink. * CloudEventOverrides - defines overrides to control the output format and modifications of the event sent to the sink.</p>     <code>token</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     <p>Token identifies the API token used for creating the proper credentials to interface with Zendesk allowing the source to auto-register the webhook to authenticate callbacks.</p>     <code>email</code>  string    <p>Email identifies the email used for creating the proper credentials to interface with Zendesk allowing the source to auto-register the webhook to authenticate callbacks.</p>     <code>webhookPassword</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     <p>WebhookPassword used for basic authentication for events sent from Zendesk to the adapter.</p>     <code>webhookUsername</code>  string    <p>WebhookUsername used for basic authentication for events sent from Zendesk to the adapter.</p>     <code>subdomain</code>  string    <p>Subdomain identifies Zendesk subdomain</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.ZendeskSourceSpec"},{"title":"ZendeskSourceStatus","text":"<p> (Appears on: ZendeskSource) </p> <p> <p>ZendeskSourceStatus defines the observed state of the event source.</p> </p>    Field Description      <code>Status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status     <p> (Members of <code>Status</code> are embedded into this type.) </p>      <p> Generated with <code>gen-crd-api-reference-docs</code> on git commit <code>b22c2e53</code>. </p>","location":"apis/sources/#sources.triggermesh.io/v1alpha1.ZendeskSourceStatus"},{"title":"Targets","text":"<p>Package:</p> <ul> <li> targets.triggermesh.io/v1alpha1 </li> </ul>","location":"apis/targets/"},{"title":"targets.triggermesh.io/v1alpha1","text":"<p> <p>Package v1alpha1 contains API Schema definitions for the targets/v1alpha1 API group.</p> </p> <p>Resource Types:</p> <ul><li> AWSComprehendTarget </li><li> AWSDynamoDBTarget </li><li> AWSEventBridgeTarget </li><li> AWSKinesisTarget </li><li> AWSLambdaTarget </li><li> AWSS3Target </li><li> AWSSNSTarget </li><li> AWSSQSTarget </li><li> AlibabaOSSTarget </li><li> AzureEventHubsTarget </li><li> AzureSentinelTarget </li><li> CloudEventsTarget </li><li> ConfluentTarget </li><li> DatadogTarget </li><li> ElasticsearchTarget </li><li> GoogleCloudFirestoreTarget </li><li> GoogleCloudPubSubTarget </li><li> GoogleCloudStorageTarget </li><li> GoogleCloudWorkflowsTarget </li><li> GoogleSheetTarget </li><li> HTTPTarget </li><li> HasuraTarget </li><li> IBMMQTarget </li><li> InfraTarget </li><li> JiraTarget </li><li> KafkaTarget </li><li> LogzMetricsTarget </li><li> LogzTarget </li><li> OracleTarget </li><li> SalesforceTarget </li><li> SendGridTarget </li><li> SlackTarget </li><li> SplunkTarget </li><li> TektonTarget </li><li> TwilioTarget </li><li> UiPathTarget </li><li> ZendeskTarget </li></ul>","location":"apis/targets/#targets.triggermesh.io/v1alpha1"},{"title":"AWSComprehendTarget","text":"<p> <p>AWSComprehendTarget is the Schema for an AWS Comprehend Target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AWSComprehendTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AWSComprehendTargetSpec          <code>awsApiKey</code>   SecretValueFromSource     <p>AWS account Key.</p>     <code>awsApiSecret</code>   SecretValueFromSource     <p>AWS account secret key.</p>     <code>region</code>  string    <p>Region to use for calling into Comprehend API.</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets.</p>     <code>language</code>  string    <p>Language code to use to interact with Comprehend. The supported list can be found at: https://docs.aws.amazon.com/comprehend/latest/dg/supported-languages.html</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/targets/#targets.triggermesh.io/v1alpha1.AWSComprehendTarget"},{"title":"AWSDynamoDBTarget","text":"<p> <p>AWSDynamoDBTarget is the Schema for an AWS DynamoDB Target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AWSDynamoDBTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AWSDynamoDBTargetSpec          <code>awsApiKey</code>   SecretValueFromSource     <p>AWS account Key</p>     <code>awsApiSecret</code>   SecretValueFromSource     <p>AWS account secret key</p>     <code>arn</code>  string    <p>Table ARN https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazondynamodb.html#amazondynamodb-resources-for-iam-policies</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/targets/#targets.triggermesh.io/v1alpha1.AWSDynamoDBTarget"},{"title":"AWSEventBridgeTarget","text":"<p> <p>AWSEventBridgeTarget is the Schema for the event target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AWSEventBridgeTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AWSEventBridgeTargetSpec          <code>awsApiKey</code>   SecretValueFromSource     <p>AWS account Key</p>     <code>awsApiSecret</code>   SecretValueFromSource     <p>AWS account secret key</p>     <code>arn</code>  string    <p>Amazon Resource Name of the EventBridge Event Bus. https://docs.aws.amazon.com/service-authorization/latest/reference/list_amazoneventbridge.html</p>     <code>discardCloudEventContext</code>  bool    <p>Whether to omit CloudEvent context attributes in notifications sent to EventBridge. When this property is false (default), the entire CloudEvent payload is included. When this property is true, only the CloudEvent data is included.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/targets/#targets.triggermesh.io/v1alpha1.AWSEventBridgeTarget"},{"title":"AWSKinesisTarget","text":"<p> <p>AWSKinesisTarget is the Schema for an AWS Kinesis Target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AWSKinesisTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AWSKinesisTargetSpec          <code>awsApiKey</code>   SecretValueFromSource     <p>AWS account Key</p>     <code>awsApiSecret</code>   SecretValueFromSource     <p>AWS account secret key</p>     <code>arn</code>  string    <p>Amazon Resource Name of the Kinesis stream. https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazonkinesis.html#amazonkinesis-resources-for-iam-policies</p>     <code>partition</code>  string    <p>Kinesis Partition to publish the events to</p>     <code>discardCloudEventContext</code>  bool    <p>Whether to omit CloudEvent context attributes in records created in Kinesis. When this property is false (default), the entire CloudEvent payload is included. When this property is true, only the CloudEvent data is included.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/targets/#targets.triggermesh.io/v1alpha1.AWSKinesisTarget"},{"title":"AWSLambdaTarget","text":"<p> <p>AWSLambdaTarget is the Schema for an AWS Lambda Target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AWSLambdaTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AWSLambdaTargetSpec          <code>awsApiKey</code>   SecretValueFromSource     <p>AWS account Key</p>     <code>awsApiSecret</code>   SecretValueFromSource     <p>AWS account secret key</p>     <code>arn</code>  string    <p>Amazon Resource Name of the Lambda function. https://docs.aws.amazon.com/IAM/latest/UserGuide/list_awslambda.html#awslambda-resources-for-iam-policies</p>     <code>discardCloudEventContext</code>  bool    <p>Whether to omit CloudEvent context attributes in Lambda function calls. When this property is false (default), the entire CloudEvent payload is included. When this property is true, only the CloudEvent data is included.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/targets/#targets.triggermesh.io/v1alpha1.AWSLambdaTarget"},{"title":"AWSS3Target","text":"<p> <p>AWSS3Target is the Schema for an AWS s3 Target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AWSS3Target</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AWSS3TargetSpec          <code>awsApiKey</code>   SecretValueFromSource     <p>AWS account Key</p>     <code>awsApiSecret</code>   SecretValueFromSource     <p>AWS account secret key</p>     <code>arn</code>  string    <p>Amazon Resource Name of the S3 bucket. https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazons3.html#amazons3-resources-for-iam-policies</p>     <code>discardCloudEventContext</code>  bool    <p>Whether to omit CloudEvent context attributes in objects created in S3. When this property is false (default), the entire CloudEvent payload is included. When this property is true, only the CloudEvent data is included.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/targets/#targets.triggermesh.io/v1alpha1.AWSS3Target"},{"title":"AWSSNSTarget","text":"<p> <p>AWSSNSTarget is the Schema for the event target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AWSSNSTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AWSSNSTargetSpec          <code>awsApiKey</code>   SecretValueFromSource     <p>AWS account Key</p>     <code>awsApiSecret</code>   SecretValueFromSource     <p>AWS account secret key</p>     <code>arn</code>  string    <p>Amazon Resource Name of the SNS topic. https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazonsns.html#amazonsns-resources-for-iam-policies</p>     <code>discardCloudEventContext</code>  bool    <p>Whether to omit CloudEvent context attributes in notifications sent to SNS. When this property is false (default), the entire CloudEvent payload is included. When this property is true, only the CloudEvent data is included.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/targets/#targets.triggermesh.io/v1alpha1.AWSSNSTarget"},{"title":"AWSSQSTarget","text":"<p> <p>AWSSQSTarget is the Schema for an AWS SQS Target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AWSSQSTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AWSSQSTargetSpec          <code>awsApiKey</code>   SecretValueFromSource     <p>AWS account Key</p>     <code>awsApiSecret</code>   SecretValueFromSource     <p>AWS account secret key</p>     <code>arn</code>  string    <p>Amazon Resource Name of the SQS queue. https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazonsqs.html#amazonsqs-resources-for-iam-policies</p>     <code>messageGroupId</code>  string    (Optional) <p>Message Group ID is required for FIFO based queues, and is used to uniquely identify the event producer https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFO-queues-understanding-logic.html</p>     <code>discardCloudEventContext</code>  bool    <p>Whether to omit CloudEvent context attributes in messages sent to SQS. When this property is false (default), the entire CloudEvent payload is included. When this property is true, only the CloudEvent data is included.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/targets/#targets.triggermesh.io/v1alpha1.AWSSQSTarget"},{"title":"AlibabaOSSTarget","text":"<p> <p>AlibabaOSSTarget is the Schema for an Alibaba Object Storage Service Target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AlibabaOSSTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AlibabaOSSTargetSpec          <code>accessKeyID</code>   SecretValueFromSource     <p>Alibaba SDK access key id as registered. For more information on how to create an access key pair, please refer to https://www.alibabacloud.com/help/doc-detail/53045.htm?spm=a2c63.p38356.879954.9.23bc7d91ARN6Hy#task968.</p>     <code>accessKeySecret</code>   SecretValueFromSource     <p>Alibaba SDK access key secret as registered.</p>     <code>endpoint</code>  string    <p>The domain name used to access the OSS. For more information, please refer to the region and endpoint guide at https://www.alibabacloud.com/help/doc-detail/31837.htm?spm=a2c63.p38356.879954.8.23bc7d91ARN6Hy#concept-zt4-cvy-5db</p>     <code>bucket</code>  string    <p>The unique container to store objects in OSS.</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/targets/#targets.triggermesh.io/v1alpha1.AlibabaOSSTarget"},{"title":"AzureEventHubsTarget","text":"<p> <p>AzureEventHubsTarget is the Schema for an Alibaba Object Storage Service Target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AzureEventHubsTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AzureEventHubsTargetSpec          <code>auth</code>   AzureAuth     <p>Authentication method to interact with the Azure Event Hubs API.</p>     <code>eventHubID</code>   EventHubResourceID     <p>Resource ID of the Event Hubs instance.</p> <p>Expected format: - /subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.EventHub/namespaces/{namespaceName}/eventhubs/{eventHubName}</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>discardCloudEventContext</code>  bool        <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/targets/#targets.triggermesh.io/v1alpha1.AzureEventHubsTarget"},{"title":"AzureSentinelTarget","text":"<p> <p>AzureSentinelTarget is the Schema for an Azure Sentinel Target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>AzureSentinelTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   AzureSentinelTargetSpec          <code>subscriptionID</code>  string    <p>SubscriptionID refers to the Azure Subscription ID that the Azure Sentinel instance is associated with.</p>     <code>resourceGroup</code>  string    <p>ResourceGroup refers to the resource group where the Azure Sentinel instance is deployed.</p>     <code>workspace</code>  string    <p>Workspace refers to the workspace name in Azure Sentinel.</p>     <code>auth</code>   AzureAuth     <p>Authentication method to interact with the Azure Event Hubs API.</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/targets/#targets.triggermesh.io/v1alpha1.AzureSentinelTarget"},{"title":"CloudEventsTarget","text":"<p> <p>CloudEventsTarget is a gateway that produces received CloudEvents to a destination.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>CloudEventsTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   CloudEventsTargetSpec          <code>credentials</code>   CloudEventsCredentials     (Optional) <p>Credentials to connect to the remote endpoint.</p>     <code>path</code>  string    (Optional) <p>Path at the remote endpoint under which requests are accepted.</p>     <code>endpoint</code>   knative.dev/pkg/apis.URL     <p>Endpoint that accept CloudEvents.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>AdapterOverrides sets runtime parameters to the adapter instance.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/targets/#targets.triggermesh.io/v1alpha1.CloudEventsTarget"},{"title":"ConfluentTarget","text":"<p> <p>ConfluentTarget is the Schema for an ConfluentTarget.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>ConfluentTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   ConfluentTargetSpec          <code>username</code>  string    <p>SASLUsername Confluent account User</p>     <code>password</code>   SecretValueFromSource     <p>SASLPassword Confluent account Password</p>     <code>topic</code>  string    <p>Topic where messages are produced.</p>     <code>topicReplicationFactor</code>  int    (Optional) <p>TopicReplicationFactor is the number of replicas for the topic.</p>     <code>topicPartitions</code>  int    (Optional) <p>TopicPartitions is the number of partitions for the topic.</p>     <code>bootstrapServers</code>  []string    <p>BootstrapServers holds the name of the Kafka Bootstrap server.</p>     <code>securityProtocol</code>  string    <p>SecurityProtocol allows the user to set the security protocol</p>     <code>saslMechanism</code>  string    <p>SASLMechanisms all the assignment of specific SASL mechanisms.</p>     <code>discardCloudEventContext</code>  bool    <p>Whether to omit CloudEvent context attributes in messages sent to Kafka. When this property is false (default), the entire CloudEvent payload is included. When this property is true, only the CloudEvent data is included.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/targets/#targets.triggermesh.io/v1alpha1.ConfluentTarget"},{"title":"DatadogTarget","text":"<p> <p>DatadogTarget is the Schema for an HTTP Target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>DatadogTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   DatadogTargetSpec          <code>apiKey</code>   SecretValueFromSource     <p>DatadogApiKey represents how Datadog credentials should be provided in the secret</p>     <code>metricPrefix</code>  string    (Optional) <p>MetricPrefix is prepended to the name of the associated metrics.</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/targets/#targets.triggermesh.io/v1alpha1.DatadogTarget"},{"title":"ElasticsearchTarget","text":"<p> <p>ElasticsearchTarget is the Schema for an Elasticsearch Target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>ElasticsearchTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     (Optional) Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   ElasticsearchTargetSpec          <code>connection</code>   Connection     (Optional) <p>Connection information to elasticsearch.</p>     <code>indexName</code>  string    <p>IndexName to write to.</p>     <code>discardCloudEventContext</code>  bool    <p>Whether to omit CloudEvent context attributes in documents created in Elasticsearch. When this property is false (default), the entire CloudEvent payload is included. When this property is true, only the CloudEvent data is included.</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/targets/#targets.triggermesh.io/v1alpha1.ElasticsearchTarget"},{"title":"GoogleCloudFirestoreTarget","text":"<p> <p>GoogleCloudFirestoreTarget is the Schema for the GoogleCloudFirestore Target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>GoogleCloudFirestoreTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   GoogleCloudFirestoreTargetSpec          <code>credentialsJson</code>   SecretValueFromSource     <p>Credentials represents how Google Firestore credentials should be provided in the secret</p>     <code>defaultCollection</code>  string    <p>DefaultCollection sets a default Firestore collection to select from</p>     <code>projectID</code>  string    <p>ProjectID specifies the Google project ID</p>     <code>discardCloudEventContext</code>  bool    <p>Whether to omit CloudEvent context attributes in documents created in Firestore. When this property is false (default), the entire CloudEvent payload is included. When this property is true, only the CloudEvent data is included.</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/targets/#targets.triggermesh.io/v1alpha1.GoogleCloudFirestoreTarget"},{"title":"GoogleCloudPubSubTarget","text":"<p> <p>GoogleCloudPubSubTarget is the Schema the event target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>GoogleCloudPubSubTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   GoogleCloudPubSubTargetSpec          <code>topic</code>   GCloudResourceName     <p>Full resource name of the Pub/Sub topic to subscribe to, in the format \u201cprojects/{project_name}/topics/{topic_name}\u201d.</p>     <code>credentialsJson</code>   SecretValueFromSource     <p>Service account key in JSON format. https://cloud.google.com/iam/docs/creating-managing-service-account-keys</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>discardCloudEventContext</code>  bool    <p>DiscardCloudEventContext is the policy for how to handle the payload of the CloudEvent.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/targets/#targets.triggermesh.io/v1alpha1.GoogleCloudPubSubTarget"},{"title":"GoogleCloudStorageTarget","text":"<p> <p>GoogleCloudStorageTarget is the Schema for an Google Storage Target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>GoogleCloudStorageTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   GoogleCloudStorageTargetSpec          <code>credentialsJson</code>   SecretValueFromSource     <p>Credentials represents how Google Storage credentials should be provided in the secret</p>     <code>bucketName</code>  string    <p>BucketName specifies the Google Storage Bucket</p>     <code>discardCloudEventContext</code>  bool    <p>Whether to omit CloudEvent context attributes in objects created in Google Cloud Storage. When this property is false (default), the entire CloudEvent payload is included. When this property is true, only the CloudEvent data is included.</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/targets/#targets.triggermesh.io/v1alpha1.GoogleCloudStorageTarget"},{"title":"GoogleCloudWorkflowsTarget","text":"<p> <p>GoogleCloudWorkflowsTarget is the Schema for an Google Cloud Workflows Target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>GoogleCloudWorkflowsTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   GoogleCloudWorkflowsTargetSpec          <code>credentialsJson</code>   SecretValueFromSource     <p>GoogleCloudWorkflowsApiKey represents how GoogleCloudWorkflows credentials should be provided in the secret</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/targets/#targets.triggermesh.io/v1alpha1.GoogleCloudWorkflowsTarget"},{"title":"GoogleSheetTarget","text":"<p> <p>GoogleSheetTarget is the Schema for an GoogleSheet Target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>GoogleSheetTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   GoogleSheetTargetSpec          <code>googleServiceAccount</code>   SecretValueFromSource     <p>GoogleSheet credential JSON for auth</p>     <code>id</code>  string    <p>ID of Google a spreadsheet</p>     <code>defaultPrefix</code>  string    <p>DefaultPrefix is a pre-defined prefix for the individual sheets.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/targets/#targets.triggermesh.io/v1alpha1.GoogleSheetTarget"},{"title":"HTTPTarget","text":"<p> <p>HTTPTarget is the Schema for an HTTP Target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>HTTPTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   HTTPTargetSpec          <code>response</code>   HTTPEventResponse     <p>Response data to be used at replies.</p>     <code>endpoint</code>   knative.dev/pkg/apis.URL     <p>Endpoint to connect to.</p>     <code>method</code>  string    <p>Method to use at requests.</p>     <code>headers</code>  map[string]string    (Optional) <p>Headers to be included at HTTP requests</p>     <code>skipVerify</code>  bool    (Optional) <p>SkipVerify disables server certificate validation.</p>     <code>caCertificate</code>  string    (Optional) <p>CACertificate uses the CA certificate to verify the remote server certificate.</p>     <code>basicAuthUsername</code>  string    (Optional) <p>BasicAuthUsername used for basic authentication.</p>     <code>basicAuthPassword</code>   SecretValueFromSource     (Optional) <p>BasicAuthPassword used for basic authentication.</p>     <code>oauthClientID</code>  string    (Optional) <p>OAuthClientID used for OAuth2 authentication.</p>     <code>oauthClientSecret</code>   SecretValueFromSource     (Optional) <p>OAuthClientSecret used for OAuth2 authentication.</p>     <code>oauthTokenURL</code>  string    (Optional) <p>OAuthTokenURL used for OAuth2 authentication.</p>     <code>oauthScopes</code>  []string    (Optional) <p>OAuthScopes used for OAuth2 authentication.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/targets/#targets.triggermesh.io/v1alpha1.HTTPTarget"},{"title":"HasuraTarget","text":"<p> <p>HasuraTarget is the Schema for the event target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>HasuraTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   HasuraTargetSpec          <code>endpoint</code>  string    <p>The GraphQL server endpoint.</p>     <code>jwt</code>   SecretValueFromSource     (Optional) <p>A user token for interfacing with Hasura.</p>     <code>admin</code>   SecretValueFromSource     (Optional) <p>An alternate token for interfacing with Hasura using admin privileges.</p>     <code>defaultRole</code>  string    (Optional) <p>A default role that the queries should use when running the query.</p>     <code>queries</code>  map[string]string    (Optional) <p>A predefined list of queries that an event can specify in the io.triggermesh.graphql.query event type.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/targets/#targets.triggermesh.io/v1alpha1.HasuraTarget"},{"title":"IBMMQTarget","text":"<p> <p>IBMMQTarget is the Schema the event target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>IBMMQTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   IBMMQTargetSpec          <code>connectionName</code>  string        <code>queueManager</code>  string        <code>queueName</code>  string        <code>channelName</code>  string        <code>replyTo</code>   MQReplyOptions         <code>credentials</code>   Credentials         <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>discardCloudEventContext</code>  bool    <p>Whether to omit CloudEvent context attributes in messages sent to MQ. When this property is false (default), the entire CloudEvent payload is included. When this property is true, only the CloudEvent data is included.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/targets/#targets.triggermesh.io/v1alpha1.IBMMQTarget"},{"title":"InfraTarget","text":"<p> <p>InfraTarget is the Schema for the Infra JS Target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>InfraTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   InfraTargetSpec          <code>script</code>   InfraTargetScript     <p>Script to be executed at every request.</p>     <code>state</code>   InfraTargetState     <p>State actions and options.</p>     <code>typeLoopProtection</code>  bool    <p>TypeLoopProtection protect against infinite loops when the cloudevent type does not change.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/targets/#targets.triggermesh.io/v1alpha1.InfraTarget"},{"title":"JiraTarget","text":"<p> <p>JiraTarget is the Schema for the Infra JS Target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>JiraTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   JiraTargetSpec          <code>auth</code>   JiraAuth     <p>Authentication to interact with the Salesforce API.</p>     <code>url</code>  string    <p>URL for Jira service.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/targets/#targets.triggermesh.io/v1alpha1.JiraTarget"},{"title":"KafkaTarget","text":"<p> <p>KafkaTarget is the Schema for an KafkaTarget.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>KafkaTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   KafkaTargetSpec          <code>topic</code>  string    <p>Topic where messages are produced.</p>     <code>topicReplicationFactor</code>  int16    (Optional) <p>TopicReplicationFactor is the number of replicas for the topic.</p>     <code>topicPartitions</code>  int32    (Optional) <p>TopicPartitions is the number of partitions for the topic.</p>     <code>bootstrapServers</code>  []string    <p>BootstrapServers holds the name of the Kafka Bootstrap server.</p>     <code>auth</code>   KafkaTargetAuth     <p>Auth contains Authentication method used to interact with Kafka.</p>     <code>discardCloudEventContext</code>  bool    <p>Whether to omit CloudEvent context attributes in messages sent to Kafka. When this property is false (default), the entire CloudEvent payload is included. When this property is true, only the CloudEvent data is included.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/targets/#targets.triggermesh.io/v1alpha1.KafkaTarget"},{"title":"LogzMetricsTarget","text":"<p> <p>LogzMetricsTarget receives CloudEvents typed <code>io.triggermesh.opentelemetry.metrics.push</code> that fullfil the schema at https://docs.triggermesh.io/schemas/opentelemetry.metrics.push.json to push new observations.</p> <p>The target works using an OpenTelemetry to Cortex adapter, and is able to manage OpenTelemetry Synchronous Kinds. In case of an error a CloudEvent response conformant with https://docs.triggermesh.io/schemas/triggermesh.error.json and with an the attribute extension <code>category: error</code> can be produced.</p> <p>Due to the buffering nature of this target, not returning an error does not guarantee that the metrics have been pushed to Logz</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>LogzMetricsTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   LogzMetricsTargetSpec          <code>connection</code>   LogzMetricsConnection     <p>Connection information for LogzMetrics.</p>     <code>instruments</code>   []Instrument     <p>Instruments configured for pushing metrics. It is mandatory that all metrics pushed by using this target are pre-registered using this list.</p>     <code>eventOptions</code>   EventOptions     (Optional) <p>EventOptions for targets</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/targets/#targets.triggermesh.io/v1alpha1.LogzMetricsTarget"},{"title":"LogzTarget","text":"<p> <p>LogzTarget is the Schema for the Logz Target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>LogzTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   LogzTargetSpec          <code>shippingToken</code>   SecretValueFromSource     <p>ShippingToken defines the API token.</p>     <code>logsListenerURL</code>  string    <p>LogsListenerURL Defines the Log listener URL</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/targets/#targets.triggermesh.io/v1alpha1.LogzTarget"},{"title":"OracleTarget","text":"<p> <p>OracleTarget is the Schema for an Oracle Target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>OracleTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   OracleTargetSpec          <code>oracleApiPrivateKey</code>   SecretValueFromSource     <p>Oracle User API private key.</p>     <code>oracleApiPrivateKeyPassphrase</code>   SecretValueFromSource     <p>Oracle User API private key passphrase.</p>     <code>oracleApiPrivateKeyFingerprint</code>   SecretValueFromSource     <p>Oracle User API cert fingerprint.</p>     <code>oracleTenancy</code>  string    <p>Oracle Tenancy OCID.</p>     <code>oracleUser</code>  string    <p>Oracle User OCID associated with the API key.</p>     <code>oracleRegion</code>  string    <p>Oracle Cloud Region.</p>     <code>function</code>   OracleFunctionSpecSpec         <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/targets/#targets.triggermesh.io/v1alpha1.OracleTarget"},{"title":"SalesforceTarget","text":"<p> <p>SalesforceTarget receives CloudEvents typed <code>io.triggermesh.salesforce.apicall</code> that fullfil the schema at https://docs.triggermesh.io/schemas/salesforce.apicall.json and consumes the Salesforce API.</p> <p>Upon a successful call a response is returned typed <code>io.triggermesh.salesforce.apicall.response</code> containing the returned payload as the CloudEvent data and a <code>category: success</code> extension. In case of an error the payload will be conformant with https://docs.triggermesh.io/schemas/triggermesh.error.json and the CloudEvent extension will be set to <code>category: error</code>.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>SalesforceTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   SalesforceTargetSpec          <code>auth</code>   SalesforceAuth     <p>Authentication information to interact with the Salesforce API.</p>     <code>apiVersion</code>  string    (Optional) <p>APIVersion at Salesforce. If not set the latest version will be used.</p>     <code>eventOptions</code>   EventOptions     (Optional) <p>EventOptions for targets</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/targets/#targets.triggermesh.io/v1alpha1.SalesforceTarget"},{"title":"SendGridTarget","text":"<p> <p>SendGridTarget is the Schema for an Sendgrid Target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>SendGridTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   SendGridTargetSpec          <code>apiKey</code>   SecretValueFromSource     <p>APIKey for account</p>     <code>defaultFromEmail</code>  string    (Optional) <p>DefaultFromEmail is a default email account to assign to the outgoing email\u2019s.</p>     <code>defaultToEmail</code>  string    (Optional) <p>DefaultToEmail is a default recipient email account to assign to the outgoing email\u2019s.</p>     <code>defaultToName</code>  string    (Optional) <p>DefaultToName is a default recipient name to assign to the outgoing email\u2019s.</p>     <code>defaultFromName</code>  string    (Optional) <p>DefaultFromName is a default sender name to assign to the outgoing email\u2019s.</p>     <code>defaultMessage</code>  string    (Optional) <p>DefaultMessage is a default message to assign to the outgoing email\u2019s.</p>     <code>defaultSubject</code>  string    (Optional) <p>DefaultSubject is a default subject to assign to the outgoing email\u2019s.</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/targets/#targets.triggermesh.io/v1alpha1.SendGridTarget"},{"title":"SlackTarget","text":"<p> <p>SlackTarget defines the schema for the Slack target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>SlackTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   SlackTargetSpec          <code>token</code>   SecretValueFromSource     <p>Token for Slack App</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/targets/#targets.triggermesh.io/v1alpha1.SlackTarget"},{"title":"SplunkTarget","text":"<p> <p>SplunkTarget is the Schema for the event target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>SplunkTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   SplunkTargetSpec          <code>endpoint</code>   knative.dev/pkg/apis.URL     <p>URL of the HTTP Event Collector (HEC). Only the scheme, hostname, and port (optionally) are evaluated, the URL path is trimmed if present. see https://docs.splunk.com/Documentation/Splunk/latest/Data/UsetheHTTPEventCollector#Enable_HTTP_Event_Collector</p>     <code>token</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     <p>Token for authenticating requests against the HEC. see https://docs.splunk.com/Documentation/Splunk/latest/Data/UsetheHTTPEventCollector#About_Event_Collector_tokens</p>     <code>index</code>  string    (Optional) <p>Name of the index to send events to. When undefined, events are sent to the default index defined in the HEC token\u2019s configuration.</p>     <code>skipTLSVerify</code>  bool    (Optional) <p>Controls whether the Splunk client verifies the server\u2019s certificate chain and host name when communicating over TLS.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/targets/#targets.triggermesh.io/v1alpha1.SplunkTarget"},{"title":"TektonTarget","text":"<p> <p>TektonTarget defines the schema for the Tekton target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>TektonTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   TektonTargetSpec          <code>reapPolicy</code>   TektonTargetReapPolicy     (Optional) <p>ReapPolicy dictates the reaping policy to be applied for the target</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/targets/#targets.triggermesh.io/v1alpha1.TektonTarget"},{"title":"TwilioTarget","text":"<p> <p>TwilioTarget is the Schema for an Twilio Target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>TwilioTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   TwilioTargetSpec          <code>sid</code>   SecretValueFromSource     <p>Twilio account SID</p>     <code>token</code>   SecretValueFromSource     <p>Twilio account Token</p>     <code>defaultPhoneFrom</code>  string    (Optional) <p>DefaultPhoneFrom is the purchased Twilio phone we are using</p>     <code>defaultPhoneTo</code>  string    (Optional) <p>DefaultPhoneTo is the destination phone</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/targets/#targets.triggermesh.io/v1alpha1.TwilioTarget"},{"title":"UiPathTarget","text":"<p> <p>UiPathTarget is the Schema for the event target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>UiPathTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   UiPathTargetSpec          <code>userKey</code>   SecretValueFromSource     <p>UserKey An OAuth token used to obtain an access key.</p>     <code>robotName</code>  string    <p>RobotName is the robot to invoke with this target.</p>     <code>processName</code>  string    <p>ProccessName is the process name that will be used by UiPath for the target.</p>     <code>tenantName</code>  string    <p>TenantName is the tenant that contains the components that will be invoked by the target.</p>     <code>accountLogicalName</code>  string    <p>AccountLogicalName is the unique site URL used to identif the UiPath tenant.</p>     <code>clientID</code>  string    <p>ClientID is the OAuth id registered to this target.</p>     <code>organizationUnitID</code>  string    <p>OrganizationUnitID is the organization unit within the tenant that the UiPath proccess will run under.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/targets/#targets.triggermesh.io/v1alpha1.UiPathTarget"},{"title":"ZendeskTarget","text":"<p> <p>ZendeskTarget is the Schema for an Zendesk Target.</p> </p>    Field Description      <code>apiVersion</code> string  <code> targets.triggermesh.io/v1alpha1 </code>     <code>kind</code> string  <code>ZendeskTarget</code>    <code>metadata</code>   Kubernetes meta/v1.ObjectMeta     Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.     <code>spec</code>   ZendeskTargetSpec          <code>token</code>   SecretValueFromSource     <p>Token contains the Zendesk account Token.</p>     <code>subdomain</code>  string    <p>Subdomain the Zendesk subdomain.</p>     <code>email</code>  string    <p>Email the registered Zendesk email account.</p>     <code>subject</code>  string    (Optional) <p>Subject a static subject assignemnt for every ticket.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>        <code>status</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.Status","location":"apis/targets/#targets.triggermesh.io/v1alpha1.ZendeskTarget"},{"title":"AWSComprehendTargetSpec","text":"<p> (Appears on: AWSComprehendTarget) </p> <p> <p>AWSComprehendTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>awsApiKey</code>   SecretValueFromSource     <p>AWS account Key.</p>     <code>awsApiSecret</code>   SecretValueFromSource     <p>AWS account secret key.</p>     <code>region</code>  string    <p>Region to use for calling into Comprehend API.</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets.</p>     <code>language</code>  string    <p>Language code to use to interact with Comprehend. The supported list can be found at: https://docs.aws.amazon.com/comprehend/latest/dg/supported-languages.html</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.AWSComprehendTargetSpec"},{"title":"AWSDynamoDBTargetSpec","text":"<p> (Appears on: AWSDynamoDBTarget) </p> <p> <p>AWSDynamoDBTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>awsApiKey</code>   SecretValueFromSource     <p>AWS account Key</p>     <code>awsApiSecret</code>   SecretValueFromSource     <p>AWS account secret key</p>     <code>arn</code>  string    <p>Table ARN https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazondynamodb.html#amazondynamodb-resources-for-iam-policies</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.AWSDynamoDBTargetSpec"},{"title":"AWSEventBridgeTargetSpec","text":"<p> (Appears on: AWSEventBridgeTarget) </p> <p> <p>AWSEventBridgeTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>awsApiKey</code>   SecretValueFromSource     <p>AWS account Key</p>     <code>awsApiSecret</code>   SecretValueFromSource     <p>AWS account secret key</p>     <code>arn</code>  string    <p>Amazon Resource Name of the EventBridge Event Bus. https://docs.aws.amazon.com/service-authorization/latest/reference/list_amazoneventbridge.html</p>     <code>discardCloudEventContext</code>  bool    <p>Whether to omit CloudEvent context attributes in notifications sent to EventBridge. When this property is false (default), the entire CloudEvent payload is included. When this property is true, only the CloudEvent data is included.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.AWSEventBridgeTargetSpec"},{"title":"AWSKinesisTargetSpec","text":"<p> (Appears on: AWSKinesisTarget) </p> <p> <p>AWSKinesisTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>awsApiKey</code>   SecretValueFromSource     <p>AWS account Key</p>     <code>awsApiSecret</code>   SecretValueFromSource     <p>AWS account secret key</p>     <code>arn</code>  string    <p>Amazon Resource Name of the Kinesis stream. https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazonkinesis.html#amazonkinesis-resources-for-iam-policies</p>     <code>partition</code>  string    <p>Kinesis Partition to publish the events to</p>     <code>discardCloudEventContext</code>  bool    <p>Whether to omit CloudEvent context attributes in records created in Kinesis. When this property is false (default), the entire CloudEvent payload is included. When this property is true, only the CloudEvent data is included.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.AWSKinesisTargetSpec"},{"title":"AWSLambdaTargetSpec","text":"<p> (Appears on: AWSLambdaTarget) </p> <p> <p>AWSLambdaTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>awsApiKey</code>   SecretValueFromSource     <p>AWS account Key</p>     <code>awsApiSecret</code>   SecretValueFromSource     <p>AWS account secret key</p>     <code>arn</code>  string    <p>Amazon Resource Name of the Lambda function. https://docs.aws.amazon.com/IAM/latest/UserGuide/list_awslambda.html#awslambda-resources-for-iam-policies</p>     <code>discardCloudEventContext</code>  bool    <p>Whether to omit CloudEvent context attributes in Lambda function calls. When this property is false (default), the entire CloudEvent payload is included. When this property is true, only the CloudEvent data is included.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.AWSLambdaTargetSpec"},{"title":"AWSS3TargetSpec","text":"<p> (Appears on: AWSS3Target) </p> <p> <p>AWSS3TargetSpec holds the desired state of the even target.</p> </p>    Field Description      <code>awsApiKey</code>   SecretValueFromSource     <p>AWS account Key</p>     <code>awsApiSecret</code>   SecretValueFromSource     <p>AWS account secret key</p>     <code>arn</code>  string    <p>Amazon Resource Name of the S3 bucket. https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazons3.html#amazons3-resources-for-iam-policies</p>     <code>discardCloudEventContext</code>  bool    <p>Whether to omit CloudEvent context attributes in objects created in S3. When this property is false (default), the entire CloudEvent payload is included. When this property is true, only the CloudEvent data is included.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.AWSS3TargetSpec"},{"title":"AWSSNSTargetSpec","text":"<p> (Appears on: AWSSNSTarget) </p> <p> <p>AWSSNSTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>awsApiKey</code>   SecretValueFromSource     <p>AWS account Key</p>     <code>awsApiSecret</code>   SecretValueFromSource     <p>AWS account secret key</p>     <code>arn</code>  string    <p>Amazon Resource Name of the SNS topic. https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazonsns.html#amazonsns-resources-for-iam-policies</p>     <code>discardCloudEventContext</code>  bool    <p>Whether to omit CloudEvent context attributes in notifications sent to SNS. When this property is false (default), the entire CloudEvent payload is included. When this property is true, only the CloudEvent data is included.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.AWSSNSTargetSpec"},{"title":"AWSSQSTargetSpec","text":"<p> (Appears on: AWSSQSTarget) </p> <p> <p>AWSSQSTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>awsApiKey</code>   SecretValueFromSource     <p>AWS account Key</p>     <code>awsApiSecret</code>   SecretValueFromSource     <p>AWS account secret key</p>     <code>arn</code>  string    <p>Amazon Resource Name of the SQS queue. https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazonsqs.html#amazonsqs-resources-for-iam-policies</p>     <code>messageGroupId</code>  string    (Optional) <p>Message Group ID is required for FIFO based queues, and is used to uniquely identify the event producer https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFO-queues-understanding-logic.html</p>     <code>discardCloudEventContext</code>  bool    <p>Whether to omit CloudEvent context attributes in messages sent to SQS. When this property is false (default), the entire CloudEvent payload is included. When this property is true, only the CloudEvent data is included.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.AWSSQSTargetSpec"},{"title":"AlibabaOSSTargetSpec","text":"<p> (Appears on: AlibabaOSSTarget) </p> <p> <p>AlibabaOSSTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>accessKeyID</code>   SecretValueFromSource     <p>Alibaba SDK access key id as registered. For more information on how to create an access key pair, please refer to https://www.alibabacloud.com/help/doc-detail/53045.htm?spm=a2c63.p38356.879954.9.23bc7d91ARN6Hy#task968.</p>     <code>accessKeySecret</code>   SecretValueFromSource     <p>Alibaba SDK access key secret as registered.</p>     <code>endpoint</code>  string    <p>The domain name used to access the OSS. For more information, please refer to the region and endpoint guide at https://www.alibabacloud.com/help/doc-detail/31837.htm?spm=a2c63.p38356.879954.8.23bc7d91ARN6Hy#concept-zt4-cvy-5db</p>     <code>bucket</code>  string    <p>The unique container to store objects in OSS.</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.AlibabaOSSTargetSpec"},{"title":"AzureAuth","text":"<p> (Appears on: AzureEventHubsTargetSpec,  AzureSentinelTargetSpec) </p> <p> <p>AzureAuth contains multiple authentication methods for Azure services.</p> </p>    Field Description      <code>servicePrincipal</code>   AzureServicePrincipal     <p>Service principals provide a way to create a non-interactive account associated with your identity to which you grant only the privileges your app needs to run. See https://docs.microsoft.com/en-us/azure/active-directory/develop/app-objects-and-service-principals</p>     <code>sasToken</code>   AzureSASToken     <p>A shared access signature (SAS) provides secure delegated access to resources in a storage account. See https://docs.microsoft.com/en-us/azure/storage/common/storage-sas-overview</p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.AzureAuth"},{"title":"AzureEventHubsTargetSpec","text":"<p> (Appears on: AzureEventHubsTarget) </p> <p> <p>AzureEventHubsTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>auth</code>   AzureAuth     <p>Authentication method to interact with the Azure Event Hubs API.</p>     <code>eventHubID</code>   EventHubResourceID     <p>Resource ID of the Event Hubs instance.</p> <p>Expected format: - /subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.EventHub/namespaces/{namespaceName}/eventhubs/{eventHubName}</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>discardCloudEventContext</code>  bool        <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.AzureEventHubsTargetSpec"},{"title":"AzureSASToken","text":"<p> (Appears on: AzureAuth) </p> <p> <p>AzureSASToken represents an Azure SAS token.</p> </p>    Field Description      <code>keyName</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>keyValue</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>connectionString</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField","location":"apis/targets/#targets.triggermesh.io/v1alpha1.AzureSASToken"},{"title":"AzureSentinelTargetSpec","text":"<p> (Appears on: AzureSentinelTarget) </p> <p> <p>AzureSentinelTargetSpec holds the desired state of the event target.</p> </p>    Field Description      <code>subscriptionID</code>  string    <p>SubscriptionID refers to the Azure Subscription ID that the Azure Sentinel instance is associated with.</p>     <code>resourceGroup</code>  string    <p>ResourceGroup refers to the resource group where the Azure Sentinel instance is deployed.</p>     <code>workspace</code>  string    <p>Workspace refers to the workspace name in Azure Sentinel.</p>     <code>auth</code>   AzureAuth     <p>Authentication method to interact with the Azure Event Hubs API.</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.AzureSentinelTargetSpec"},{"title":"AzureServicePrincipal","text":"<p> (Appears on: AzureAuth) </p> <p> <p>AzureServicePrincipal represents an AAD Service Principal.</p> </p>    Field Description      <code>tenantID</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>clientID</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>clientSecret</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField","location":"apis/targets/#targets.triggermesh.io/v1alpha1.AzureServicePrincipal"},{"title":"CloudEventsCredentials","text":"<p> (Appears on: CloudEventsTargetSpec) </p> <p> <p>CloudEventsCredentials to be used when sending requests.</p> </p>    Field Description      <code>basicAuth</code>   HTTPBasicAuth","location":"apis/targets/#targets.triggermesh.io/v1alpha1.CloudEventsCredentials"},{"title":"CloudEventsTargetSpec","text":"<p> (Appears on: CloudEventsTarget) </p> <p> <p>CloudEventsTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>credentials</code>   CloudEventsCredentials     (Optional) <p>Credentials to connect to the remote endpoint.</p>     <code>path</code>  string    (Optional) <p>Path at the remote endpoint under which requests are accepted.</p>     <code>endpoint</code>   knative.dev/pkg/apis.URL     <p>Endpoint that accept CloudEvents.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>AdapterOverrides sets runtime parameters to the adapter instance.</p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.CloudEventsTargetSpec"},{"title":"ConfluentTargetSpec","text":"<p> (Appears on: ConfluentTarget) </p> <p> <p>ConfluentTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>username</code>  string    <p>SASLUsername Confluent account User</p>     <code>password</code>   SecretValueFromSource     <p>SASLPassword Confluent account Password</p>     <code>topic</code>  string    <p>Topic where messages are produced.</p>     <code>topicReplicationFactor</code>  int    (Optional) <p>TopicReplicationFactor is the number of replicas for the topic.</p>     <code>topicPartitions</code>  int    (Optional) <p>TopicPartitions is the number of partitions for the topic.</p>     <code>bootstrapServers</code>  []string    <p>BootstrapServers holds the name of the Kafka Bootstrap server.</p>     <code>securityProtocol</code>  string    <p>SecurityProtocol allows the user to set the security protocol</p>     <code>saslMechanism</code>  string    <p>SASLMechanisms all the assignment of specific SASL mechanisms.</p>     <code>discardCloudEventContext</code>  bool    <p>Whether to omit CloudEvent context attributes in messages sent to Kafka. When this property is false (default), the entire CloudEvent payload is included. When this property is true, only the CloudEvent data is included.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.ConfluentTargetSpec"},{"title":"Connection","text":"<p> (Appears on: ElasticsearchTargetSpec) </p> <p> <p>Connection contains connection and configuration parameters</p> </p>    Field Description      <code>addresses</code>  []string    <p>Array of hostnames or IP addresses to connect the target to.</p>     <code>caCert</code>  string    <p>CA Certificate used to verify connection with the Elasticsearch instance.</p>     <code>skipVerify</code>  bool    <p>Skip verification of the SSL certificate during the connection.</p>     <code>username</code>  string    <p>Elasticsearch account username.</p>     <code>password</code>   SecretValueFromSource     <p>Elasticsearch account password.</p>     <code>apiKey</code>   SecretValueFromSource     <p>When informed supersedes username and password.</p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.Connection"},{"title":"Credentials","text":"<p> (Appears on: IBMMQTargetSpec) </p> <p> <p>Credentials holds the auth details.</p> </p>    Field Description      <code>username</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>password</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>tls</code>   TLSSpec","location":"apis/targets/#targets.triggermesh.io/v1alpha1.Credentials"},{"title":"DatadogTargetSpec","text":"<p> (Appears on: DatadogTarget) </p> <p> <p>DatadogTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>apiKey</code>   SecretValueFromSource     <p>DatadogApiKey represents how Datadog credentials should be provided in the secret</p>     <code>metricPrefix</code>  string    (Optional) <p>MetricPrefix is prepended to the name of the associated metrics.</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.DatadogTargetSpec"},{"title":"ElasticsearchTargetSpec","text":"<p> (Appears on: ElasticsearchTarget) </p> <p> <p>ElasticsearchTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>connection</code>   Connection     (Optional) <p>Connection information to elasticsearch.</p>     <code>indexName</code>  string    <p>IndexName to write to.</p>     <code>discardCloudEventContext</code>  bool    <p>Whether to omit CloudEvent context attributes in documents created in Elasticsearch. When this property is false (default), the entire CloudEvent payload is included. When this property is true, only the CloudEvent data is included.</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.ElasticsearchTargetSpec"},{"title":"EventHubResourceID","text":"<p> (Appears on: AzureEventHubsTargetSpec) </p> <p> <p>EventHubResourceID represents a resource ID for an Event Hubs instance or namespace.</p> </p>    Field Description      <code>SubscriptionID</code>  string        <code>ResourceGroup</code>  string        <code>Namespace</code>  string        <code>EventHub</code>  string","location":"apis/targets/#targets.triggermesh.io/v1alpha1.EventHubResourceID"},{"title":"EventOptions","text":"<p> (Appears on: AWSComprehendTargetSpec,  AlibabaOSSTargetSpec,  AzureEventHubsTargetSpec,  AzureSentinelTargetSpec,  DatadogTargetSpec,  ElasticsearchTargetSpec,  GoogleCloudFirestoreTargetSpec,  GoogleCloudPubSubTargetSpec,  GoogleCloudStorageTargetSpec,  GoogleCloudWorkflowsTargetSpec,  IBMMQTargetSpec,  LogzMetricsTargetSpec,  LogzTargetSpec,  SalesforceTargetSpec,  SendGridTargetSpec,  TwilioTargetSpec) </p> <p> <p>EventOptions modifies CloudEvents management at Targets.</p> </p>    Field Description      <code>payloadPolicy</code>  github.com/triggermesh/triggermesh/pkg/targets/adapter/cloudevents.PayloadPolicy    (Optional) <p>PayloadPolicy indicates if replies from the target should include a payload if available. Possible values are:</p> <ul> <li>always: will return a with the reply payload if avaliable.</li> <li>errors: will only reply with payload in case of an error.</li> <li>never: will not reply with payload.</li> </ul>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.EventOptions"},{"title":"GCloudResourceName","text":"<p> (Appears on: GoogleCloudPubSubTargetSpec) </p> <p> <p>GCloudResourceName represents a fully qualified resource name, as described at https://cloud.google.com/apis/design/resource_names</p> <p>Examples of such resource names include: - projects/{project_name}/topics/{topic_name} - projects/{project_name}/repos/{repo_name} - projects/{project_name}/subscriptions/{subscription_name}</p> </p>    Field Description      <code>Project</code>  string        <code>Collection</code>  string        <code>Resource</code>  string","location":"apis/targets/#targets.triggermesh.io/v1alpha1.GCloudResourceName"},{"title":"GoogleCloudFirestoreTargetSpec","text":"<p> (Appears on: GoogleCloudFirestoreTarget) </p> <p> <p>GoogleCloudFirestoreTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>credentialsJson</code>   SecretValueFromSource     <p>Credentials represents how Google Firestore credentials should be provided in the secret</p>     <code>defaultCollection</code>  string    <p>DefaultCollection sets a default Firestore collection to select from</p>     <code>projectID</code>  string    <p>ProjectID specifies the Google project ID</p>     <code>discardCloudEventContext</code>  bool    <p>Whether to omit CloudEvent context attributes in documents created in Firestore. When this property is false (default), the entire CloudEvent payload is included. When this property is true, only the CloudEvent data is included.</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.GoogleCloudFirestoreTargetSpec"},{"title":"GoogleCloudPubSubTargetSpec","text":"<p> (Appears on: GoogleCloudPubSubTarget) </p> <p> <p>GoogleCloudPubSubTargetSpec holds the desired state of the event target.</p> </p>    Field Description      <code>topic</code>   GCloudResourceName     <p>Full resource name of the Pub/Sub topic to subscribe to, in the format \u201cprojects/{project_name}/topics/{topic_name}\u201d.</p>     <code>credentialsJson</code>   SecretValueFromSource     <p>Service account key in JSON format. https://cloud.google.com/iam/docs/creating-managing-service-account-keys</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>discardCloudEventContext</code>  bool    <p>DiscardCloudEventContext is the policy for how to handle the payload of the CloudEvent.</p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.GoogleCloudPubSubTargetSpec"},{"title":"GoogleCloudPubSubTargetStatus","text":"<p> <p>GoogleCloudPubSubTargetStatus communicates the observed state of the event target.</p> </p>    Field Description      <code>Status</code>   knative.dev/pkg/apis/duck/v1.Status     <p> (Members of <code>Status</code> are embedded into this type.) </p>     <code>AddressStatus</code>   knative.dev/pkg/apis/duck/v1.AddressStatus     <p> (Members of <code>AddressStatus</code> are embedded into this type.) </p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.GoogleCloudPubSubTargetStatus"},{"title":"GoogleCloudStorageTargetSpec","text":"<p> (Appears on: GoogleCloudStorageTarget) </p> <p> <p>GoogleCloudStorageTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>credentialsJson</code>   SecretValueFromSource     <p>Credentials represents how Google Storage credentials should be provided in the secret</p>     <code>bucketName</code>  string    <p>BucketName specifies the Google Storage Bucket</p>     <code>discardCloudEventContext</code>  bool    <p>Whether to omit CloudEvent context attributes in objects created in Google Cloud Storage. When this property is false (default), the entire CloudEvent payload is included. When this property is true, only the CloudEvent data is included.</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.GoogleCloudStorageTargetSpec"},{"title":"GoogleCloudWorkflowsTargetSpec","text":"<p> (Appears on: GoogleCloudWorkflowsTarget) </p> <p> <p>GoogleCloudWorkflowsTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>credentialsJson</code>   SecretValueFromSource     <p>GoogleCloudWorkflowsApiKey represents how GoogleCloudWorkflows credentials should be provided in the secret</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.GoogleCloudWorkflowsTargetSpec"},{"title":"GoogleSheetTargetSpec","text":"<p> (Appears on: GoogleSheetTarget) </p> <p> <p>GoogleSheetTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>googleServiceAccount</code>   SecretValueFromSource     <p>GoogleSheet credential JSON for auth</p>     <code>id</code>  string    <p>ID of Google a spreadsheet</p>     <code>defaultPrefix</code>  string    <p>DefaultPrefix is a pre-defined prefix for the individual sheets.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.GoogleSheetTargetSpec"},{"title":"HTTPBasicAuth","text":"<p> (Appears on: CloudEventsCredentials) </p> <p> <p>HTTPBasicAuth credentials.</p> </p>    Field Description      <code>username</code>  string        <code>password</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField","location":"apis/targets/#targets.triggermesh.io/v1alpha1.HTTPBasicAuth"},{"title":"HTTPEventResponse","text":"<p> (Appears on: HTTPTargetSpec) </p> <p> <p>HTTPEventResponse for reply events context.</p> </p>    Field Description      <code>eventType</code>  string    <p>EventType for the reply.</p>     <code>eventSource</code>  string    <p>EventSource for the reply.</p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.HTTPEventResponse"},{"title":"HTTPTargetSpec","text":"<p> (Appears on: HTTPTarget) </p> <p> <p>HTTPTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>response</code>   HTTPEventResponse     <p>Response data to be used at replies.</p>     <code>endpoint</code>   knative.dev/pkg/apis.URL     <p>Endpoint to connect to.</p>     <code>method</code>  string    <p>Method to use at requests.</p>     <code>headers</code>  map[string]string    (Optional) <p>Headers to be included at HTTP requests</p>     <code>skipVerify</code>  bool    (Optional) <p>SkipVerify disables server certificate validation.</p>     <code>caCertificate</code>  string    (Optional) <p>CACertificate uses the CA certificate to verify the remote server certificate.</p>     <code>basicAuthUsername</code>  string    (Optional) <p>BasicAuthUsername used for basic authentication.</p>     <code>basicAuthPassword</code>   SecretValueFromSource     (Optional) <p>BasicAuthPassword used for basic authentication.</p>     <code>oauthClientID</code>  string    (Optional) <p>OAuthClientID used for OAuth2 authentication.</p>     <code>oauthClientSecret</code>   SecretValueFromSource     (Optional) <p>OAuthClientSecret used for OAuth2 authentication.</p>     <code>oauthTokenURL</code>  string    (Optional) <p>OAuthTokenURL used for OAuth2 authentication.</p>     <code>oauthScopes</code>  []string    (Optional) <p>OAuthScopes used for OAuth2 authentication.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.HTTPTargetSpec"},{"title":"HasuraTargetSpec","text":"<p> (Appears on: HasuraTarget) </p> <p> <p>HasuraTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>endpoint</code>  string    <p>The GraphQL server endpoint.</p>     <code>jwt</code>   SecretValueFromSource     (Optional) <p>A user token for interfacing with Hasura.</p>     <code>admin</code>   SecretValueFromSource     (Optional) <p>An alternate token for interfacing with Hasura using admin privileges.</p>     <code>defaultRole</code>  string    (Optional) <p>A default role that the queries should use when running the query.</p>     <code>queries</code>  map[string]string    (Optional) <p>A predefined list of queries that an event can specify in the io.triggermesh.graphql.query event type.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.HasuraTargetSpec"},{"title":"HeaderPolicy (<code>string</code> alias)","text":"<p> (Appears on: InfraTargetState) </p> <p> <p>HeaderPolicy is the action to take on stateful headers</p> </p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.HeaderPolicy"},{"title":"IBMMQTargetSpec","text":"<p> (Appears on: IBMMQTarget) </p> <p> <p>IBMMQTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>connectionName</code>  string        <code>queueManager</code>  string        <code>queueName</code>  string        <code>channelName</code>  string        <code>replyTo</code>   MQReplyOptions         <code>credentials</code>   Credentials         <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>discardCloudEventContext</code>  bool    <p>Whether to omit CloudEvent context attributes in messages sent to MQ. When this property is false (default), the entire CloudEvent payload is included. When this property is true, only the CloudEvent data is included.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.IBMMQTargetSpec"},{"title":"InfraTargetScript","text":"<p> (Appears on: InfraTargetSpec) </p> <p> <p>InfraTargetScript holds the script options</p> </p>    Field Description      <code>code</code>  string    <p>Code to be executed at every request.</p>     <code>timeout</code>  int    <p>Timeout is the script execution time after which it will be halted.</p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.InfraTargetScript"},{"title":"InfraTargetSpec","text":"<p> (Appears on: InfraTarget) </p> <p> <p>InfraTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>script</code>   InfraTargetScript     <p>Script to be executed at every request.</p>     <code>state</code>   InfraTargetState     <p>State actions and options.</p>     <code>typeLoopProtection</code>  bool    <p>TypeLoopProtection protect against infinite loops when the cloudevent type does not change.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.InfraTargetSpec"},{"title":"InfraTargetState","text":"<p> (Appears on: InfraTargetSpec) </p> <p> <p>InfraTargetState holds the state options</p> </p>    Field Description      <code>headersPolicy</code>   HeaderPolicy     <p>HeadersPolicy determines actions on stateful headers.</p>     <code>bridge</code>  string    <p>Bridge is the identifier to be used if the adapter needs to create cloud events headers as part of its policy.</p> <p>The Bridge moniker identifies uniquely the workflow that this component is part of, and should be taken into account when storing variables in the state store.</p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.InfraTargetState"},{"title":"Instrument","text":"<p> (Appears on: LogzMetricsTargetSpec) </p> <p> <p>Instrument push metrics for.</p> </p>    Field Description      <code>name</code>  string    <p>Name for the Instrument.</p>     <code>description</code>  string    (Optional) <p>Description for the Instrument</p>     <code>instrument</code>   InstrumentKind     <p>Instrument Kind as defined by OpenTelemetry. Supported values are:</p> <ul> <li>Histogram: for absolute values that can be aggregated.</li> <li>Counter: for delta values that increase monotonically.</li> <li>UpDownCounter: for delta values that can increase and decrease.</li> </ul>     <code>number</code>   NumberKind     <p>Number Kind as defined by OpenTelemetry, defines the measure data type accepted by the Instrument. Supported values are:</p> <ul> <li>Int64.</li> <li>Float64.</li> </ul>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.Instrument"},{"title":"InstrumentKind (<code>string</code> alias)","text":"<p> (Appears on: Instrument) </p> <p> <p>InstrumentKind as defined by OpenTelemetry.</p> </p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.InstrumentKind"},{"title":"JiraAuth","text":"<p> (Appears on: JiraTargetSpec) </p> <p> <p>JiraAuth contains Jira credentials.</p> </p>    Field Description      <code>user</code>  string    <p>Jira username to connect to the instance as.</p>     <code>token</code>   SecretValueFromSource     <p>Jira API token bound to the user.</p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.JiraAuth"},{"title":"JiraTargetSpec","text":"<p> (Appears on: JiraTarget) </p> <p> <p>JiraTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>auth</code>   JiraAuth     <p>Authentication to interact with the Salesforce API.</p>     <code>url</code>  string    <p>URL for Jira service.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.JiraTargetSpec"},{"title":"KafkaTargetAuth","text":"<p> (Appears on: KafkaTargetSpec) </p> <p> <p>KafkaTargetAuth contains Authentication method used to interact with Kafka.</p> </p>    Field Description      <code>kerberos</code>   KafkaTargetKerberos         <code>tls</code>   KafkaTargetTLSAuth         <code>saslEnable</code>  bool    <p>SASL Enable</p>     <code>tlsEnable</code>  bool    (Optional) <p>TLS Enable</p>     <code>securityMechanism</code>  string    (Optional) <p>SecurityMechanisms holds the assignment of the specific SASL mechanisms.</p>     <code>username</code>  string    (Optional) <p>Username Kafka account User</p>     <code>password</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     (Optional) <p>Password Kafka account Password</p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.KafkaTargetAuth"},{"title":"KafkaTargetKerberos","text":"<p> (Appears on: KafkaTargetAuth) </p> <p> <p>KafkaTargetKerberos contains kerberos credentials.</p> </p>    Field Description      <code>username</code>  string        <code>password</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>serviceName</code>  string        <code>configPath</code>  string        <code>keytabPath</code>  string        <code>config</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>keytab</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>realm</code>  string","location":"apis/targets/#targets.triggermesh.io/v1alpha1.KafkaTargetKerberos"},{"title":"KafkaTargetSpec","text":"<p> (Appears on: KafkaTarget) </p> <p> <p>KafkaTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>topic</code>  string    <p>Topic where messages are produced.</p>     <code>topicReplicationFactor</code>  int16    (Optional) <p>TopicReplicationFactor is the number of replicas for the topic.</p>     <code>topicPartitions</code>  int32    (Optional) <p>TopicPartitions is the number of partitions for the topic.</p>     <code>bootstrapServers</code>  []string    <p>BootstrapServers holds the name of the Kafka Bootstrap server.</p>     <code>auth</code>   KafkaTargetAuth     <p>Auth contains Authentication method used to interact with Kafka.</p>     <code>discardCloudEventContext</code>  bool    <p>Whether to omit CloudEvent context attributes in messages sent to Kafka. When this property is false (default), the entire CloudEvent payload is included. When this property is true, only the CloudEvent data is included.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.KafkaTargetSpec"},{"title":"KafkaTargetTLSAuth","text":"<p> (Appears on: KafkaTargetAuth) </p> <p> <p>KafkaTargetTLSAuth contains kerberos credentials.</p> </p>    Field Description      <code>ca</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>clientCert</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>clientKey</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>skipVerify</code>  bool","location":"apis/targets/#targets.triggermesh.io/v1alpha1.KafkaTargetTLSAuth"},{"title":"Keystore","text":"<p> (Appears on: TLSSpec) </p> <p> <p>Keystore represents Key Database components.</p> </p>    Field Description      <code>keyDatabase</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField         <code>passwordStash</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField","location":"apis/targets/#targets.triggermesh.io/v1alpha1.Keystore"},{"title":"LogzMetricsConnection","text":"<p> (Appears on: LogzMetricsTargetSpec) </p> <p> <p>LogzMetricsConnection contains the information to connect to a Logz tenant to push metrics.</p> </p>    Field Description      <code>token</code>   SecretValueFromSource     <p>Token for connecting to Logz metrics listener.</p>     <code>listenerURL</code>  string    <p>ListenerURL for pushing metrics.</p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.LogzMetricsConnection"},{"title":"LogzMetricsTargetSpec","text":"<p> (Appears on: LogzMetricsTarget) </p> <p> <p>LogzMetricsTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>connection</code>   LogzMetricsConnection     <p>Connection information for LogzMetrics.</p>     <code>instruments</code>   []Instrument     <p>Instruments configured for pushing metrics. It is mandatory that all metrics pushed by using this target are pre-registered using this list.</p>     <code>eventOptions</code>   EventOptions     (Optional) <p>EventOptions for targets</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.LogzMetricsTargetSpec"},{"title":"LogzTargetSpec","text":"<p> (Appears on: LogzTarget) </p> <p> <p>LogzTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>shippingToken</code>   SecretValueFromSource     <p>ShippingToken defines the API token.</p>     <code>logsListenerURL</code>  string    <p>LogsListenerURL Defines the Log listener URL</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.LogzTargetSpec"},{"title":"MQReplyOptions","text":"<p> (Appears on: IBMMQTargetSpec) </p> <p> </p>    Field Description      <code>queueManager</code>  string        <code>queueName</code>  string","location":"apis/targets/#targets.triggermesh.io/v1alpha1.MQReplyOptions"},{"title":"NumberKind (<code>string</code> alias)","text":"<p> (Appears on: Instrument) </p> <p> <p>NumberKind as defined by OpenTelemetry.</p> </p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.NumberKind"},{"title":"OracleFunctionSpecSpec","text":"<p> (Appears on: OracleTargetSpec) </p> <p> <p>OracleFunctionSpecSpec defines the desired state of the event target.</p> </p>    Field Description      <code>function</code>  string    <p> (Members of <code>function</code> are embedded into this type.) </p> <p>Oracle Cloud ID of the function to invoke.</p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.OracleFunctionSpecSpec"},{"title":"OracleTargetSpec","text":"<p> (Appears on: OracleTarget) </p> <p> <p>OracleTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>oracleApiPrivateKey</code>   SecretValueFromSource     <p>Oracle User API private key.</p>     <code>oracleApiPrivateKeyPassphrase</code>   SecretValueFromSource     <p>Oracle User API private key passphrase.</p>     <code>oracleApiPrivateKeyFingerprint</code>   SecretValueFromSource     <p>Oracle User API cert fingerprint.</p>     <code>oracleTenancy</code>  string    <p>Oracle Tenancy OCID.</p>     <code>oracleUser</code>  string    <p>Oracle User OCID associated with the API key.</p>     <code>oracleRegion</code>  string    <p>Oracle Cloud Region.</p>     <code>function</code>   OracleFunctionSpecSpec         <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.OracleTargetSpec"},{"title":"SalesforceAuth","text":"<p> (Appears on: SalesforceTargetSpec) </p> <p> <p>SalesforceAuth contains OAuth JWT information to interact with the Salesforce API. See: https://help.salesforce.com/s/articleView?id=sf.remoteaccess_oauth_jwt_flow.htm</p> </p>    Field Description      <code>clientID</code>  string    <p>ClientID for the Salesforce connected app.</p>     <code>server</code>  string    <p>Server points to the authorization URL.</p>     <code>user</code>  string    <p>User configuring the connected app.</p>     <code>certKey</code>   SecretValueFromSource     <p>CertKey is the private key used to sign requests from the target.</p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.SalesforceAuth"},{"title":"SalesforceTargetSpec","text":"<p> (Appears on: SalesforceTarget) </p> <p> <p>SalesforceTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>auth</code>   SalesforceAuth     <p>Authentication information to interact with the Salesforce API.</p>     <code>apiVersion</code>  string    (Optional) <p>APIVersion at Salesforce. If not set the latest version will be used.</p>     <code>eventOptions</code>   EventOptions     (Optional) <p>EventOptions for targets</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.SalesforceTargetSpec"},{"title":"SecretValueFromSource","text":"<p> (Appears on: AWSComprehendTargetSpec,  AWSDynamoDBTargetSpec,  AWSEventBridgeTargetSpec,  AWSKinesisTargetSpec,  AWSLambdaTargetSpec,  AWSS3TargetSpec,  AWSSNSTargetSpec,  AWSSQSTargetSpec,  AlibabaOSSTargetSpec,  ConfluentTargetSpec,  Connection,  DatadogTargetSpec,  GoogleCloudFirestoreTargetSpec,  GoogleCloudPubSubTargetSpec,  GoogleCloudStorageTargetSpec,  GoogleCloudWorkflowsTargetSpec,  GoogleSheetTargetSpec,  HTTPTargetSpec,  HasuraTargetSpec,  JiraAuth,  LogzMetricsConnection,  LogzTargetSpec,  OracleTargetSpec,  SalesforceAuth,  SendGridTargetSpec,  SlackTargetSpec,  TwilioTargetSpec,  UiPathTargetSpec,  ZendeskTargetSpec) </p> <p> <p>SecretValueFromSource represents the source of a secret value</p> </p>    Field Description      <code>secretKeyRef</code>   Kubernetes core/v1.SecretKeySelector     <p>The Secret key to select from.</p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.SecretValueFromSource"},{"title":"SendGridTargetSpec","text":"<p> (Appears on: SendGridTarget) </p> <p> <p>SendGridTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>apiKey</code>   SecretValueFromSource     <p>APIKey for account</p>     <code>defaultFromEmail</code>  string    (Optional) <p>DefaultFromEmail is a default email account to assign to the outgoing email\u2019s.</p>     <code>defaultToEmail</code>  string    (Optional) <p>DefaultToEmail is a default recipient email account to assign to the outgoing email\u2019s.</p>     <code>defaultToName</code>  string    (Optional) <p>DefaultToName is a default recipient name to assign to the outgoing email\u2019s.</p>     <code>defaultFromName</code>  string    (Optional) <p>DefaultFromName is a default sender name to assign to the outgoing email\u2019s.</p>     <code>defaultMessage</code>  string    (Optional) <p>DefaultMessage is a default message to assign to the outgoing email\u2019s.</p>     <code>defaultSubject</code>  string    (Optional) <p>DefaultSubject is a default subject to assign to the outgoing email\u2019s.</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.SendGridTargetSpec"},{"title":"SlackTargetSpec","text":"<p> (Appears on: SlackTarget) </p> <p> <p>SlackTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>token</code>   SecretValueFromSource     <p>Token for Slack App</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.SlackTargetSpec"},{"title":"SplunkTargetSpec","text":"<p> (Appears on: SplunkTarget) </p> <p> <p>SplunkTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>endpoint</code>   knative.dev/pkg/apis.URL     <p>URL of the HTTP Event Collector (HEC). Only the scheme, hostname, and port (optionally) are evaluated, the URL path is trimmed if present. see https://docs.splunk.com/Documentation/Splunk/latest/Data/UsetheHTTPEventCollector#Enable_HTTP_Event_Collector</p>     <code>token</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.ValueFromField     <p>Token for authenticating requests against the HEC. see https://docs.splunk.com/Documentation/Splunk/latest/Data/UsetheHTTPEventCollector#About_Event_Collector_tokens</p>     <code>index</code>  string    (Optional) <p>Name of the index to send events to. When undefined, events are sent to the default index defined in the HEC token\u2019s configuration.</p>     <code>skipTLSVerify</code>  bool    (Optional) <p>Controls whether the Splunk client verifies the server\u2019s certificate chain and host name when communicating over TLS.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.SplunkTargetSpec"},{"title":"TLSSpec","text":"<p> (Appears on: Credentials) </p> <p> <p>TLSSpec defines the desired state of the event target.</p> </p>    Field Description      <code>cipher</code>  string        <code>clientAuthRequired</code>  bool        <code>certLabel</code>  string        <code>keyRepository</code>   Keystore","location":"apis/targets/#targets.triggermesh.io/v1alpha1.TLSSpec"},{"title":"TektonTargetReapPolicy","text":"<p> (Appears on: TektonTargetSpec) </p> <p> <p>TektonTargetReapPolicy defines desired Repeating Policy.</p> </p>    Field Description      <code>success</code>  string    <p>ReapSuccessAge How long to wait before reaping runs that were successful</p>     <code>fail</code>  string    <p>ReapFailAge How long to wait before reaping runs that failed</p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.TektonTargetReapPolicy"},{"title":"TektonTargetSpec","text":"<p> (Appears on: TektonTarget) </p> <p> <p>TektonTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>reapPolicy</code>   TektonTargetReapPolicy     (Optional) <p>ReapPolicy dictates the reaping policy to be applied for the target</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.TektonTargetSpec"},{"title":"TwilioTargetSpec","text":"<p> (Appears on: TwilioTarget) </p> <p> <p>TwilioTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>sid</code>   SecretValueFromSource     <p>Twilio account SID</p>     <code>token</code>   SecretValueFromSource     <p>Twilio account Token</p>     <code>defaultPhoneFrom</code>  string    (Optional) <p>DefaultPhoneFrom is the purchased Twilio phone we are using</p>     <code>defaultPhoneTo</code>  string    (Optional) <p>DefaultPhoneTo is the destination phone</p>     <code>eventOptions</code>   EventOptions     <p>EventOptions for targets</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.TwilioTargetSpec"},{"title":"UiPathTargetSpec","text":"<p> (Appears on: UiPathTarget) </p> <p> <p>UiPathTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>userKey</code>   SecretValueFromSource     <p>UserKey An OAuth token used to obtain an access key.</p>     <code>robotName</code>  string    <p>RobotName is the robot to invoke with this target.</p>     <code>processName</code>  string    <p>ProccessName is the process name that will be used by UiPath for the target.</p>     <code>tenantName</code>  string    <p>TenantName is the tenant that contains the components that will be invoked by the target.</p>     <code>accountLogicalName</code>  string    <p>AccountLogicalName is the unique site URL used to identif the UiPath tenant.</p>     <code>clientID</code>  string    <p>ClientID is the OAuth id registered to this target.</p>     <code>organizationUnitID</code>  string    <p>OrganizationUnitID is the organization unit within the tenant that the UiPath proccess will run under.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.UiPathTargetSpec"},{"title":"ZendeskTargetSpec","text":"<p> (Appears on: ZendeskTarget) </p> <p> <p>ZendeskTargetSpec defines the desired state of the event target.</p> </p>    Field Description      <code>token</code>   SecretValueFromSource     <p>Token contains the Zendesk account Token.</p>     <code>subdomain</code>  string    <p>Subdomain the Zendesk subdomain.</p>     <code>email</code>  string    <p>Email the registered Zendesk email account.</p>     <code>subject</code>  string    (Optional) <p>Subject a static subject assignemnt for every ticket.</p>     <code>adapterOverrides</code>   github.com/triggermesh/triggermesh/pkg/apis/common/v1alpha1.AdapterOverrides     (Optional) <p>Adapter spec overrides parameters.</p>      <p> Generated with <code>gen-crd-api-reference-docs</code> on git commit <code>b22c2e53</code>. </p>","location":"apis/targets/#targets.triggermesh.io/v1alpha1.ZendeskTargetSpec"},{"title":"TriggerMesh Enterprise","text":"<p>TriggerMesh Enterprise builds on the TriggerMesh Open Source Platform</p> <p>TriggerMesh Enterprise provides additional capabilities such as:</p> <ul> <li>Powerful web interface</li> <li>Administration dashboard</li> <li>Integration visual editor</li> <li>Single sign-on</li> <li>Custom connectors builder</li> <li>Knative distribution</li> </ul> <p>If you want to know more, contact us at info@triggermesh.com</p>","location":"cloud/"},{"title":"Preview","text":"<p>The following screenshots give you a preview of what the TriggerMesh interface looks like.</p> <p></p> <p>Once logged in you have acess to the Dashboard.</p> <p></p> <p>If you want to use our command line client keep reading...</p>","location":"cloud/#preview"},{"title":"For CLI Lovers","text":"<p>If you would prefer to use a CLI, we have prepared <code>tm</code> for you.</p> <p><code>tm</code> is a generic Knative client with some added features to deploy functions from source. You can download <code>tm</code> by following our instructions</p> <p>For example you will be able to bypass the console and do something like this:</p> <pre><code>tm deploy service hello -f gcr.io/google-samples/hello-app:1.0\n</code></pre>","location":"cloud/#for-cli-lovers"},{"title":"Bridge","text":"<p>Each bridge created within the TM console operates via the following <code>flow</code>:</p> <ol> <li>An event source retrieves data. </li> <li>A broker to act as an event bucket</li> <li>A trigger that subscribes the Target to receive events from the broker.</li> <li>A target that receives events. </li> </ol> <p></p>","location":"cloud/bridge/"},{"title":"Creating a New Bridge","text":"<p>For this example a small service called Event Display is used as the <code>Target</code>. <code>Event Display</code> prints all the messages it receives into a log.</p> <ul> <li>From the Bridges view. Select <code>Create New</code></li> </ul> <p></p> <ul> <li>Select <code>Create a new Bridge</code>.</li> </ul> <p></p> <ul> <li>Select <code>Sources</code></li> </ul> <p></p> <ul> <li>Select <code>CronJob</code> from the popup menu.</li> </ul> <p></p> <ul> <li>Give it a name such as \"test-cron\", a Cron Schedule of every minute (or /1 *  * *), and keep the <code>Cron data</code> set at <code>{\"foo\": \"bar\"}</code>.</li> </ul> <p></p> <p>Before configuring a Bridge, normally, a Target would be created or pre-existing, because this example assumes a fresh TM console, There are no services currently deployed so a detour to the <code>Target</code> section is required.  * Select <code>Service</code> here.</p> <p></p> <ul> <li>Select <code>Create New</code> from the <code>Existing Service</code> dropdown.</li> </ul> <p></p> <ul> <li>Select <code>Image Catalog</code>, then <code>Event display</code>, and finally <code>SAVE</code></li> </ul> <p></p> <p>This will complete the flow from Source to Trigger automatically for us by creating an <code>auto-trigger</code>.</p> <ul> <li>We can finish now by selecting <code>SUBMIT BRIDGE</code> from the top right corner.</li> </ul> <p></p> <ul> <li>To verify the functionality of the bridge, navigate to the Services section.</li> </ul> <p></p> <ul> <li>The <code>event display</code> service that was created with the bridge will be shown. When that is clicked, there will be a page showing the details of the service.</li> </ul> <p></p> <ul> <li>When the <code>PODS</code> link is selected, the a list of associated pods will be shown. There is only one, but if you click the button that says \"Logs\" on the far right side of the list, then the log for that event will be displayed. </li> </ul> <p></p> <ul> <li>We now can see the log for that event. </li> </ul> <p></p>","location":"cloud/bridge/#creating-a-new-bridge"},{"title":"Highlighted Bridges","text":"<ul> <li>Slack to Confluent: learn how to subscribe to events at Slack and get them delivered to a Confluent Kafka cluster.</li> </ul>","location":"cloud/bridge/#highlighted-bridges"},{"title":"Secrets","text":"<p>The TriggerMesh console provides a central location to view and store sensitive information called <code>Secrets.</code> The secrets created here can then be used by any service deployed via the TriggerMesh platform.</p> <p>From the Secrets view. Select <code>Create New</code>. Selecting the button here will give you a choice to create various secrets (e.g AWS, GitHub, GitLab, GCP)</p> <p></p>","location":"cloud/secrets/"},{"title":"AWS API Keys","text":"<p>All the AWS event sources need access to some AWS API credentials to be able to establish a secure connection.</p> <p>You should create a AWS IAM user and generate a dedicated set of API credentials with only the proper permissions. Once you are ready to create your secret, click on <code>AWS</code>.</p> <p></p> <p>Once you do so, you can create a secret with the AWS specific wizard shown below:</p> <p></p> <p>The secret name is pre-configured to be <code>aws</code>, but you can edit this name when you are creating a new secret. The keys are <code>aws_access_key_id</code> and <code>aws_secrets_access_key</code>.</p>","location":"cloud/secrets/#aws-api-keys"},{"title":"Using a Secret in a Service Definition","text":"<p>If your service needs access to a secret, you can load it in a service definition through the Service creation wizard.</p> <p>Select <code>Advanced Configuration</code>, a pane will expand and at the bottom you will be able to select the secrets that you want your service to use.</p> <p></p>","location":"cloud/secrets/#using-a-secret-in-a-service-definition"},{"title":"Using a Secret in a Source Definition","text":"<p>When you deploy a new event source, that source may need a secret to access an external API. A dropdown menu is available in the source configuration which will let you choose the pre-created secret.</p> <p></p>","location":"cloud/secrets/#using-a-secret-in-a-source-definition"},{"title":"Accessing Your Secrets with <code>kubectl</code>","text":"<p>These secrets are stored as Kubernetes secrets and protected via RBAC rules.</p> <p>You can interact with your secrets using <code>kubectl</code> and the configuration downloaded for using <code>tm</code>.</p> <pre><code>kubectl --kubeconfig=config.json -n &lt;your_login_username&gt; get secrets\n</code></pre>","location":"cloud/secrets/#accessing-your-secrets-with-kubectl"},{"title":"Secrets","text":"<p>The TriggerMesh console provides a central location to view and store sensitive information called <code>Secrets.</code> The secrets created here can then be used by any service deployed via the TriggerMesh platform.</p> <p>From the Secrets view. Select <code>Create New</code>. Selecting the button here will give you a choice to create various secrets (e.g AWS, GitHub, GitLab, GCP)</p> <p></p>","location":"cloud/guides/secrets/"},{"title":"AWS API Keys","text":"<p>All the AWS event sources need access to some AWS API credentials to be able to establish a secure connection.</p> <p>You should create a AWS IAM user and generate a dedicated set of API credentials with only the proper permissions. Once you are ready to create your secret, click on <code>AWS</code>.</p> <p></p> <p>Once you do so, you can create a secret with the AWS specific wizard shown below:</p> <p></p> <p>The secret name is pre-configured to be <code>aws</code>, but you can edit this name when you are creating a new secret. The keys are <code>aws_access_key_id</code> and <code>aws_secrets_access_key</code>.</p>","location":"cloud/guides/secrets/#aws-api-keys"},{"title":"Using a Secret in a Service Definition","text":"<p>If your service needs access to a secret, you can load it in a service definition through the Service creation wizard.</p> <p>Select <code>Advanced Configuration</code>, a pane will expand and at the bottom you will be able to select the secrets that you want your service to use.</p> <p></p>","location":"cloud/guides/secrets/#using-a-secret-in-a-service-definition"},{"title":"Using a Secret in a Source Definition","text":"<p>When you deploy a new event source, that source may need a secret to access an external API. A dropdown menu is available in the source configuration which will let you choose the pre-created secret.</p> <p></p>","location":"cloud/guides/secrets/#using-a-secret-in-a-source-definition"},{"title":"Accessing Your Secrets with <code>kubectl</code>","text":"<p>These secrets are stored as Kubernetes secrets and protected via RBAC rules.</p> <p>You can interact with your secrets using <code>kubectl</code> and the configuration downloaded for using <code>tm</code>.</p> <pre><code>kubectl --kubeconfig=config.json -n &lt;your_login_username&gt; get secrets\n</code></pre>","location":"cloud/guides/secrets/#accessing-your-secrets-with-kubectl"},{"title":"Event Source for AWS CodeCommit","text":"<p>This event source captures notifications from an AWS CodeCommit repository whenever a specific action, such as a new commit or the creation of a pull request, happens in this repository.</p>","location":"cloud/sources/awscodecommit/"},{"title":"Prerequisite(s)","text":"<ul> <li>CodeCommit Repository and Branch</li> <li>Amazon Resource Name (ARN)</li> <li>API Credentials</li> </ul>","location":"cloud/sources/awscodecommit/#prerequisites"},{"title":"CodeCommit Repository and Branch","text":"<p>If you don't already have an AWS CodeCommit repository, create one by following the instructions at Create an AWS CodeCommit repository. The repository should contain at least one branch. To create one, follow the instructions at Create a branch in AWS CodeCommit.</p> <p></p>","location":"cloud/sources/awscodecommit/#codecommit-repository-and-branch"},{"title":"Amazon Resource Name (ARN)","text":"<p>A fully qualified ARN is required to uniquely identify the AWS CodeCommit repository.</p> <p>The easiest way to obtain the ARN of a CodeCommit repository is by using the AWS CLI. The following command retrieves the information of a repository called <code>triggermeshtest</code> in the <code>us-west-2</code> region:</p> <pre><code>$ aws codecommit get-repository --repository-name triggermeshtest --region us-west-2\n{\n    \"repositoryMetadata\": {\n        \"accountId\": \"123456789012\",\n        \"repositoryId\": \"510acd3d-b96d-473c-bbe4-a8c6799d02a9\",\n        \"repositoryName\": \"triggermeshtest\",\n        \"defaultBranch\": \"main\",\n        \"lastModifiedDate\": \"2020-07-20T20:54:27.806000+02:00\",\n        \"creationDate\": \"2020-07-20T20:49:12.324000+02:00\",\n        \"cloneUrlHttp\": \"https://git-codecommit.eu-central-1.amazonaws.com/v1/repos/triggermeshtest\",\n        \"cloneUrlSsh\": \"ssh://git-codecommit.eu-central-1.amazonaws.com/v1/repos/triggermeshtest\",\n        \"Arn\": \"arn:aws:codecommit:eu-central-1:123456789012:triggermeshtest\"\n    }\n}\n</code></pre> <p>If you don't have the AWS CLI installed on your workstation, you can use the template below to compose a fully qualified ARN of a CodeCommit repository.</p> <pre><code>arn:aws:codecommit:{awsRegion}:{awsAccountId}:{repositoryName}\n</code></pre>","location":"cloud/sources/awscodecommit/#amazon-resource-name-arn"},{"title":"API Credentials","text":"<p>The TriggerMesh event source for Amazon CodeCommit authenticates calls to the AWS API using AWS Access Keys. The page Understanding and getting your AWS credentials contains instructions to create access keys when signed-in either as the root user or as an IAM user. Take note of the Access Key ID and Secret Access Key, they will be used to create an instance of the event source.</p> <p>It is considered a good practice to create dedicated users with restricted privileges in order to programmatically access AWS services. Permissions can be added or revoked granularly for a given IAM user by attaching IAM Policies to it.</p> <p>As an example, the following policy contains only the permissions required by the TriggerMesh AWS CodeCommit event source to operate:</p> <pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"codecommit:GetBranch\",\n                \"codecommit:GetCommit\",\n                \"codecommit:ListPullRequests\",\n                \"codecommit:GetPullRequest\"\n            ],\n            \"Resource\": \"arn:aws:codecommit:*:*:*\"\n        }\n    ]\n}\n</code></pre> <p></p>","location":"cloud/sources/awscodecommit/#api-credentials"},{"title":"Deploying an Instance of the Source","text":"<p>Open the Bridge creation screen and add a source of type <code>AWS CodeCommit</code>.</p> <p></p> <p>In the Source creation form, give a name to the event source and add the following information:</p> <ul> <li>AWS ARN: ARN of the CodeCommit repository, as described in the previous sections.</li> <li>Branch name: Name of the Git branch the source should be watching for commits.</li> <li>Event types: List of event types the event source should subscribe to.</li> <li>AWS Secret: Reference to a TriggerMesh secret containing an Access Key ID and a Secret   Access Key to communicate with the AWS CodeCommit API, as described in the previous sections.</li> </ul> <p></p> <p>After clicking the <code>Save</code> button, you will be taken back to the Bridge editor. Proceed to adding the remaining components to the Bridge, then submit it.</p> <p></p> <p>A ready status on the main Bridges page indicates that the event source is ready to receive notifications from the AWS CodeCommit repository.</p> <p></p>","location":"cloud/sources/awscodecommit/#deploying-an-instance-of-the-source"},{"title":"Event Types","text":"<p>The AWS CodeCommit event source emits events of the following types:</p> <ul> <li><code>com.amazon.codecommit.push</code></li> <li><code>com.amazon.codecommit.pull_request</code></li> </ul>","location":"cloud/sources/awscodecommit/#event-types"},{"title":"Event source for Amazon Cognito User Pools","text":"<p>This event source captures messages from an Amazon Cognito User Pool whenever a specific action, such as the creation of a new user, happens in the user identity pool.</p>","location":"cloud/sources/awscognitouserpool/"},{"title":"Prerequisite(s)","text":"<ul> <li>Amazon Cognito User Pool</li> <li>Amazon Resource Name (ARN)</li> <li>API Credentials</li> </ul>","location":"cloud/sources/awscognitouserpool/#prerequisites"},{"title":"Amazon Cognito User Pool","text":"<p>If you don't already have an Amazon Cognito User Pool, create one by following the instructions in the Getting started with User Pools guide.</p>","location":"cloud/sources/awscognitouserpool/#amazon-cognito-user-pool"},{"title":"Amazon Resource Name (ARN)","text":"<p>A fully qualified ARN is required to uniquely identify the Amazon Cognito User Pool.</p> <p></p> <p>As shown in the above screenshot, you can obtain the ARN of a User Pool from the AWS console. It typically has the following format:</p> <pre><code>arn:aws:cognito-idp:{awsRegion}:{awsAccountId}:userpool/{poolId}\n</code></pre> <p>Alternatively you can also use the [AWS CLI][aws-cli]. The following command retrieves the ARN of a User Pool in the <code>us-west-2</code> region which has the pool id <code>us-west-2_fak3p001B</code>.</p> <pre><code>$ aws --region us-west-2 cognito-idp describe-user-pool --user-pool-id us-west-2_fak3p001B\n{\n    \"UserPool\": {\n        \"Id\": \"us-west-2_fak3p001B\",\n        ...\n        \"Arn\": \"arn:aws:cognito-idp:us-west-2:043455440429:userpool/us-west-2_fak3p001B\",\n        ...\n    }\n}\n</code></pre>","location":"cloud/sources/awscognitouserpool/#amazon-resource-name-arn"},{"title":"API credentials","text":"<p>The TriggerMesh event source for Amazon Cognito User Pools authenticates calls to the AWS API using AWS Access Keys. The page Understanding and getting your AWS credentials contains instructions to create access keys when signed-in either as the root user or as an IAM user. Take note of the Access Key ID and Secret Access Key, they will be used to create an instance of the event source.</p> <p>It is considered a good practice to create dedicated users with restricted privileges in order to programmatically access AWS services. Permissions can be added or revoked granularly for a given IAM user by attaching IAM Policies to it.</p> <p>As an example, the following policy contains the permissions required by the TriggerMesh Amazon Cognito User Pool event source to list users in any user pool associated with the AWS account:</p> <pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"AWSCognitoUserPoolSourceReceiveAdapter\",\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"cognito-idp:DescribeUserPool\",\n                \"cognito-idp:ListUsers\"\n            ],\n            \"Resource\": \"arn:aws:cognito-idp:*:*:userpool/*\"\n        }\n    ]\n}\n</code></pre>","location":"cloud/sources/awscognitouserpool/#api-credentials"},{"title":"Deploying an instance of the Source","text":"<p>Open the Bridge creation screen and add a source of type <code>Amazon Cognito User Pool</code>.</p> <p></p> <p>In the Source creation form, give a name to the event source and add the following information:</p> <ul> <li>Secret: Reference to a TriggerMesh secret containing an Access Key ID and a Secret   Access Key to communicate with the Amazon Cognito API, as described in the previous sections.</li> <li>AWS ARN: ARN of the User Pool, as described in the previous sections.</li> </ul> <p></p> <p>After clicking the <code>Save</code> button, you will be taken back to the Bridge editor. Proceed to adding the remaining components to the Bridge, then submit it.</p> <p></p> <p>A ready status on the main Bridges page indicates that the event source is ready to receive notifications from the Amazon Cognito User Pool.</p> <p></p>","location":"cloud/sources/awscognitouserpool/#deploying-an-instance-of-the-source"},{"title":"Event Types","text":"<p>The Amazon Cognito User Pool event source emits events of the following type:</p> <ul> <li><code>com.amazon.cognito-idp.sync_trigger</code></li> </ul>","location":"cloud/sources/awscognitouserpool/#event-types"},{"title":"Event Source for Amazon DynamoDB","text":"<p>This event source captures changes to items stored in an Amazon DynamoDB Table by reading the time-ordered sequence of item-level modifications from a DynamoDB Stream.</p>","location":"cloud/sources/awsdynamodb/"},{"title":"Prerequisite(s)","text":"<ul> <li>DynamoDB Table and Stream</li> <li>Amazon Resource Name (ARN)</li> <li>API Credentials</li> </ul>","location":"cloud/sources/awsdynamodb/#prerequisites"},{"title":"DynamoDB Table and Stream","text":"<p>If you don't already have an Amazon DynamoDB Table, create one by following the instructions at Getting Started with DynamoDB. In order for change notifications to be consumed by the TriggerMesh Amazon DynamoDB event source, it is mandatory to enable a Stream on the DynamoDB Table. To do so, follow the instructions at Enabling a Stream. You are free to select the View type that is the most suitable for your own usage of the event source.</p> <p></p>","location":"cloud/sources/awsdynamodb/#dynamodb-table-and-stream"},{"title":"Amazon Resource Name (ARN)","text":"<p>A fully qualified ARN is required to uniquely identify the Amazon DynamoDB Table.</p> <p>This ARN can be obtained directly from the Overview tab after clicking the DynamoDB Table name in the list of existing tables. It typically has the following format:</p> <pre><code>arn:aws:dynamodb:{awsRegion}:{awsAccountId}:table/{tableName}\n</code></pre> <p></p> <p>Alternatively, one can obtain the ARN of a DynamoDB Table by using the AWS CLI. The following command retrieves the information of a table called <code>triggermeshtest</code> in the <code>us-west-2</code> region:</p> <pre><code>$ aws dynamodb describe-table --table-name triggermeshtest --region us-west-2\n{\n    \"Table\": {\n        \"TableName\": \"triggermeshtest\",\n        \"TableStatus\": \"ACTIVE\",\n        \"TableArn\": \"arn:aws:dynamodb:us-west-2:123456789012:table/triggermeshtest\",\n        (...)\n    }\n}\n</code></pre>","location":"cloud/sources/awsdynamodb/#amazon-resource-name-arn"},{"title":"API Credentials","text":"<p>The TriggerMesh event source for Amazon DynamoDB authenticates calls to the AWS API using AWS Access Keys. The page Understanding and getting your AWS credentials contains instructions to create access keys when signed-in either as the root user or as an IAM user. Take note of the Access Key ID and Secret Access Key, they will be used to create an instance of the event source.</p> <p>It is considered a good practice to create dedicated users with restricted privileges in order to programmatically access AWS services. Permissions can be added or revoked granularly for a given IAM user by attaching IAM Policies to it.</p> <p>As an example, the following policy contains only the permissions required by the TriggerMesh Amazon DynamoDB event source to operate:</p> <pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"dynamodb:ListStreams\",\n                \"dynamodb:DescribeStream\",\n                \"dynamodb:GetShardIterator\",\n                \"dynamodb:GetRecords\"\n            ],\n            \"Resource\": \"arn:aws:dynamodb:*:*:*\"\n        }\n    ]\n}\n</code></pre> <p></p>","location":"cloud/sources/awsdynamodb/#api-credentials"},{"title":"Deploying an Instance of the Source","text":"<p>Open the Bridge creation screen and add a source of type <code>Amazon DynamoDB</code>.</p> <p></p> <p>In the Source creation form, give a name to the event source and add the following information:</p> <ul> <li>AWS ARN: ARN of the DynamoDB Table, as described in the previous sections.</li> <li>AWS Secret: Reference to a TriggerMesh secret containing an Access Key ID and a Secret   Access Key to communicate with the Amazon DynamoDB API, as described in the previous sections.</li> </ul> <p></p> <p>After clicking the <code>Save</code> button, you will be taken back to the Bridge editor. Proceed to adding the remaining components to the Bridge, then submit it.</p> <p></p> <p>A ready status on the main Bridges page indicates that the event source is ready to receive notifications from the Amazon DynamoDB Stream.</p> <p></p>","location":"cloud/sources/awsdynamodb/#deploying-an-instance-of-the-source"},{"title":"Event Types","text":"<p>The Amazon DynamoDB event source emits events of the following type:</p> <ul> <li><code>com.amazon.dynamodb.stream_record</code></li> </ul>","location":"cloud/sources/awsdynamodb/#event-types"},{"title":"Event Source for Amazon Kinesis","text":"<p>This event source acts as a consumer of an Amazon Kinesis Data Stream and forwards all messages it reads after wrapping them in a CloudEvent envelope.</p>","location":"cloud/sources/awskinesis/"},{"title":"Prerequisite(s)","text":"<ul> <li>Kinesis Data Stream</li> <li>Amazon Resource Name (ARN)</li> <li>API Credentials</li> </ul>","location":"cloud/sources/awskinesis/#prerequisites"},{"title":"Kinesis Data Stream","text":"<p>If you don't already have an Amazon Kinesis Data Stream, create one by following the instructions at Creating and Updating Data Streams.</p>","location":"cloud/sources/awskinesis/#kinesis-data-stream"},{"title":"Amazon Resource Name (ARN)","text":"<p>A fully qualified ARN is required to uniquely identify the Amazon Kinesis Stream.</p> <p>This ARN can be obtained directly from the overview page of the Kinesis Stream. It typically has the following format:</p> <pre><code>arn:aws:kinesis:{awsRegion}:{awsAccountId}:stream/{steamName}\n</code></pre> <p></p> <p>Alternatively, one can obtain the ARN of a Kinesis Stream by using the AWS CLI. The following command retrieves the information of a stream called <code>triggermeshtest</code> in the <code>us-west-2</code> region:</p> <pre><code>$ aws kinesis describe-stream --stream-name triggermeshtest --region us-west-2\n{\n    \"StreamDescription\": {\n        \"StreamARN\": \"arn:aws:kinesis:us-west-2:123456789012:stream/triggermeshtest\",\n        \"StreamName\": \"triggermeshtest\",\n        \"StreamStatus\": \"ACTIVE\",\n        (...)\n    }\n}\n</code></pre>","location":"cloud/sources/awskinesis/#amazon-resource-name-arn"},{"title":"API Credentials","text":"<p>The TriggerMesh event source for Amazon Kinesis authenticates calls to the AWS API using AWS Access Keys. The page Understanding and getting your AWS credentials contains instructions to create access keys when signed-in either as the root user or as an IAM user. Take note of the Access Key ID and Secret Access Key, they will be used to create an instance of the event source.</p> <p>It is considered a good practice to create dedicated users with restricted privileges in order to programmatically access AWS services. Permissions can be added or revoked granularly for a given IAM user by attaching IAM Policies to it.</p> <p>As an example, the following policy contains only the permissions required by the TriggerMesh Amazon Kinesis event source to operate:</p> <pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"kinesis:DescribeStream\",\n                \"kinesis:GetShardIterator\",\n                \"kinesis:GetRecords\"\n            ],\n            \"Resource\": \"arn:aws:kinesis:*:*:*\"\n        }\n    ]\n}\n</code></pre> <p></p>","location":"cloud/sources/awskinesis/#api-credentials"},{"title":"Deploying an Instance of the Source","text":"<p>Open the Bridge creation screen and add a source of type <code>Amazon Kinesis</code>.</p> <p></p> <p>In the Source creation form, give a name to the event source and add the following information:</p> <ul> <li>AWS ARN: ARN of the Kinesis Data Stream, as described in the previous sections.</li> <li>AWS Secret: Reference to a TriggerMesh secret containing an Access Key ID and a Secret   Access Key to communicate with the Amazon Kinesis API, as described in the previous sections.</li> </ul> <p></p> <p>After clicking the <code>Save</code> button, you will be taken back to the Bridge editor. Proceed to adding the remaining components to the Bridge, then submit it.</p> <p></p> <p>A ready status on the main Bridges page indicates that the event source is ready to forward messages from the Amazon Kinesis Data Stream.</p> <p></p>","location":"cloud/sources/awskinesis/#deploying-an-instance-of-the-source"},{"title":"Event Types","text":"<p>The Amazon Kinesis event source emits events of the following types:</p> <ul> <li><code>com.amazon.kinesis.stream_record</code></li> </ul>","location":"cloud/sources/awskinesis/#event-types"},{"title":"Event Source for Amazon S3","text":"<p>This event source subscribes to event notifications from an Amazon S3 bucket. Events are published by S3 to an Amazon SQS queue in order to be consumable by the event source.</p>","location":"cloud/sources/awss3/"},{"title":"Prerequisite(s)","text":"<ul> <li>S3 Bucket</li> <li>Amazon Resource Name (ARN)</li> <li>API Credentials</li> <li>SQS Queue (optional)</li> </ul>","location":"cloud/sources/awss3/#prerequisites"},{"title":"S3 Bucket","text":"<p>If you didn't already do so, create a S3 bucket by following the instructions at Create your first S3 bucket.</p>","location":"cloud/sources/awss3/#s3-bucket"},{"title":"Amazon Resource Name (ARN)","text":"<p>A fully qualified ARN is required to uniquely identify the Amazon S3 bucket.</p>  <p>Note</p> <p>Although not technically required by S3, the ARN provided to this event source may include an AWS region and account ID, in addition to the bucket name. When this information is provided, it is used to set an accurate identity-based access policy between the S3 bucket and the reconciled SQS queue, unless a user-managed queue is provided as described in the SQS Queue section of this document.</p> <p>The format of such ARN is:</p> <pre><code>arn:aws:s3:{aws_region}:{aws_account_id}:{bucket_name}\n</code></pre> <p>This information is purely optional and will be determined automatically if not provided.</p>  <p></p>","location":"cloud/sources/awss3/#amazon-resource-name-arn"},{"title":"API Credentials","text":"<p>The TriggerMesh event source for Amazon S3 authenticates calls to the AWS API using AWS Access Keys. The page Understanding and getting your AWS credentials contains instructions to create access keys when signed-in either as the root user or as an IAM user. Take note of the Access Key ID and Secret Access Key, they will be used to create an instance of the event source.</p> <p>It is considered a good practice to create dedicated users with restricted privileges in order to programmatically access AWS services. Permissions can be added or revoked granularly for a given IAM user by attaching IAM Policies to it.</p> <p>As an example, the following policy contains only the permissions required by the Amazon S3 event source to operate:</p> <pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"S3SourceSetBucketConfig\",\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"s3:GetBucketNotification\",\n                \"s3:PutBucketNotification\"\n            ],\n            \"Resource\": \"arn:aws:s3:::*\"\n        },\n        {\n            \"Sid\": \"S3SourceConsumeMessages\",\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"sqs:GetQueueUrl\",\n                \"sqs:ReceiveMessage\",\n                \"sqs:DeleteMessage\"\n            ],\n            \"Resource\": \"arn:aws:sqs:*:*:*\"\n        }\n    ]\n}\n</code></pre> <p>Additionally, the following permissions are also required if you opt for letting the event source manage the SQS queue for you (see next section for more information):</p> <pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"S3SourceGetBucketLocation\",\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"s3:GetBucketLocation\"\n            ],\n            \"Resource\": \"arn:aws:s3:::*\"\n        },\n        {\n            \"Sid\": \"S3SourceManageQueue\",\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"sqs:CreateQueue\",\n                \"sqs:DeleteQueue\",\n                \"sqs:GetQueueAttributes\",\n                \"sqs:SetQueueAttributes\",\n                \"sqs:GetQueueUrl\",\n                \"sqs:ListQueueTags\",\n                \"sqs:TagQueue\"\n            ],\n            \"Resource\": \"arn:aws:sqs:*:*:*\"\n        }\n    ]\n}\n</code></pre> <p></p>","location":"cloud/sources/awss3/#api-credentials"},{"title":"SQS Queue (optional)","text":"<p>The TriggerMesh event source for Amazon S3 configures the S3 bucket to send event notifications to an Amazon SQS queue.</p> <p>By default, the source creates and manages a SQS queue for that purpose on behalf of the user. An identity-based policy is set on that SQS queue to only accept messages originating from the configured S3 bucket.</p> <p>Alternatively, in case you prefer not to delegate this responsibility to the event source, it is possible to provide your own SQS queue as an event destination. In this scenario, it is your own responsibility to configure the queue according to Amazon's documentation: Configuring a bucket for notifications.</p>","location":"cloud/sources/awss3/#sqs-queue-optional"},{"title":"Deploying an Instance of the Source","text":"<p>Open the Bridge creation screen and add a source of type <code>Amazon S3</code>.</p> <p></p> <p>In the Source creation form, give a name to the event source and add the following information:</p> <ul> <li>Source secret: Reference to a TriggerMesh secret containing an Access Key ID and a   Secret Access Key to communicate with the AWS API, as described in the previous sections.</li> <li>Bucket ARN: ARN of the S3 bucket, as described in the previous sections.</li> <li>Queue ARN: (optional) ARN of the SQS queue which acts as event destination, in case you prefer to manage   this queue yourself as described in the previous sections.</li> <li>Event types: List of event types to subscribe to.</li> </ul> <p></p> <p>After clicking the <code>Save</code> button, you will be taken back to the Bridge editor. Proceed by adding the remaining components to the Bridge, then submit it.</p> <p></p> <p>A ready status on the main Bridges page indicates that the event source is ready to receive notifications from the Amazon S3 bucket.</p> <p></p> <p>This can be confirmed by navigating to the Properties tab of the S3 bucket in the AWS console, and ensuring that it contains a new Event Notification targeting the SQS queue.</p> <p></p>","location":"cloud/sources/awss3/#deploying-an-instance-of-the-source"},{"title":"Event Types","text":"<p>The TriggerMesh event source for Amazon S3 emits events of the following types:</p> <ul> <li><code>com.amazon.s3.objectcreated</code></li> <li><code>com.amazon.s3.objectremoved</code></li> <li><code>com.amazon.s3.objectrestore</code></li> <li><code>com.amazon.s3.reducedredundancylostobject</code></li> <li><code>com.amazon.s3.replication</code></li> <li><code>com.amazon.s3.testevent</code></li> </ul>","location":"cloud/sources/awss3/#event-types"},{"title":"Event Source for Amazon SNS","text":"<p>This event source subscribes to messages from a Amazon SNS topic and sends them as CloudEvents to an event sink.</p>","location":"cloud/sources/awssns/"},{"title":"Prerequisite(s)","text":"<ul> <li>SNS Topic (standard)</li> <li>Amazon Resource Name (ARN)</li> <li>API Credentials</li> </ul>","location":"cloud/sources/awssns/#prerequisites"},{"title":"SNS Topic (standard)","text":"<p>If you don't already have an Amazon SNS standard topic, create one by following the instructions in the Getting started with Amazon SNS guide.</p>","location":"cloud/sources/awssns/#sns-topic-standard"},{"title":"Amazon Resource Name (ARN)","text":"<p>A fully qualified ARN is required to uniquely identify the Amazon SNS topic.</p> <p></p> <p>As shown in the above screenshot, you can obtain the ARN of a SNS topic from the AWS console. It typically has the following format:</p> <pre><code>arn:aws:sns:{awsRegion}:{awsAccountId}:{topicName}\n</code></pre> <p>Alternatively you can also use the AWS CLI. The following command retrieves the ARN of a SNS topic named <code>MyTopic</code> in the <code>us-west-2</code> region.</p> <pre><code>$ aws --region us-west-2 sns list-topics\n{\n    \"Topics\": [\n        ...\n        {\n            \"TopicArn\": \"arn:aws:sns:us-west-2:123456789012:MyTopic\"\n        },\n        ...\n    ]\n}\n</code></pre>","location":"cloud/sources/awssns/#amazon-resource-name-arn"},{"title":"API Credentials","text":"<p>The TriggerMesh event source for Amazon SNS authenticates calls to the AWS API using AWS Access Keys. The page Understanding and getting your AWS credentials contains instructions to create access keys when signed-in either as the root user or as an IAM user. Take note of the Access Key ID and Secret Access Key, they will be used to create an instance of the event source.</p> <p>It is considered a good practice to create dedicated users with restricted privileges in order to programmatically access AWS services. Permissions can be added or revoked granularly for a given IAM user by attaching IAM Policies to it.</p> <p>As an example, the following policy contains the permissions required by the TriggerMesh Amazon SNS event source to read and delete messages from any topic linked to the AWS account:</p> <pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"AWSSNSSourceReceiveAdapter\",\n            \"Effect\": \"Allow\",\n            \"Action\": \"sns:ConfirmSubscription\",\n            \"Resource\": \"*\"\n        },\n        {\n            \"Sid\": \"AWSSNSSourceReconciler\",\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"sns:ListSubscriptionsByTopic\",\n                \"sns:Subscribe\",\n                \"sns:Unsubscribe\"\n            ],\n            \"Resource\": \"*\"\n        }\n    ]\n}\n</code></pre> <p></p>","location":"cloud/sources/awssns/#api-credentials"},{"title":"Deploying an Instance of the Source","text":"<p>Open the Bridge creation screen and add a source of type <code>Amazon SNS</code>.</p> <p></p> <p>In the Source creation form, give a name to the event source and add the following information:</p> <ul> <li>Secret: Reference to a TriggerMesh secret containing an Access Key ID and a Secret   Access Key to communicate with the Amazon SNS API, as described in the previous sections.</li> <li>AWS ARN: ARN of the SNS topic, as described in the previous sections.</li> <li>DeliveryPolicy: Delivery policy to define how Amazon SNS retries the delivery of messages   to HTTP/S endpoints.</li> </ul> <p></p> <p>After clicking the <code>Save</code> button, you will be taken back to the Bridge editor. Proceed to adding the remaining components to the Bridge, then submit it.</p> <p></p> <p>A ready status on the main Bridges page indicates that the event source is ready to receive messages from the Amazon SNS topic.</p> <p></p>","location":"cloud/sources/awssns/#deploying-an-instance-of-the-source"},{"title":"Event Types","text":"<p>The Amazon SNS event source emits events of the following type:</p> <ul> <li><code>com.amazon.sns.notification</code></li> </ul>","location":"cloud/sources/awssns/#event-types"},{"title":"Event Source for Amazon SQS","text":"<p>The event source captures messages sent to a Amazon SQS queue and sends them as CloudEvents to an event sink.</p>","location":"cloud/sources/awssqs/"},{"title":"Prerequisite(s)","text":"<ul> <li>SQS Queue</li> <li>Amazon Resource Name (ARN)</li> <li>API Credentials</li> </ul>","location":"cloud/sources/awssqs/#prerequisites"},{"title":"SQS Queue","text":"<p>If you don't already have an Amazon SQS queue, create one by following the instructions in the Getting started with Amazon SQS guide.</p>","location":"cloud/sources/awssqs/#sqs-queue"},{"title":"Amazon Resource Name (ARN)","text":"<p>A fully qualified ARN is required to uniquely identify the Amazon SQS queue.</p> <p></p> <p>As shown in the above screenshot, you can obtain the ARN of a SQS queue from the AWS console. It typically has the following format:</p> <pre><code>arn:aws:sqs:{awsRegion}:{awsAccountId}:{queueName}\n</code></pre> <p>Alternatively you can also use the AWS CLI. The following command retrieves the ARN of a SQS queue named <code>MyQueue</code> in the <code>us-west-2</code> region.</p> <pre><code>$ aws --region us-west-2 sqs get-queue-attributes --queue-url $(aws --region us-west-2 sqs list-queues --queue-name MyQueue | jq -r .QueueUrls[0]) --attribute-names QueueArn\n{\n    \"Attributes\": {\n        \"QueueArn\": \"arn:aws:sqs:us-west-2:123456789012:MyQueue\"\n    }\n}\n</code></pre>","location":"cloud/sources/awssqs/#amazon-resource-name-arn"},{"title":"API Credentials","text":"<p>The TriggerMesh event source for Amazon SQS authenticates calls to the AWS API using AWS Access Keys. The page Understanding and getting your AWS credentials contains instructions to create access keys when signed-in either as the root user or as an IAM user. Take note of the Access Key ID and Secret Access Key, they will be used to create an instance of the event source.</p> <p>It is considered a good practice to create dedicated users with restricted privileges in order to programmatically access AWS services. Permissions can be added or revoked granularly for a given IAM user by attaching IAM Policies to it.</p> <p>As an example, the following policy contains the permissions required by the TriggerMesh Amazon SQS event source to read and delete messages from any queue linked to the AWS account:</p> <pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"AWSSQSSourceReceiveAdapter\",\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"sqs:GetQueueUrl\",\n                \"sqs:ReceiveMessage\",\n                \"sqs:DeleteMessage\"\n            ],\n            \"Resource\": [\n                \"arn:aws:sqs:*:*:*\"\n            ]\n        }\n    ]\n}\n</code></pre> <p></p>","location":"cloud/sources/awssqs/#api-credentials"},{"title":"Deploying an Instance of the Source","text":"<p>Open the Bridge creation screen and add a source of type <code>Amazon SQS</code>.</p> <p></p> <p>In the Source creation form, give a name to the event source and add the following information:</p> <ul> <li>Secret: Reference to a TriggerMesh secret containing an Access Key ID and a Secret   Access Key to communicate with the Amazon SQS API, as described in the previous sections.</li> <li>AWS ARN: ARN of the SQS queue, as described in the previous sections.</li> </ul> <p></p> <p>After clicking the <code>Save</code> button, you will be taken back to the Bridge editor. Proceed to adding the remaining components to the Bridge, then submit it.</p> <p></p> <p>A ready status on the main Bridges page indicates that the event source is ready to receive notifications from the Amazon SQS queue.</p> <p></p>","location":"cloud/sources/awssqs/#deploying-an-instance-of-the-source"},{"title":"Event Types","text":"<p>The Amazon SQS event source emits events of the following type:</p> <ul> <li><code>com.amazon.sqs.message</code></li> </ul>","location":"cloud/sources/awssqs/#event-types"},{"title":"Event Source for Azure Activity Logs","text":"<p>This event source forwards Activity Logs from a given Azure Subscription by routing them over Azure Event Hubs. It does so by registering Diagnostic Settings that automatically send a selected set of log categories to a dedicated Event Hub, then subscribing to the events from that Event Hub.</p>","location":"cloud/sources/azureactivitylogs/"},{"title":"Prerequisite(s)","text":"<ul> <li>Service Principal</li> <li>Event Hubs Namespace</li> <li>Event Hubs Instance (optional)</li> <li>Shared Access Policy / Shared Access Signature (SAS)</li> </ul>","location":"cloud/sources/azureactivitylogs/#prerequisites"},{"title":"Service Principal","text":"<p>A Service Principal is required in order to authenticate the event source against the Azure tenant that has authority over the Azure Subscription to monitor. You can create a Service Principal by following the instructions at How to: Use the portal to create an Azure AD application and service principal that can access resources.</p> <p>The section called Assign a role to the application describes how to assign permissions to the Service Principal. Make sure you select a role which has at least the following permissions:</p> <ul> <li><code>Microsoft.Insights/DiagnosticSettings/Read</code></li> <li><code>Microsoft.Insights/DiagnosticSettings/Delete</code></li> <li><code>Microsoft.Insights/DiagnosticSettings/Write</code></li> <li><code>Microsoft.EventHub/namespaces/authorizationRules/listkeys/action</code></li> </ul> <p>Additionally, assign the role <code>Azure Event Hubs Data Receiver</code> to the Service Principal to allow it to receive events from Event Hubs.</p> <p>In the example below, we create a custom IAM role that is dedicated to the TriggerMesh Activity Logs event source:</p> <p> </p> <p>The corresponding role JSON is given as a reference which you can replicate to create a similar custom IAM role:</p> <pre><code>{\n    \"properties\": {\n        \"roleName\": \"TriggerMesh Activity logs manager\",\n        \"description\": \"Allows the usage of TriggerMesh event sources for Azure Activity Logs.\",\n        \"assignableScopes\": [\n            \"/subscriptions/d2f958de-93b1-4c73-9ce0-b7e1dc43c4ba\"\n        ],\n        \"permissions\": [\n            {\n                \"actions\": [\n                    \"Microsoft.Insights/DiagnosticSettings/Read\",\n                    \"Microsoft.Insights/DiagnosticSettings/Delete\",\n                    \"Microsoft.Insights/DiagnosticSettings/Write\",\n                    \"Microsoft.EventHub/namespaces/authorizationRules/listkeys/action\"\n                ],\n                \"notActions\": [],\n                \"dataActions\": [],\n                \"notDataActions\": []\n            }\n        ]\n    }\n}\n</code></pre> <p>After the Service Principal is created and assigned suitable roles, take note of the following information:</p> <ul> <li>Tenant ID and Client ID (see Get tenant and app ID values for signing in)</li> <li>Client secret (see Create a new application secret)</li> </ul>","location":"cloud/sources/azureactivitylogs/#service-principal"},{"title":"Event Hubs Namespace","text":"<p>Follow the instructions at Quickstart: Create an Event Hub using Azure portal, and create a new Event Hubs namespace. This namespace will contain an Event Hubs instance which will be configured by the event source as the destination of Activity Logs originating from the Azure subscription.</p> <p></p>","location":"cloud/sources/azureactivitylogs/#event-hubs-namespace"},{"title":"Event Hubs Instance (optional)","text":"<p>This section can be skipped if you would like to let Azure manage the destination Event Hub. When the Event Hub's name is omitted upon deployment of the event source, Azure creates an Event Hub with the name <code>insights-activity-logs</code> upon reception of the first log entry (which can take a few minutes).</p> <p>If, however, you prefer to provide your own Event Hub for that purpose, follow the instructions at Quickstart: Create an Event Hub using Azure portal to create an Event Hubs instance. Take note of its resource ID, it is a required input to be able to run an instance of the Azure Activity Logs event source.</p> <p>A resource ID for an Event Hub has the following format:</p> <pre><code>/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.EventHub/namespaces/{namespaceName}/eventHubs/{eventHubName}\n</code></pre>  <p>Note</p> <p>The resource ID of the corresponding Event Hubs namespace is obtained by simply omitting the <code>/eventHubs/{eventHubName}</code> part of the Event Hub's resource ID.</p>  <p> </p> <p>Resource IDs can also be obtained using the Azure CLI (<code>az</code>). The following command line uses values from the screenshots above:</p> <pre><code>$ az eventhubs eventhub show --resource-group activitylogs-source-dev --namespace-name triggermesh-event-sources --name my-logs\n{\n  \"id\": \"/subscriptions/15537daf-e607-4df8-b2ef-277248b205b3/resourceGroups/activitylogs-source-dev/providers/Microsoft.EventHub/namespaces/triggermesh-event-sources/eventhubs/my-logs\",\n  \"resourceGroup\": \"activitylogs-source-dev\",\n  \"type\": \"Microsoft.EventHub/Namespaces/EventHubs\",\n  \"name\": \"my-logs\",\n  \"location\": \"East US\",\n  \"status\": \"Active\",\n  ...\n}\n</code></pre>","location":"cloud/sources/azureactivitylogs/#event-hubs-instance-optional"},{"title":"Shared Access Policy / Shared Access Signature (SAS)","text":"<p>The TriggerMesh Activity Logs event source requires a reference to the name of a Shared Access Policy (also called Shared Access Signatures). This policy contains a token that can be used to delegate permissions within an Event Hubs namespace, such as the management of Event Hub instances.</p> <p>Open your Event Hubs namespace, then open the Shared access policies panel under the Settings section of the Event Hubs screen. By default, the namespace contains a pre-created policy called <code>RootManageSharedAccessKey</code> with <code>Manage, Send, Listen</code> claims, which is perfectly suitable for the TriggerMesh Activity Logs event source. If you prefer to use your own policy instead, make sure it has the same <code>Manage, Send, Listen</code> claims as the default policy.</p> <p></p>","location":"cloud/sources/azureactivitylogs/#shared-access-policy-shared-access-signature-sas"},{"title":"Deploying an Instance of the Source","text":"<p>Open the Bridge creation screen and add a source of type <code>Azure Activity Logs</code>.</p> <p></p> <p>In the Source creation form, give a name to the event source and add the following information:</p>  <p>Note</p> <p>The ID of the Azure subscription which Activity Logs are to be subscribed to is inferred from the Event Hub ID parameter below. Therefore, the form does not require providing a subscription ID explicitly.</p>  <ul> <li>Secret: Service Principal authentication credentials, as described in the previous sections.</li> <li>Event Hub ID: Resource ID of either<ul> <li>an Event Hubs namespace (Event Hub managed by Azure, defaults to <code>insights-activity-logs</code>)</li> <li>an Event Hubs instance (Event Hub managed by the user)</li> </ul> </li> <li>SAS Policy: (optional) Name of a SAS policy with Manage permissions on the Event Hubs namespace   referenced in the Event Hub ID field. Uses Azure's default \"RootManageSharedAccessKey\" policy if not provided.</li> <li>Log categories: (optional) Categories of Activity Logs to collect. All available categories are   selected when the list of categories is left empty.</li> </ul> <p></p> <p>After clicking the <code>Save</code> button, you will be taken back to the Bridge editor. Proceed to adding the remaining components to the Bridge, then submit it.</p> <p></p> <p>A ready status on the main Bridges page indicates that the Diagnostic Settings were successfully created and that the event source is ready to route events from Event Hubs.</p> <p></p> <p>After creating a Bridge with the Azure Activity Logs event source, navigate back to the Event Hubs screen in the Azure Portal. You should see a message count above 0 within the namespace, providing that activity logs are being generated within the Azure Subscription.</p> <p></p>","location":"cloud/sources/azureactivitylogs/#deploying-an-instance-of-the-source"},{"title":"Event Types","text":"<p>The Azure Activity Logs event source emits events of the following type:</p> <ul> <li><code>com.microsoft.azure.monitor.activity-log</code></li> </ul>","location":"cloud/sources/azureactivitylogs/#event-types"},{"title":"Event Source for Azure Blob Storage","text":"<p>This event source subscribes to blob events from an Azure Storage Account through an Event Grid subscription. Events are consumed from a dedicated Event Hubs instance, which is used as event destination in this setup.</p>","location":"cloud/sources/azureblobstorage/"},{"title":"Prerequisite(s)","text":"<ul> <li>Storage Account</li> <li>Service Principal</li> <li>Event Hubs Namespace</li> <li>Event Hubs Instance (optional)</li> </ul>","location":"cloud/sources/azureblobstorage/#prerequisites"},{"title":"Storage Account","text":"<p>If you didn't already do so, create a Storage Account of one of the following supported types: General-purpose V2, BlockBlobStorage or BlobStorage. Take note of its resource ID, it is a required input to be able to run an instance of the Azure Blob Storage event source.</p> <p>A resource ID for a Storage Account has the following format:</p> <pre><code>/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.Storage/storageAccounts/{storageAccountName}\n</code></pre> <p> </p> <p>Resource IDs can also be obtained using the Azure CLI (<code>az</code>). The following command line uses values from the screenshots above:</p> <pre><code>$ az storage account show --resource-group blobstorage-source-dev --name eventsourcedev\n{\n  \"id\": \"/subscriptions/15537daf-e607-4df8-b2ef-277248b205b3/resourceGroups/blobstorage-source-dev/providers/Microsoft.Storage/storageAccounts/eventsourcedev\",\n  \"resourceGroup\": \"blobstorage-source-dev\",\n  \"type\": \"Microsoft.Storage/storageAccounts\",\n  \"kind\": \"BlobStorage\",\n  \"name\": \"eventsourcedev\",\n  \"location\": \"eastus\",\n  \"provisioningState\": \"Succeeded\",\n  ...\n}\n</code></pre>","location":"cloud/sources/azureblobstorage/#storage-account"},{"title":"Service Principal","text":"<p>A Service Principal is required in order to authenticate the event source against the Azure tenant that has authority over the Azure Subscription to monitor. You can create a Service Principal by following the instructions at How to: Use the portal to create an Azure AD application and service principal that can access resources.</p> <p>The section called Assign a role to the application describes how to assign permissions to the Service Principal. Make sure you select a role which has at least the following permissions:</p> <ul> <li><code>Microsoft.EventGrid/eventSubscriptions/read</code></li> <li><code>Microsoft.EventGrid/eventSubscriptions/write</code></li> <li><code>Microsoft.EventGrid/eventSubscriptions/delete</code></li> <li><code>Microsoft.EventHub/namespaces/eventhubs/write</code></li> </ul> <p>The following set of permissions is also required if you decide to delegate the management of the Event Hub to the event source. In case you prefer to use your own Event Hub, these can be safely be omitted. More details on that topic are provided in the Event Hubs Instance section below.</p> <ul> <li><code>Microsoft.EventHub/namespaces/eventhubs/read</code> (optional)</li> <li><code>Microsoft.EventHub/namespaces/eventhubs/delete</code> (optional)</li> </ul> <p>Additionally, assign the built-in role <code>Azure Event Hubs Data Receiver</code> to the Service Principal to allow it to receive events from an Event Hubs instance.</p> <p>In the example below, we create a custom IAM role that is dedicated to the TriggerMesh event source for Azure Blob Storage:</p> <p> </p> <p>The corresponding role JSON is given as a reference which you can replicate to create a similar custom IAM role:</p> <pre><code>{\n    \"properties\": {\n        \"roleName\": \"TriggerMesh Event Grid subscriptions manager\",\n        \"description\": \"Allows the usage of TriggerMesh event sources for Azure Blob Storage.\",\n        \"assignableScopes\": [\n            \"/subscriptions/15537daf-e607-4df8-b2ef-277248b205b3\"\n        ],\n        \"permissions\": [\n            {\n                \"actions\": [\n                    \"Microsoft.EventGrid/eventSubscriptions/read\",\n                    \"Microsoft.EventGrid/eventSubscriptions/write\",\n                    \"Microsoft.EventGrid/eventSubscriptions/delete\",\n                    \"Microsoft.EventHub/namespaces/eventhubs/read\",\n                    \"Microsoft.EventHub/namespaces/eventhubs/write\",\n                    \"Microsoft.EventHub/namespaces/eventhubs/delete\"\n                ],\n                \"notActions\": [],\n                \"dataActions\": [],\n                \"notDataActions\": []\n            }\n        ]\n    }\n}\n</code></pre> <p>After the Service Principal is created and assigned suitable roles, take note of the following information:</p> <ul> <li>Tenant ID and Client ID (see Get tenant and app ID values for signing in)</li> <li>Client secret (see Create a new application secret)</li> </ul>","location":"cloud/sources/azureblobstorage/#service-principal"},{"title":"Event Hubs Namespace","text":"<p>Follow the instructions at Quickstart: Create an Event Hub using Azure portal, and create a new Event Hubs namespace. This namespace will contain an Event Hubs instance which will be configured by the event source as the destination of events originating from the Azure Storage Account.</p> <p></p>","location":"cloud/sources/azureblobstorage/#event-hubs-namespace"},{"title":"Event Hubs Instance (optional)","text":"<p>This section can be skipped if you would like to let the event source manage its own Event Hub. In this case, please ensure you granted all necessary permissions to the Service Principal in the previous section.</p> <p>If, however, you prefer to provide your own Event Hub for that purpose, follow the instructions at Quickstart: Create an Event Hub using Azure portal to create an Event Hubs instance. Take note of its resource ID, it is a required input to be able to run an instance of the Azure Blob Storage event source.</p> <p>A resource ID for an Event Hub has the following format:</p> <pre><code>/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.EventHub/namespaces/{namespaceName}/eventHubs/{eventHubName}\n</code></pre>  <p>Note</p> <p>The resource ID of the corresponding Event Hubs namespace is obtained by simply omitting the <code>/eventHubs/{eventHubName}</code> part of the Event Hub's resource ID.</p>  <p> </p> <p>Resource IDs can also be obtained using the Azure CLI (<code>az</code>). The following command line uses values from the screenshots above:</p> <pre><code>$ az eventhubs eventhub show --resource-group blobstorage-source-dev --namespace-name eventsourcedev --name my-event-hub\n{\n  \"id\": \"/subscriptions/15537daf-e607-4df8-b2ef-277248b205b3/resourceGroups/blobstorage-source-dev/providers/Microsoft.EventHub/namespaces/eventsourcedev/eventhubs/my-event-hub\",\n  \"resourceGroup\": \"blobstorage-source-dev\",\n  \"type\": \"Microsoft.EventHub/Namespaces/EventHubs\",\n  \"name\": \"my-event-hub\",\n  \"location\": \"East US\",\n  \"status\": \"Active\",\n  ...\n}\n</code></pre>","location":"cloud/sources/azureblobstorage/#event-hubs-instance-optional"},{"title":"Deploying an Instance of the Source","text":"<p>Open the Bridge creation screen and add a source of type <code>Azure Blob Storage</code>.</p> <p></p> <p>In the Source creation form, give a name to the event source and add the following information:</p> <ul> <li>Secret: Service Principal authentication credentials, as described in the previous sections.</li> <li>Storage Account ID: Resource ID of the Storage Account.</li> <li>Event Hub ID: Resource ID of either<ul> <li>an Event Hubs namespace (Event Hub managed by the event source)</li> <li>an Event Hubs instance (Event Hub managed by the user)</li> </ul> </li> <li>Event types: (optional) List of event types to subscribe to. <code>BlobCreated</code> and <code>BlobDeleted</code> are   enabled by default when no item is set.</li> </ul> <p></p> <p>After clicking the <code>Save</code> button, you will be taken back to the Bridge editor. Proceed to adding the remaining components to the Bridge, then submit it.</p> <p></p> <p>A ready status on the main Bridges page indicates that the event subscription was successfully created in the configured Storage Account, and that the event source is ready to consume events from Event Hubs.</p> <p></p> <p>This can be confirmed by navigating back to the Azure Portal and ensuring that:</p> <ul> <li>The Storage Account contains a new Event Subscription targeting Event Hubs.</li> <li>The Resource Group contains an Event Grid System Topic with an Event Subscription matching the one from the Storage   Account.</li> </ul> <p> </p>","location":"cloud/sources/azureblobstorage/#deploying-an-instance-of-the-source"},{"title":"Event Types","text":"<p>The TriggerMesh event source for Azure Blob Storage emits events of the following types:</p> <ul> <li><code>Microsoft.Storage.BlobCreated</code></li> <li><code>Microsoft.Storage.BlobDeleted</code></li> <li><code>Microsoft.Storage.BlobRenamed</code></li> <li><code>Microsoft.Storage.DirectoryCreated</code></li> <li><code>Microsoft.Storage.DirectoryDeleted</code></li> <li><code>Microsoft.Storage.DirectoryRenamed</code></li> <li><code>Microsoft.Storage.BlobTierChanged</code></li> <li><code>Microsoft.Storage.AsyncOperationInitiated</code></li> <li><code>Microsoft.Storage.BlobInventoryPolicyCompleted</code></li> </ul>","location":"cloud/sources/azureblobstorage/#event-types"},{"title":"Event Source for Github","text":"<p>This event source creates a webhook to listen for incoming Github Events, turning received requests into CloudEvents to be consumed by other TriggerMesh components.</p>","location":"cloud/sources/github/"},{"title":"Prerequisite(s)","text":"<ul> <li>GitHub Tokens</li> </ul>","location":"cloud/sources/github/#prerequisites"},{"title":"Create GitHub Tokens","text":"<p>Create a personal access token for GitHub that the GitHub source can use to register webhooks with the GitHub API. Also decide on a secret token that your code will use to authenticate the incoming webhooks from GitHub (secretToken).</p> <p>The token can be named anything you find convenient. The Source requires <code>repo:public_repo</code> and <code>admin:repo_hook</code>, to let it fire events from your public repositories and to create webhooks for those repositories. Copy and save this token; GitHub will force you to generate it again if misplaced.</p> <p>Here's an example for a token named \"GitHubSource Sample\" with the recommended scopes:</p> <p></p>","location":"cloud/sources/github/#create-github-tokens"},{"title":"Deploying an Instance of the Source","text":"<p>Open the Bridge creation screen and add a source of type <code>Github</code>.</p> <p>In the Source creation form, give a name to the event source and add the following information:</p> <ul> <li>Secret: Reference to a TriggerMesh secret containing an Access Token and Secret Token, as described in the previous sections.</li> <li>Name: all TriggerMesh components need a unique name per namespace.</li> <li>Broker: request converted into CloudEvents will be sent to this location.</li> <li>Repository owner and Name: A valid GitHub public repository owned by your GitHub user. (eg. /). <li>Event Types: Select from the dropdown the types of events the source should emit. </li>  <p>After clicking the <code>Save</code> button, you will be taken back to the Bridge editor. Proceed by adding the remaining components to the Bridge, then submit it.</p> <p>A ready status on the main Bridges page indicates that the event source is ready to receive notifications from the Github Event Source.</p> <p></p>","location":"cloud/sources/github/#deploying-an-instance-of-the-source"},{"title":"Verify","text":"<p>Verify the GitHub webhook was created by looking at the list of webhooks under the Settings tab in your GitHub repository. A hook should be listed that points to your Knative cluster with a green check mark to the left of the hook URL, as shown below.</p> <p></p>","location":"cloud/sources/github/#verify"},{"title":"More Information","text":"<p>More information on the Github Event Source can be found here: https://knative.dev/docs/eventing/samples/github-source/</p>","location":"cloud/sources/github/#more-information"},{"title":"Event Types","text":"<p>The Github event source emits events that begin with <code>dev.knative.source.github.</code> and end in the event type. For example: <code>dev.knative.source.github.pull_request</code>, <code>dev.knative.source.github.create</code>, and <code>dev.knative.source.github.delete</code>.</p>","location":"cloud/sources/github/#event-types"},{"title":"Event Source for Google Cloud Audit Logs","text":"<p>This event source receives messages from a Google Cloud Audit Logs Sink by subscribing to a Google Cloud Pub/Sub topic.</p>","location":"cloud/sources/googlecloudauditlogs/"},{"title":"Service Account","text":"<p>A Service Account is required to authenticate the event source and allow it to interact with Google Cloud Audit Logs.</p> <p>The service account must be granted an IAM Role with at least the following permissions:</p> <ul> <li><code>logging.sinks.get</code></li> <li><code>logging.sinks.create</code></li> <li><code>logging.sinks.delete</code></li> </ul> <p>The following set of permissions is also required because this source delegates the management of the Pub/Sub subscription to the Pub/Sub Source.</p> <ul> <li><code>pubsub.subscriptions.create</code></li> <li><code>pubsub.subscriptions.delete</code></li> </ul> <p>The predefined <code>roles/logging.admin</code> and <code>roles/pubsub.editor</code> roles are an example of roles that are suitable for use with the TriggerMesh event source for Google Cloud Audit Logs.</p> <p>Create a key for this service account and save it. This key must be in JSON format. It is required to be able to run an instance of the Google Cloud Audit Logs event source.</p>","location":"cloud/sources/googlecloudauditlogs/#service-account"},{"title":"Deploying an Instance of the Source","text":"","location":"cloud/sources/googlecloudauditlogs/#deploying-an-instance-of-the-source"},{"title":"Prerequisite(s)","text":"<ul> <li>Service Name: The name of the API service performing the operation. For example, \"pubsub.googleapis.com\".</li> <li>Method Name: The name of the service method or operation. For API calls, this should be                the name of the API method. For example, \"google.pubsub.v1.Publisher.CreateTopic\".</li> <li>Resource Name (Optional): The resource or collection that is the target of the operation. The name is                             a scheme-less URI, not including the API service name. Google Cloud Audit Logs Types</li> </ul> <p>Open the Bridge creationg screen and add a source of type Google Cloud Audit Logs.</p> <p></p> <p>In the Source creation form, give a name to the event source and add the required parameters:</p> <p></p> <p>After clicking the Save button, you will be taken back to the Bridge editor. Proceed to adding the remaining components to the Bridge, then submit it.</p> <p></p> <p>A ready status on the main Bridges page indicates that the event source is ready to consume messages from the Audit Logs Sink configured.</p> <p></p>","location":"cloud/sources/googlecloudauditlogs/#prerequisites"},{"title":"Event Types","text":"<p>The TriggerMesh event source for Google Cloud Audit Logs emits events of the following type:</p> <ul> <li>com.google.cloud.auditlogs.message</li> </ul>","location":"cloud/sources/googlecloudauditlogs/#event-types"},{"title":"Event Source for Google Cloud Billing","text":"<p>This event source receives messages from a Google Cloud Billing Budget over a Google Cloud Pub/Sub topic.</p>","location":"cloud/sources/googlecloudbilling/"},{"title":"Service Account","text":"<p>A Service Account is required to authenticate the event source and allow it to interact with Google Cloud Billing budget.</p> <p>The service account must be granted an IAM Role with at least the following permissions:</p> <ul> <li><code>billing.budgets.get</code></li> <li><code>billing.budgets.update</code></li> </ul> <p>The following set of permissions is also required to allow this source to manage the Pub/Sub topic and subscription:</p> <ul> <li><code>pubsub.subscriptions.create</code></li> <li><code>pubsub.subscriptions.delete</code></li> </ul> <p>The predefined <code>roles/billing.costsManager</code> and <code>roles/pubsub.editor</code> roles are an example of roles that are suitable for use with the TriggerMesh event source for Google Cloud Billing.</p> <p>Create a key for this service account and save it. This key must be in JSON format. It is required to be able to run an instance of the Google Cloud Billing event source.</p>","location":"cloud/sources/googlecloudbilling/#service-account"},{"title":"Deploying an Instance of the Source","text":"","location":"cloud/sources/googlecloudbilling/#deploying-an-instance-of-the-source"},{"title":"Prerequisite(s)","text":"<ul> <li>Billing Account ID: The identifier for the Cloud Billing account owning the budget. For example, 01D4EE-079462-DFD6EC.</li> <li>Budget ID: The identifier for the Cloud Billing budget. You can locate the budget's ID in your budget under \"Manage notifications\".              The ID is displayed after you select Connect a Pub/Sub topic to this budget. For example, de72f49d-779b-4945-a127-4d6ce8def0bb.</li> </ul> <p>Open the Bridge creationg screen and add a source of type Google Cloud Billing.</p> <p></p> <p>In the Source creation form, give a name to the event source and add the required parameters:</p> <p></p> <p>After clicking the Save button, you will be taken back to the Bridge editor. Proceed to adding the remaining components to the Bridge, then submit it.</p> <p></p> <p>A ready status on the main Bridges page indicates that the event source is ready to consume messages from the Billing budget configured.</p> <p></p>","location":"cloud/sources/googlecloudbilling/#prerequisites"},{"title":"Event Types","text":"<p>The TriggerMesh event source for Google Cloud Billing emits events of the following type:</p> <ul> <li><code>com.google.cloud.billing.message</code></li> </ul>","location":"cloud/sources/googlecloudbilling/#event-types"},{"title":"Known Issues","text":"<p>Because the Google Cloud Billing API doesn't allow disabling a Budget's notifications programmatically, budget notifications will remain enabled even after the deletion of the event source. The destination Pub/Sub topic will nevertheless be deleted, effectively causing the interruption of budget notifications.</p>","location":"cloud/sources/googlecloudbilling/#known-issues"},{"title":"Event Source for Google Cloud Pub/Sub","text":"<p>This event source subscribes to messages sent to a Google Cloud Pub/Sub topic.</p>","location":"cloud/sources/googlecloudpubsub/"},{"title":"Prerequisite(s)","text":"<ul> <li>Service Account</li> <li>Pub/Sub Topic</li> <li>Pub/Sub Subscription (optional)</li> </ul>","location":"cloud/sources/googlecloudpubsub/#prerequisites"},{"title":"Service Account","text":"<p>A Service Account is required to authenticate the event source and allow it to interact with Google Cloud Pub/Sub. You can create a service account by following the instructions at Creating and managing service accounts.</p> <p>The service account must be granted an IAM Role with at least the following permissions:</p> <ul> <li><code>pubsub.subscriptions.consume</code></li> <li><code>pubsub.subscriptions.get</code></li> </ul> <p>The following set of permissions is also required if you delegate the management of the Pub/Sub subscription to the event source. In case you prefer to manage the subscription yourself, these can be safely be omitted. More details on that topic are provided in the Pub/Sub Subscription section below.</p> <ul> <li><code>pubsub.subscriptions.create</code></li> <li><code>pubsub.subscriptions.delete</code></li> </ul> <p>The predefined <code>roles/pubsub.editor</code> role is one example of role that is suitable for use with the TriggerMesh event source for Google Cloud Pub/Sub.</p> <p></p> <p>Create a key for this service account and save it. This key must be in JSON format. It is required to be able to run an instance of the Google Cloud Pub/Sub event source.</p>","location":"cloud/sources/googlecloudpubsub/#service-account"},{"title":"Pub/Sub Topic","text":"<p>If you don't already have a Pub/Sub topic to subscribe to, create one by following the instructions at Managing topics and subscriptions.</p> <p>Take note of the full topic name, it is a required input to be able to run an instance of the Google Cloud Pub/Sub event source.</p> <p></p>","location":"cloud/sources/googlecloudpubsub/#pubsub-topic"},{"title":"Pub/Sub Subscription (optional)","text":"<p>A subscription is required in order to allow the TriggerMesh event source for Google Cloud Pub/Sub to pull messages from a Pub/Sub topic.</p> <p>This section can be skipped if you would like to let the event source manage its own subscription, which is the default behaviour. In this case, please simply ensure you granted all necessary permissions to the service account in the previous section.</p> <p>If, however, you prefer messages to be pulled using a subscription which you manage yourself, please ensure that subscription is a \"pull\" subscription as described in the documentation page Managing topics and subscriptions.</p> <p></p>","location":"cloud/sources/googlecloudpubsub/#pubsub-subscription-optional"},{"title":"Deploying an Instance of the Source","text":"<p>Open the Bridge creation screen and add a source of type <code>Google Cloud Pub/Sub</code>.</p> <p></p> <p>In the Source creation form, give a name to the event source and add the following information:</p> <ul> <li>Secret: Service account key in JSON format, as described in the previous sections.</li> <li>Topic: Full resource name of the Pub/Sub topic to subscribe to.</li> <li>Subscription ID: (optional) ID of the subscription to use for pulling messages from the Pub/Sub topic, in case   you prefer to manage this subscription yourself as described in the previous sections.</li> </ul> <p></p> <p>After clicking the <code>Save</code> button, you will be taken back to the Bridge editor. Proceed to adding the remaining components to the Bridge, then submit it.</p> <p></p> <p>A ready status on the main Bridges page indicates that the event source is ready to consume messages from the Pub/Sub topic.</p> <p></p>","location":"cloud/sources/googlecloudpubsub/#deploying-an-instance-of-the-source"},{"title":"Event Types","text":"<p>The TriggerMesh event source for Google Cloud Pub/Sub emits events of the following type:</p> <ul> <li><code>com.google.cloud.pubsub.message</code></li> </ul>","location":"cloud/sources/googlecloudpubsub/#event-types"},{"title":"Event Source for Google Cloud Repositories","text":"<p>This event source receives messages from a Google Cloud Repositories over a Google Cloud Pub/Sub topic.</p>","location":"cloud/sources/googlecloudrepositories/"},{"title":"Service Account","text":"<p>A Service Account is required to authenticate the event source and allow it to interact with Google Cloud Repositories.</p> <p>The service account must be granted an IAM Role with at least the following permissions:</p> <ul> <li><code>source.repos.updateRepoConfig</code></li> <li><code>iam.serviceAccounts.actAs</code></li> </ul> <p>The following set of permissions is also required to allow this source to manage the Pub/Sub topic and subscription:</p> <ul> <li><code>pubsub.subscriptions.create</code></li> <li><code>pubsub.subscriptions.delete</code></li> </ul> <p>The predefined <code>roles/source.admin</code>, <code>roles/iam.serviceAccountUser</code> and <code>roles/pubsub.editor</code> roles are an example of roles that are suitable for use with the TriggerMesh event source for Google Cloud Repositories.</p> <p>Create a key for this service account and save it. This key must be in JSON format. It is required to be able to run an instance of the Google Cloud Repositories event source.</p>","location":"cloud/sources/googlecloudrepositories/#service-account"},{"title":"Prerequisite(s)","text":"<ul> <li>Repository</li> <li>Pub/Sub Topic (optional)</li> </ul>","location":"cloud/sources/googlecloudrepositories/#prerequisites"},{"title":"Repository","text":"<p>Full resource name of the Repository. For example, projects/my-project/repos/my-repo.</p>","location":"cloud/sources/googlecloudrepositories/#repository"},{"title":"Pub/Sub Topic (optional)","text":"<p>Full resource name of the Pub/Sub topic where change notifications originating from the configured repo are sent to. If not supplied, a topic is created on behalf of the user, in the GCP project referenced by the 'project' attribute. The expected format is described at https://cloud.google.com/pubsub/docs/admin#resource_names</p>","location":"cloud/sources/googlecloudrepositories/#pubsub-topic-optional"},{"title":"Deploying an Instance of the Source","text":"<p>Open the Bridge creationg screen and add a source of type Google Cloud Repositories.</p> <p></p> <p>In the Source creation form, give a name to the event source and add the required parameters:</p> <p></p> <p>After clicking the Save button, you will be taken back to the Bridge editor. Proceed to adding the remaining components to the Bridge, then submit it.</p> <p></p> <p>A ready status on the main Bridges page indicates that the event source is ready to consume messages from the Repository configured.</p> <p></p>","location":"cloud/sources/googlecloudrepositories/#deploying-an-instance-of-the-source"},{"title":"Event Types","text":"<p>The TriggerMesh event source for Google Cloud Repositories emits events of the following type:</p> <ul> <li><code>com.google.cloud.repositories.notification</code></li> </ul>","location":"cloud/sources/googlecloudrepositories/#event-types"},{"title":"Event Source for Google Cloud Storage","text":"<p>This event source receives change notifications emerging from a Google Cloud Storage bucket by subscribing to a Google Cloud Pub/Sub topic.</p>","location":"cloud/sources/googlecloudstorage/"},{"title":"Prerequisite(s)","text":"<ul> <li>Event Source for Google Cloud Pub/Sub</li> <li>Storage Bucket</li> <li>Notification Configuration</li> </ul>","location":"cloud/sources/googlecloudstorage/#prerequisites"},{"title":"Event Source for Google Cloud Pub/Sub","text":"<p>Change notifications from Cloud Storage buckets can not be consumed directly, but are instead sent to a Google Cloud Pub/Sub topic. Follow the instructions at Event Source for Google Cloud Pub/Sub for setting up a Pub/Sub topic and running an instance of the Pub/Sub event source.</p>  <p>Note</p> <p>As an alternative to a manual creation, the Pub/Sub topic will be created automatically while enabling the Notification Configuration if it doesn't already exist.</p>","location":"cloud/sources/googlecloudstorage/#event-source-for-google-cloud-pubsub"},{"title":"Storage Bucket","text":"<p>You can create a Cloud Storage bucket by following the instructions from the Cloud Storage How-To Guides.</p>","location":"cloud/sources/googlecloudstorage/#storage-bucket"},{"title":"Notification Configuration","text":"<p>Change notifications need to be enabled in the selected bucket by applying a notification configuration. Follow the instructions at Using Pub/Sub notifications for Cloud Storage to add a new notification configuration using the <code>gsutil</code> command-line tool.</p> <p>Below is an example of command which applies a notification configuration to a bucket called <code>eventsource-dev</code>, with a Pub/Sub topic called <code>triggermesh-storage-source</code> set as event destination.</p> <pre><code>$ gsutil notification create -t triggermesh-storage-source -f json gs://eventsource-dev\nCreated Cloud Pub/Sub topic projects/my-project/topics/triggermesh-storage-source\nCreated notification config projects/_/buckets/eventsource-dev/notificationConfigs/1\n</code></pre> <pre><code>$ gsutil notification list gs://eventsource-dev\nprojects/_/buckets/eventsource-dev/notificationConfigs/1\n        Cloud Pub/Sub topic: projects/my-project/topics/triggermesh-storage-source\n</code></pre>  <p>Note</p> <p>It is currently not possible to manage Pub/Sub notifications via the Cloud Console.</p>","location":"cloud/sources/googlecloudstorage/#notification-configuration"},{"title":"Event Source for HTTP Polling","text":"<p>This event source launches periodic HTTP requests against an external system endpoint, turning received requests into CloudEvents to be consumed by other TriggerMesh components.</p>","location":"cloud/sources/httppoller/"},{"title":"Prerequisite(s)","text":"<ul> <li>An external system that exposes an HTTP endpoint.</li> <li>When using HTTP basic authentication, a secret containing the password.</li> </ul>","location":"cloud/sources/httppoller/#prerequisites"},{"title":"Deploying an Instance of the HTTP Poller Source","text":"<p>Open the Bridge creation screen and add a source of type <code>HTTP Poller</code>.</p> <p>In the Source creation form add the following information:</p> <ul> <li>Name: all TriggerMesh components need a unique name per namespace.</li> <li>Broker: request converted into CloudEvents will be sent to this location.</li> <li>EventType: string that identifies the purpose for all CloudEvent messages produced from this source.</li> <li>EventSource: (optional) string that identifies the origin for all CloudEvent messages produced from this source.</li> <li>Enpoint: URL location for the remote service to be polled.</li> <li>Method: HTTP method.</li> <li>Interval: interval between requests formatted as Go duration.</li> <li>CA Certificate: (optional) CA certificate configured for TLS connection as plain text.</li> <li>Skip Verify: (optional) when set to true skips remote server TLS certificate verification.</li> <li>Basic Auth Username: (optional) HTTP basic authentication username.</li> <li>Basic Auth Password (optional) points to a secret that contains the HTTP basic authentication password.</li> <li>Headers (optional) is a set of key/value pairs that will be set within the HTTP request.</li> </ul> <p><code>Interval</code> is formatted after Go's duration parsing. Most typically this value will contain a number followed by one of \"ns\", \"us\" or \"\u00b5s\", \"ms\", \"s\", \"m\", \"h\". Valid examples are <code>15000ms</code> or <code>15s</code> for 15 seconds, <code>60m</code> or <code>1h</code> for one hour.</p> <p>When using <code>CA Certificate</code> it should be copied into the text area in plain text.</p> <p>After clicking the <code>Save</code> button, you will be taken back to the Bridge editor. Proceed to adding the remaining components to the Bridge, then submit it.</p>","location":"cloud/sources/httppoller/#deploying-an-instance-of-the-http-poller-source"},{"title":"Events Types","text":"<p>The HTTP Poller Source creates a CloudEvent for each request received. CloudEvents header values are filled according to these rules:</p> <ul> <li><code>event-type</code> is set to the source's provided value.</li> <li><code>event-source</code> is set to the source's provided value.</li> <li><code>id</code> is set to a generated UID.</li> <li><code>date</code> is timestamped when generating the CloudEvent at TriggerMesh.</li> </ul> <p>Request response body is used to fill the CloudEvent data.</p>","location":"cloud/sources/httppoller/#events-types"},{"title":"Event Source for Oracle Cloud Infrastructure Metrics (OCIMetrics)","text":"<p>This event source collects metrics data from the Oracle Cloud.</p>","location":"cloud/sources/ocimetrics/"},{"title":"Prerequisite(s)","text":"<ul> <li>Oracle Cloud Account</li> <li>Oracle Cloud Infrastructure (OCI)</li> <li>Oracle Cloud Secret</li> </ul>","location":"cloud/sources/ocimetrics/#prerequisites"},{"title":"Oracle Cloud Account","text":"<p>An Oracle Cloud account is required.</p>","location":"cloud/sources/ocimetrics/#oracle-cloud-account"},{"title":"Oracle Cloud Infrastructure (OCI)","text":"<p>The Oracle Cloud account needs to have permissions to inspect and read metrics for the Oracle Cloud Infrastructure (OCI) compartment.</p> <p>For additional information on how to create an API key and associate it with your Oracle Cloud user, go to Oracle's Developer Documentation</p>","location":"cloud/sources/ocimetrics/#oracle-cloud-infrastructure-oci"},{"title":"Oracle Cloud Secret","text":"<p>Three pieces of information are required for the Oracle Cloud: 1. API Private Key used for signing the request 1. API Private Key passphrase to decrypt the key 1. API Key's fingerprint to identify which key to use on the Oracle Cloud end</p> <p>Consult the Secrets guide for more information about how to add an Oracle Cloud specific secret.</p>","location":"cloud/sources/ocimetrics/#oracle-cloud-secret"},{"title":"Deploying an Instance of the Source","text":"","location":"cloud/sources/ocimetrics/#deploying-an-instance-of-the-source"},{"title":"Creating the Source","text":"<p>Open the Bridge creation screen and add a source of type <code>OCIMetrics</code>.</p> <p></p> <p>In the source creation form, provide a unique name and broker. These are used by TriggerMesh to uniquely identify the source and where to send the events to.</p> <p>For the Oracle Cloud specific information, provide the following information: - Oracle tenancy using the Oracle Cloud ID (OCID) - Oracle username as an OCID - Oracle Cloud region where the metrics should be pulled from</p> <p>For the metrics specific information: - Metrics namespace such as <code>oci_computeagent</code> or <code>oci_vcn</code> - The metrics query based on MQL</p> <p>For details on how to write a query, consult the Oracle Cloud Monitoring Overview</p> <p></p> <p>After clicking the <code>SAVE</code> button, you will be taken back to the Bridge editor. Continue to add the targets, and then submit the bridge.</p> <p></p>","location":"cloud/sources/ocimetrics/#creating-the-source"},{"title":"Event Types","text":"<p>The CloudEvent type is:</p> <pre><code>com.oracle.cloud.monitoring\n</code></pre> <p>The CloudEvent source of the form:</p> <pre><code>ocimetrics/&lt;namespace&gt;/&lt;source-name&gt;\n</code></pre> <p>Where <code>namespace</code> is your current namespace and <code>source-name</code> is the name specified during creation of the source.</p> <p>The event payload will match the payload from the Oracle Cloud Monitoring API's Metric Data.</p>","location":"cloud/sources/ocimetrics/#event-types"},{"title":"Event Source for Salesforce","text":"<p>This event source acts as a consumer of the Salesforce stream API and forwards all messages it receives after wrapping them in a CloudEvent envelope.</p>","location":"cloud/sources/salesforce/"},{"title":"Prerequisite(s)","text":"<ul> <li>Salesforce Account</li> <li>Salesforce Stream Channel</li> <li>Certificate Key Secret</li> </ul>","location":"cloud/sources/salesforce/#prerequisites"},{"title":"Salesforce Account","text":"<p>Salesforce source uses OAuth JWT credentials for service authentication.</p> <ol> <li> <p>First, you will need to generate an X509 certificate for signing and verifying requests. We will be using <code>OpenSSL</code> but any other certificate generation tool should work.</p> <pre><code>openssl req -x509 -sha256 -nodes -days 36500 -newkey rsa:2048 -keyout tm-sf.key -out tm-sf.crt\n</code></pre> </li> <li> <p>At Salesforce site select <code>Setup &gt; Apps &gt; App Manager</code>, click on <code>New Connected App</code>.</p> <ul> <li>Fill in mandatory fields, then click <code>Enable OAuth Settings</code>.</li> <li>A callback URL is mandatory but can be filled with any HTTPS data.</li> <li>Enable <code>Use digital signatures</code> and upload the public cert (<code>tm-sf.crt</code> in the example above).</li> <li>Add Scopes for <code>api</code> and <code>refresh_token, offline_access</code>.</li> <li>Save.</li> </ul> <p></p> <ul> <li>Select the Connected App from the list and at the click on <code>Manage</code>.</li> <li>Click <code>Edit policies</code>.</li> <li>Set Permitted users to <code>Admin approved users are pre-authorized</code>.</li> <li>Save.</li> </ul> <p></p> <ul> <li>Select the Connected App from the list and at the click on <code>Manage</code>.</li> <li>Click <code>Manage Profiles</code>.</li> <li>Add permissions on the data this user will have access to.</li> <li>Save.</li> </ul> </li> <li> <p>Retrieve OAuth data to configure TriggerMesh Source.</p> </li> <li> <p>Select the Connected App from the list and at the click on <code>View</code>.</p> </li> <li>Copy <code>Consumer Key</code></li> <li>Reveal and copy <code>Consumer Secret</code></li> </ol>","location":"cloud/sources/salesforce/#salesforce-account"},{"title":"Salesforce Stream Channel","text":"<p>Refer to Salesforce stream API on how to create stream channels:</p> <ul> <li>Change Data Capture events: <code>/data/ChangeEvents</code></li> <li>PushTopics for streams based on single entity SOQL queries: <code>/topic/TicketsSold</code></li> <li>Standard Platform Events for Salesforce event monitoring: <code>/event/LoginEventStream</code></li> <li>Custom Platform Events for your SOQL platform events: <code>/event/MyCustom__e</code></li> </ul> <p>Each Streaming event type has a distinct set of features</p>","location":"cloud/sources/salesforce/#salesforce-stream-channel"},{"title":"Certificate Key Secret","text":"<p>The TriggerMesh Salesforce integration needs the certificate key to sign authentication requests with the Salesforce API. A secret needs to be created at TriggerMesh that contains that certificate key. The file name containing the key will need to be renamed to <code>certKey</code>, then select <code>Secrets</code> &gt; <code>+ ADD SECRET</code>, <code>File Upload</code></p> <p></p>","location":"cloud/sources/salesforce/#certificate-key-secret"},{"title":"Deploying an Instance of the Source","text":"<p>Open the Bridge creation screen and add a source of type <code>Salesforce</code>.</p> <p></p> <p>In the Source creation form, give a name to the event source and add the following information:</p> <ul> <li>Broker to send the events to.</li> <li>Client ID as retrieved from Salesforce Connected App.</li> <li>Server for authentication at Salesforce.</li> <li>User for the Salesforce account.</li> <li>Channel as configured at the Salesforce stream.</li> </ul> <p></p> <p>After clicking <code>Save</code> at the source, you will be taken back to the Bridge editor. Proceed to add the remaining components to the Bridge, then submit it.</p> <p>Wait a few seconds for all components to become ready, the green <code>Status</code> indicator for the bridge indicates that the event source is ready to forward messages from the Salesforce event Stream.</p> <p></p>","location":"cloud/sources/salesforce/#deploying-an-instance-of-the-source"},{"title":"Event Types","text":"<p>The Salesforce event source emits events of the following types:</p> <ul> <li><code>com.salesforce.stream.message</code></li> </ul>","location":"cloud/sources/salesforce/#event-types"},{"title":"Event Source for Slack","text":"<p>This event source uses the Slack Events API through a bot user to ingest events into TriggerMesh.</p>","location":"cloud/sources/slack/"},{"title":"Prerequisite(s)","text":"<ul> <li>A Slack user that can manage applications is required to configure the source.</li> </ul>","location":"cloud/sources/slack/#prerequisites"},{"title":"Create the Slack Source Integration","text":"<p>Deploy the Slack source in 3 steps:</p> <ol> <li>Deploy the Slack source, retrieve exposed endpoint at TriggerMesh.</li> <li>Configure Slack App to send events to the Slack Source endpoint.</li> <li>(optional) Modify the Slack Source to add Signing Secret and AppID from the configured App.</li> </ol>","location":"cloud/sources/slack/#create-the-slack-source-integration"},{"title":"Deploy Slack Source","text":"<p>Create an instance of the Slack Source at TriggerMesh as part of a Bridge.</p> <ul> <li><code>name</code> is an internal identifier inside the bridge.</li> <li><code>broker</code> where messages should be sent to.</li> </ul> <p>Save the source, fill the rest of the bridge fields and press <code>Submit Bridge</code>. The Slack source creates a service, navigate to Functions/Services and copy the URL for the exposed service.</p>","location":"cloud/sources/slack/#deploy-slack-source"},{"title":"Configure Slack Events API App","text":"<ol> <li>Create a new [Slack App][slack-app]</li> </ol> <p></p> <ol> <li>From Basic Information, Features and functionality, select <code>Event Subscriptions</code></li> </ol> <p></p> <ol> <li>Slide the <code>Enable Events</code> selector to <code>on</code> and write the Slack source exposed URL at the <code>Request URL</code> box. A request with a verification challenge will be sent and when the Slack source adapter answer it will be validated and a green check will be shown.</li> </ol> <p></p> <ol> <li> <p>At the <code>Subscribe to bot events</code> section select the bot events that will be sent on behalf of this integration and then press <code>Save Changes</code> at the bottom of the page.. Refer to Slack documentation on which ones to use, as a hint the we think these 3 could be useful for different scenarios:</p> </li> <li> <p><code>app_mention</code> will send an event when the App is mentioned.</p> </li> <li><code>message.im</code> will send an event when sending a direct message to the App.</li> <li><code>message.channels</code> an event will be sent for each message at a channel where the App is invited.</li> </ol> <p></p> <ol> <li>At <code>Install App</code> section click on <code>Install App to Workspace</code></li> </ol> <p></p> <ol> <li> <p>(Optional)Return to the application's <code>Basic Information</code> and take note of <code>App ID</code> and <code>Signing Secret</code></p> <p></p> </li> </ol> <p>You will now have a working integration. Any Slack action that matches the configured event subscription will be sent to the Slack Source and from there to the sink.</p>","location":"cloud/sources/slack/#configure-slack-events-api-app"},{"title":"Secure the Slack Source (optional)","text":"<p>Create a new secret at TriggerMesh and add a key named <code>signingSecret</code> containing the value retrieved at the previous step.</p> <p></p> <p>Go back to the bridge and edit the source:</p> <ul> <li><code>Signing secret</code> set to the created secret.</li> <li><code>App ID</code> is also optional and will filter for the App ID in case the endpoint is used for multiple integrations.</li> </ul>","location":"cloud/sources/slack/#secure-the-slack-source-optional"},{"title":"Events","text":"<p>The Slack source creates a cloud event for each Slack event sent on behalf of the integration. Slack events are wrapped in a structure that is used for CloudEvents categorization, while the wrapped event is sent as the payload.</p> <p>Cloud Event header example:</p>    CloudEvent Description Example     type fixed value <code>com.slack.events</code>   source Team ID (Slack workspace) <code>TA1J7JEBS</code>   subject Event type <code>message</code>   time Event wrapper time <code>2020-06-21T09:44:35Z</code>   id Event wrapper ID <code>Ev01656P5WP3</code>    <p>Cloud Event data example:</p> <pre><code>{\n  \"blocks\": [\n    {\n      \"block_id\": \"ws9ME\",\n      \"elements\": [\n        {\n          \"elements\": [\n            {\n              \"text\": \"waving hello \",\n              \"type\": \"text\"\n            },\n            {\n              \"type\": \"user\",\n              \"user_id\": \"U015NKH6R6G\"\n            }\n          ],\n          \"type\": \"rich_text_section\"\n        }\n      ],\n      \"type\": \"rich_text\"\n    }\n  ],\n  \"channel\": \"C01112A09FT\",\n  \"channel_type\": \"channel\",\n  \"client_msg_id\": \"9fc2ed3e-c823-4dcf-be6b-4d788ab0beea\",\n  \"event_ts\": \"1592732675.009400\",\n  \"team\": \"TA1J7JEBS\",\n  \"text\": \"waving hello \\u003c@U015NKH6R6G\\u003e\",\n  \"ts\": \"1592732675.009400\",\n  \"type\": \"message\",\n  \"user\": \"UT8LFLXR8\"\n}\n</code></pre>","location":"cloud/sources/slack/#events"},{"title":"Event sources","text":"<p>The following is a list of TriggerMesh event Sources, some available as open source projects, some available as hosted solutions on our Cloud.</p>","location":"cloud/sources/sources/"},{"title":"Current TriggerMesh Sources","text":"<ul> <li>Azure<ul> <li>Azure Activity Logs: Consume Activity Logs from a given Azure Subscription.</li> <li>Azure Blob Storage: Subscribe to events from an Azure storage account.</li> </ul> </li> <li>AWS<ul> <li>AWS CodeCommit: Capture notifications from an AWS CodeCommit repository.</li> <li>Amazon Cognito User Pool: Capture notifications from an Amazon Cognito User Pool.</li> <li>Amazon DynamoDB: Capture activity from an Amazon DynamoDB table.</li> <li>Amazon Kinesis: Forward messages from an Amazon Kinesis Data Stream.</li> <li>Amazon S3: Subscribe to event notifications from an Amazon S3 bucket.</li> <li>Amazon SNS: Subscribe to messages from a Amazon SNS topic.</li> <li>Amazon SQS: Capture messages from an Amazon SQS queue.</li> </ul> </li> <li>Github: Consume Github events as Cloudevents</li> <li>Google Cloud<ul> <li>Google Cloud Audit Logs: Capture messages from a Google Cloud Audit Logs Sink.</li> <li>Google Cloud Billing: Capture budget notifications from Google Cloud Billing.</li> <li>Google Cloud Pub/Sub: Receive messages from a Google Cloud Pub/Sub topic.</li> <li>Google Cloud Repositories: Capture change notifications from a Google Cloud Repository.</li> <li>Google Cloud Storage: Capture change notifications from a Google Cloud Storage bucket.</li> </ul> </li> <li>Webhook: Generic Webhook integration.</li> <li>HTTP Poller: Generic HTTP Poller.</li> <li>OCIMetrics: Oracle Cloud Infrastructure Metrics</li> <li>Salesforce: Consume messages from Salesforce Streaming API.</li> <li>Slack: Consume messages from Slack API.</li> <li>Zendesk: Source events from Zendesk, such as the creation of new tickets.</li> </ul>","location":"cloud/sources/sources/#current-triggermesh-sources"},{"title":"Event Source for Twilio","text":"<p>This event source is to be deployed and then registered as a webhook via Twilio Proxy</p>","location":"cloud/sources/twilio/"},{"title":"Prerequisite(s)","text":"<ul> <li>A Twilio account (trial or paid)</li> </ul>","location":"cloud/sources/twilio/#prerequisites"},{"title":"Deploying an Instance of the Source","text":"<p>Open the Bridge creation screen and add a source of type <code>Twilio</code>.</p> <p></p> <p>In the Source creation form, give a name to the event source and add assign it to a Broker</p> <p></p> <p>After clicking the <code>Save</code> button, you will be taken back to the Bridge editor. Proceed to add the remaining</p> <p>components to the Bridge, then submit it.</p> <p></p> <p>A ready status on the main Bridges page indicates that the Twilio Source was successfully created and is ready to forward events from Twilio.</p> <p></p>","location":"cloud/sources/twilio/#deploying-an-instance-of-the-source"},{"title":"Integrate with Twilio","text":"<p>Retrieve the public URL of the deployed Twilio source by selecting it from within the <code>Services</code> section within TriggerMesh.</p> <p></p> <p>Copy down the <code>Domain</code> for later steps.</p> <p></p> <p>Navigate to your Twilio dashboard and search for <code>proxy</code></p> <p></p> <p>From the Twilio Proxy dashboard select <code>Create new Service</code> and, in the following pop-up box, assign it a name.</p> <p></p> <p>You should now be on a similar page to this:</p> <p></p> <p>Enter the <code>Domain</code> that was retrieved earlier into the  \"CALLBACK URL\", \"INTERCEPT CALLBACK URL\", and \"OUT OF SESSION CALLBACK URL\" fields. Then select <code>Save</code></p> <p></p> <p>Select <code>Proxy Numbers</code></p> <p></p> <p>Select <code>Add Numbers</code></p> <p></p> <p>Assing an available number</p> <p></p> <p>All done!</p>","location":"cloud/sources/twilio/#integrate-with-twilio"},{"title":"Event Type","text":"<p>The Twilio event source emits events of the following type:</p> <ul> <li><code>com.triggermesh.twilio.sms</code></li> </ul>","location":"cloud/sources/twilio/#event-type"},{"title":"Example event emited from this source:","text":"<pre><code>\u2601\ufe0f  cloudevents.Event\nValidation: valid\nContext Attributes,\n  specversion: 1.0\n  type: com.triggermesh.twilio.sms\n  source: io.triggermesh.twilio/jeff/twilio-source\n  id: 6a547451-be05-4da4-a10f-1af92422c7d1\n  time: 2021-01-25T19:18:38.550812939Z\n  datacontenttype: application/json\nExtensions,\n  knativearrivaltime: 2021-01-25T19:18:38.580569695Z\nData,\n  {\n    \"message_sid\": \"ASDFc9ac2663bbeASDFd51a\",\n    \"sms_status\": \"received\",\n    \"from_country\": \"US\",\n    \"num_segments\": \"1\",\n    \"to_zip\": \"99204\",\n    \"num_meda\": \"\",\n    \"account_sid\": \"ADF0610bd2e60abdda72\",\n    \"sms_message_sid\": \"ASKDFb2c9ac26621CADfca1d51a\",\n    \"api_version\": \"2010-04-01\",\n    \"to_country\": \"US\",\n    \"to_city\": \"SPOKANE\",\n    \"from_zip\": \"27707\",\n    \"sms_sid\": \"ASDFc2663bbefcASa\",\n    \"from_state\": \"NC\",\n    \"body\": \"hello world\",\n    \"from\": \"&lt;redacted&gt;\",\n    \"from_city\": \"DURHAM\",\n    \"to\": \"&lt;redacted&gt;\",\n    \"to_state\": \"WA\"\n  }\n</code></pre>","location":"cloud/sources/twilio/#example-event-emited-from-this-source"},{"title":"Event Source for Webhooks","text":"<p>This event source exposes a generic HTTP endpoint to be configured at external systems webhooks or be called from custom applications. It turns received requests into CloudEvents to be consumed by other TriggerMesh components.</p>","location":"cloud/sources/webhook/"},{"title":"Prerequisite(s)","text":"<ul> <li>An external client that executes HTTP requests.</li> <li>When using HTTP basic authentication, a secret containing the password.</li> </ul>","location":"cloud/sources/webhook/#prerequisites"},{"title":"Deploying an Instance of the Webhook Source","text":"<p>Open the Bridge creation screen and add a source of type <code>Webhook</code>.</p> <p>In the Source creation form add the following information:</p> <ul> <li>Name: all TriggerMesh components need a unique name per namespace.</li> <li>Broker: request converted into CloudEvents will be sent to this location.</li> <li>EventType: string that identifies the purpose for all messages produced from this source.</li> <li>EventSource: string that identifies the origin for all messages produced from this source.</li> <li>Basic Auth Username: (optional) HTTP basic authentication username.</li> <li>Basic Auth Password (optional) points to a secret that contains the HTTP basic authentication password.</li> </ul> <p>After clicking the <code>Save</code> button, you will be taken back to the Bridge editor. Proceed to adding the remaining components to the Bridge, then submit it.</p> <p>The exposed URL can be retrieved by navigating to <code>Services</code> and clicking on the corresponding Webhook source component.</p>","location":"cloud/sources/webhook/#deploying-an-instance-of-the-webhook-source"},{"title":"Events Types","text":"<p>The Webhook source creates a cloud event for each request received. CloudEvents header event type and event source are set to the configured values. Event data is set to the received body at the request.</p> <p>Cloud Event header example:</p>    CloudEvent Description Example     type User defined <code>shopify.user.new</code>   source User defined <code>cool-tshirts</code>   time Event time <code>2020-06-21T09:44:35Z</code>   id Generated UID <code>e150b165-c77d-4378-adf7-5d94c26e996d</code>    <p>Cloud Event data example (same as received body):</p> <pre><code>{\n  \"operation\": \"signup\",\n  \"user\": {\n    \"...\":\"...\",\n  },\n}\n</code></pre>","location":"cloud/sources/webhook/#events-types"},{"title":"Event Source for Zendesk","text":"<p>This event source registers itself as a notification receiver in Zendesk in order to capture events such as ticket creations.</p>","location":"cloud/sources/zendesk/"},{"title":"Prerequisite(s)","text":"<ul> <li>API Token</li> </ul>","location":"cloud/sources/zendesk/#prerequisites"},{"title":"API Token","text":"<p>An API token is required in order to let the TriggerMesh Zendesk event source create a corresponding Target and Trigger in your Zendesk account. To create a new API token from the Zendesk Admin interface, follow the instructions at Generating a new API token .</p>","location":"cloud/sources/zendesk/#api-token"},{"title":"Deploying an Instance of the Source","text":"<p>Open the Bridge creation screen and add a source of type <code>Zendesk</code>.</p> <p></p> <p>In the Source creation form, give a name to the event source and add the following information:</p> <ul> <li>Email: Email address associated with the Zendesk account.</li> <li>Subdomain: Name of the Zendesk subdomain, without the <code>zendesk.com</code> domain or <code>https://</code> scheme.</li> <li>Token: Reference to a TriggerMesh secret containing an API token to communicate with the   Zendesk API, as described in the previous section.</li> <li>Webhook username/password: arbitrary user name and password, used to verify event callbacks.</li> </ul> <p></p> <p>After clicking the <code>Save</code> button, you will be taken back to the Bridge editor. Proceed to adding the remaining components to the Bridge, then submit it.</p> <p></p> <p>A ready status on the main Bridges page indicates that the Zendesk Target and Trigger were successfully created and that the event source is ready to forward events from Zendesk.</p> <p></p>","location":"cloud/sources/zendesk/#deploying-an-instance-of-the-source"},{"title":"Verification of External Resources","text":"<p>To verify the successful deployment of the Zendesk event source, navigate to the Targets tab of the Extensions screen in the Zendesk Admin interface, below the Settings section. The event source instance should have created a Target following the naming pattern <code>io.triggermesh.zendesksource.&lt;user namespace&gt;.&lt;source name&gt;</code>.</p> <p></p> <p>The Target is configured to include the webhook username and password defined earlier in each request header.</p> <p></p> <p>The Target is linked to a Trigger, which can be found by navigating to the Triggers screen, below the Business rules section. This Trigger follows the same naming convention as the matching Target.</p> <p></p> <p>The Trigger defines the condition on which a new event is generated and sent to the Target. In the example below, the condition is the creation of a new ticket.</p> <p></p> <p>If the Trigger is marked as <code>active</code>, it will be sending notifications to the HTTP(S) endpoint exposed by the instance of the TriggerMesh Zendesk event source as soon as a corresponding action happens in Zendesk.</p>","location":"cloud/sources/zendesk/#verification-of-external-resources"},{"title":"Event Types","text":"","location":"cloud/sources/zendesk/#event-types"},{"title":"<code>com.zendesk.ticket.created</code>","text":"<p>When a new ticket is created in Zendesk a registred source will emit an event of type <code>com.zendesk.ticket.created</code>. An example event of this type can be found below.</p> <pre><code>\u2601\ufe0f  cloudevents.Event\nValidation: valid\nContext Attributes,\n  specversion: 1.0\n  type: com.zendesk.ticket.created\n  source: triggermesh.zendesk.com/zdevntsrc\n  id: aeb9d9c9-89a9-468f-b157-015160c03454\n  time: 2021-01-29T15:10:08.500296727Z\n  datacontenttype: application/json\nExtensions,\n  knativearrivaltime: 2021-01-29T15:10:08.522619069Z\nData,\n  {\n    \"current_user\": {\n      \"details\": \"\",\n      \"email\": \"demo@triggermesh.com\",\n      \"external_id\": \"\",\n      \"first_name\": \"Demo\",\n      \"language\": \"English\",\n      \"name\": \"Demo\",\n      \"notes\": \"\",\n      \"organization\": {\n        \"details\": \"\",\n        \"name\": \"\",\n        \"notes\": \"\"\n      },\n      \"phone\": \"\"\n    },\n    \"satisfaction\": {\n      \"current_comment\": \"\",\n      \"current_rating\": \"\"\n    },\n    \"ticket\": {\n      \"account\": \"TriggerMesh\",\n      \"assignee\": {\n        \"email\": \"support@triggermesh.com\",\n        \"first_name\": \"TriggerMesh\",\n        \"last_name\": \"Developer\",\n        \"name\": \"TriggerMesh Developer\"\n      },\n      \"brand_name\": \"TriggerMesh\",\n      \"cc_names\": \"\",\n      \"ccs\": \"[]\",\n      \"current_holiday_name\": \"Liquid error: internal\",\n      \"description\": \"----------------------------------------------\\n\\nDemo, Jan 29, 2021, 11:10\\n\\nhello world\",\n      \"due_date\": \"\",\n      \"external_id\": \"\",\n      \"group_name\": \"Support\",\n      \"id\": 343,\n      \"organization\": {\n        \"details\": \"\",\n        \"external_id\": \"\",\n        \"name\": \"\",\n        \"notes\": \"\"\n      },\n      \"priority\": \"\",\n      \"requester\": {\n        \"details\": \"\",\n        \"email\": \"demo@triggermesh.com\",\n        \"external_id\": \"\",\n        \"field\": \"\",\n        \"first_name\": \"Demo\",\n        \"language\": \"English\",\n        \"last_name\": \"Demo\",\n        \"name\": \"Demo\",\n        \"phone\": \"\"\n      },\n      \"status\": \"Open\",\n      \"tags\": \"oracle\",\n      \"ticket_field_id\": \"\",\n      \"ticket_field_option_title_id\": \"\",\n      \"ticket_type\": \"Ticket\",\n      \"title\": \"hello world\",\n      \"url\": \"triggermesh.zendesk.com/agent/tickets/343\",\n      \"via\": \"Web Form\"\n    }\n  }\n</code></pre>","location":"cloud/sources/zendesk/#comzendeskticketcreated"},{"title":"Event Target for Alibaba OSS","text":"<p>This event target receives CloudEvents over HTTP and sends them to Alibaba OSS creating a new file containing the event data.</p>","location":"cloud/targets/alibabaoss/"},{"title":"Prerequisite(s)","text":"<ul> <li>Alibaba Cloud account.</li> <li>The Access Key ID and Secret Access Key associated to the account.</li> </ul>","location":"cloud/targets/alibabaoss/#prerequisites"},{"title":"Deploying an Instance of the Target","text":"<p>Open the Bridge creation screen and add a target of type <code>Alibaba OSS</code>.</p> <p>In the Target creation form, give a name to the event Target and add the following information:</p> <ul> <li>Secret: Reference to a TriggerMesh secret containing the Access Key ID and Secret Access Key.</li> <li>Endpoint: The OSS endpoint.</li> <li>Bucket: The OSS Bucket.</li> </ul> <p>After clicking the <code>Save</code> button, you will be taken back to the Bridge editor. Proceed by adding the remaining components to the Bridge, then submit it.</p> <p>A ready status on the main Bridges page indicates that the Alibaba OSS target is ready to accept events.</p> <p>For more information about using Alibaba OSS, please refer to the documentation.</p>","location":"cloud/targets/alibabaoss/#deploying-an-instance-of-the-target"},{"title":"Event Types","text":"","location":"cloud/targets/alibabaoss/#event-types"},{"title":"Arbitrary","text":"<p>This target will consume arbitrary events and upload them into a table with the Cloudevent ID as the object key.</p> <p>The response event type will contain the original event type with <code>.response</code> appended to the end. </p>","location":"cloud/targets/alibabaoss/#arbitrary"},{"title":"Event Target for Amazon Comprehend","text":"<p>This event target receives CloudEvents over HTTP and sends them to Amazon Comprehend</p>","location":"cloud/targets/awscomprehend/"},{"title":"Prerequisite(s)","text":"<ul> <li>AWS API key and secret.</li> </ul>","location":"cloud/targets/awscomprehend/#prerequisites"},{"title":"Deploying an Instance of the Target","text":"<p>Open the Bridge creation screen and add a target of type <code>Amazon Comprehend</code>.</p> <p>In the Target creation form, give a name to the event Target and add the following information:</p> <ul> <li>AWS Secret: Reference a TriggerMesh secret containing an AWS API key and Secret.</li> <li>Region: Denotes the region to run the Amazon Comprehend services from.</li> <li>Language: Denotes the language to expect in the events.</li> </ul> <p>After clicking the <code>Save</code> button, you will be taken back to the Bridge editor. Proceed to adding the remaining components to the Bridge, then submit it.</p> <p>A ready status on the main Bridges page indicates that the Amazon Comprehend target is ready to accept events.</p> <p>For more information about using Amazon Comprehend, please refer to the [documentation][https://docs.aws.amazon.com/comprehend/].</p>","location":"cloud/targets/awscomprehend/#deploying-an-instance-of-the-target"},{"title":"Event Types","text":"","location":"cloud/targets/awscomprehend/#event-types"},{"title":"Arbitrary","text":"<p>This target will consume arbitrary events and analyzes each of the key values sentiment. It then combines the scores and  returns the analysis in a response event of type <code>io.triggermesh.targets.aws.comprehend.result</code></p>","location":"cloud/targets/awscomprehend/#arbitrary"},{"title":"Event Target for Amazon EventBridge","text":"<p>This event Target receives arbitrary CloudEvents over HTTP and sends them to an Amazon EventBridge partner event bus in a JSON format.</p>","location":"cloud/targets/awseventbridge/"},{"title":"Deploying an Instance of the Target","text":"<p>Open the Bridge creation screen and add a target of type <code>Amazon EventBridge</code>.</p> <p></p> <p>In the Target creation form, provide a name for the event Target and add the following information:</p> <ul> <li>AWS account ID: defines the AWS account in which the TriggerMesh partner event source is to be created.</li> <li>AWS region: defines the AWS region in which the TriggerMesh partner event source is to be created.</li> </ul> <p></p> <p>After clicking the <code>Save</code> button, you will be taken back to the Bridge editor. Proceed to adding the remaining components to the Bridge, then submit it.</p> <p></p> <p>A ready status on the main Bridges page indicates that the TriggerMesh partner event source was successfully created.</p> <p></p> <p>Although this event source can immediately start receiving events, those events can only be consumed after associating the TriggerMesh partner event source with a corresponding partner event bus.</p> <p>To associate the TriggerMesh partner event source with a partner event bus:</p> <ol> <li>Navigate to the Partner event sources menu of the Amazon EventBridge Console.</li> <li>Select the \"Pending\" partner event source which name starts with <code>aws.partner/triggermesh.com</code>.</li> <li>Click the <code>Associate with event bus</code> button.</li> </ol> <p></p> <p>On the next screen called Associate with event bus, click the <code>Associate</code> button.</p> <p></p> <p>Back to the Partner event sources page, your partner event source should now show as \"Active\".</p> <p></p> <p>You will also see a custom event bus named after the TriggerMesh partner event source on the Event buses page.</p> <p></p> <p>Your can now start creating rules that trigger on certain events in the Amazon EventBridge console.</p> <p>For more information about using Amazon EventBridge, please refer to the EventBridge user guide.</p>","location":"cloud/targets/awseventbridge/#deploying-an-instance-of-the-target"},{"title":"Event Types","text":"<p>The Amazon EventBridge event Target can consume events of any type.</p>","location":"cloud/targets/awseventbridge/#event-types"},{"title":"Event Target for Amazon Kinesis","text":"<p>This event Target receives CloudEvents over HTTP and publishes the event to Amazon Kinesis.</p>","location":"cloud/targets/awskinesis/"},{"title":"Prerequisite(s)","text":"<ul> <li>AWS API key and secret</li> <li>ARN for the Kinesis stream</li> <li>A Kinesis partition name to publish the events to</li> </ul> <p>Consult the Secrets guide for more information about how to add the AWS API specific secrets.</p>","location":"cloud/targets/awskinesis/#prerequisites"},{"title":"Deploying an Instance of the Target","text":"<p>Open the Bridge creation screen and add a Target of type <code>Amazon Kinesis</code>.</p> <p></p> <p>In the Target creation form, provide a name for the event Target and add the following information:</p> <ul> <li>AWS Secret: Reference a TriggerMesh secret containing an AWS API key and Secret as discussed in the prerequisites.</li> <li>AWS ARN: The ARN that points to the Amazon Kinesis stream.</li> <li>Partition: The Kinesis partition to publish the events to.</li> </ul> <p>There is an optional toggle flag indicating if the full CloudEvent should be sent to Kinesis. By default, this is disabled which means only the event payload will be sent.</p> <p></p> <p>After clicking the <code>Save</code> button, the console will self-navigate to the Bridge editor. Proceed by adding the remaining components to the Bridge.</p> <p></p> <p>After submitting the Bridge, and allowing for some configuration time, a green check mark on the main Bridges page indicates that the Bridge with the Amazon Kinesis Target was successfully created.</p> <p></p> <p>For more information about using Amazon Kinesis, please refer to the AWS documentation.</p>","location":"cloud/targets/awskinesis/#deploying-an-instance-of-the-target"},{"title":"Event Types","text":"<p>The Amazon Kinesis event Target leaves the CloudEvent type definition to the discretion of the implementer given the flexible nature of Kinesis.</p> <p>However, the response CloudEvent would have the following payload:</p>    Name Value Description     ce-type io.triggermesh.targets.aws.kinesis.result Denotes a response payload from Kinesis   ce-source <code>arn:aws:kinesis:...</code> The Kinesis ARN value as configured by the target   body JSON A JSON response from the Target invocation","location":"cloud/targets/awskinesis/#event-types"},{"title":"Event Target for AWS Lambda","text":"<p>This event Target receives CloudEvents over HTTP and invokes an AWS Lambda function.</p>","location":"cloud/targets/awslambda/"},{"title":"Prerequisite(s)","text":"<ul> <li>AWS API key and secret</li> <li>ARN for the Lambda to invoke</li> </ul> <p>Consult the Secrets guide for more information about how to add the AWS API specific secrets.</p>","location":"cloud/targets/awslambda/#prerequisites"},{"title":"Deploying an Instance of the Target","text":"<p>Open the Bridge creation screen and add a Target of type <code>AWS Lambda</code>.</p> <p></p> <p>In the Target creation form, provide a name for the event Target and add the following information:</p> <ul> <li>AWS Secret: Reference a TriggerMesh secret containing an AWS API key and Secret as discussed in the prerequisites.</li> <li>AWS ARN: The ARN that points to the AWS Lambda function to invoke</li> </ul> <p>There is an optional toggle flag indicating if the full CloudEvent should be sent to the lambda function. By default, this is disabled which means only the event payload will be sent.</p> <p></p> <p>After clicking the <code>Save</code> button, the console will self-navigate to the Bridge editor. Proceed by adding the remaining components to the Bridge.</p> <p></p> <p>After submitting the Bridge, and allowing for some configuration time, a green check mark on the main Bridges page indicates that the Bridge with the AWS Lambda Target was successfully created.</p> <p></p> <p>For more information about using AWS Lambda, please refer to the AWS documentation.</p>","location":"cloud/targets/awslambda/#deploying-an-instance-of-the-target"},{"title":"Event Types","text":"<p>The AWS Lambda event Target leaves the CloudEvent type definition to the discretion of the implementer given the flexible nature of AWS Lambda.</p> <p>However, the response CloudEvent would have the following payload:</p>    Name Value Description     ce-type io.triggermesh.targets.aws.lambda.result Denotes a response payload from the Lambda function   ce-source <code>arn:aws:lambda:...</code> The Lambda's ARN value as configured by the target   body JSON A JSON response from the Target invocation","location":"cloud/targets/awslambda/#event-types"},{"title":"Event Target for Amazon S3","text":"<p>This event Target receives CloudEvents over HTTP and invokes an Amazon S3 endpoint.</p>","location":"cloud/targets/awss3/"},{"title":"Prerequisite(s)","text":"<ul> <li>AWS API key and secret</li> <li>ARN for the S3 bucket to store the event</li> </ul> <p>Consult the Secrets guide for more information about how to add the AWS API specific secrets.</p> <p>The ARN for the S3 bucket must include the account number and region of a pre-defined access point.</p>","location":"cloud/targets/awss3/#prerequisites"},{"title":"Deploying an Instance of the Target","text":"<p>Open the Bridge creation screen and add a Target of type <code>Amazon S3</code>.</p> <p></p> <p>In the Target creation form, provide a name for the event Target and add the following information:</p> <ul> <li>AWS Secret: Reference a TriggerMesh secret containing an AWS API key and Secret as discussed in the prerequisites.</li> <li>AWS ARN: The ARN that points to the Amazon S3 bucket.</li> </ul> <p>There is an optional toggle flag indicating if the full CloudEvent should be sent to S3 bucket. By default, this is disabled which means only the event payload will be sent.</p> <p></p> <p>After clicking the <code>Save</code> button, the console will self-navigate to the Bridge editor. Proceed by adding the remaining components to the Bridge.</p> <p></p> <p>After submitting the Bridge, and allowing for some configuration time, a green check mark on the main Bridges page indicates that the Bridge with the Amazon S3 Target was successfully created.</p> <p></p> <p>For more information about using Amazon S3, please refer to the AWS documentation.</p>","location":"cloud/targets/awss3/#deploying-an-instance-of-the-target"},{"title":"Event Types","text":"<p>Events of this type will store the event payload into an Amazon S3 bucket.</p> <p>The Amazon S3 event Target leaves the CloudEvent type definition to the discretion of the implementer given the flexible nature of what can be stored in Amazon S3.  There is an exception if the <code>io.triggermesh.awss3.object.put</code> type is used where the target will store the payload body regardless of the <code>Discard CloudEvent context attributes</code> setting.</p> <p>The Amazon S3 bucket key used to store the event is defined by the <code>ce-subject</code> attribute. If <code>ce-subject</code> is not set, the default key will be: ce-type/ce-source/ce-time.</p> <p>This type expects a JSON payload with the following properties:</p>    Name Value Description     ce-type io.triggermesh.awss3.object.put or user defined Event type denoting the s3 put request   ce-subject string The key to use with the assigned bucket for the Target   body JSON The data payload to store    <p>The response CloudEvent would have the following payload:</p>    Name Value Description     ce-type io.triggermesh.targets.aws.s3.result Denotes a response payload from the S3 put request   ce-source <code>arn:aws:s3:...</code> The S3's bucket ARN value as configured by the target   body JSON A JSON response from the Target invocation with the Etag associated with the request","location":"cloud/targets/awss3/#event-types"},{"title":"Event Target for Amazon SNS","text":"<p>This event Target receives CloudEvents over HTTP and invokes an Amazon SNS endpoint.</p>","location":"cloud/targets/awssns/"},{"title":"Prerequisite(s)","text":"<ul> <li>AWS API key and secret</li> <li>ARN for the SNS topic to invoke</li> </ul> <p>Consult the Secrets guide for more information about how to add the AWS API specific secrets.</p>","location":"cloud/targets/awssns/#prerequisites"},{"title":"Deploying an Instance of the Target","text":"<p>Open the Bridge creation screen and add a Target of type <code>Amazon SNS</code>.</p> <p></p> <p>In the Target creation form, provide a name for the event Target and add the following information:</p> <ul> <li>AWS Secret: Reference a TriggerMesh secret containing an AWS API key and Secret as discussed in the prerequisites.</li> <li>AWS ARN: The ARN that points to the Amazon SNS topic.</li> </ul> <p>There is an optional toggle flag indicating if the full CloudEvent should be sent to SNS. By default, this is disabled which means only the event payload will be sent.</p> <p></p> <p>After clicking the <code>Save</code> button, the console will self-navigate to the Bridge editor. Proceed by adding the remaining components to the Bridge.</p> <p></p> <p>After submitting the Bridge, and allowing for some configuration time, a green check mark on the main Bridges page indicates that the Bridge with the Amazon SNS Target was successfully created.</p> <p></p> <p>For more information about using AWS Simple Notification Service, please refer to the AWS documentation.</p>","location":"cloud/targets/awssns/#deploying-an-instance-of-the-target"},{"title":"Event Types","text":"<p>The Amazon SNS event Target leaves the CloudEvent type definition to the discretion of the implementer given the flexible nature of Amazon SNS.</p> <p>However, the response CloudEvent would have the following payload:</p>    Name Value Description     ce-type io.triggermesh.targets.aws.sns.result Denotes a response payload from SNS   ce-source <code>arn:aws:sns:...</code> The SNS ARN value as configured by the target   body JSON A JSON response from the Target invocation","location":"cloud/targets/awssns/#event-types"},{"title":"Event Target for Amazon SQS","text":"<p>This event Target receives CloudEvents over HTTP and invokes an Amazon SQS endpoint.</p>","location":"cloud/targets/awssqs/"},{"title":"Prerequisite(s)","text":"<ul> <li>AWS API key and secret</li> <li>ARN for the SQS queue to invoke</li> </ul> <p>Consult the Secrets guide for more information about how to add the AWS API specific secrets.</p>","location":"cloud/targets/awssqs/#prerequisites"},{"title":"Deploying an Instance of the Target","text":"<p>Open the Bridge creation screen and add a Target of type <code>Amazon SQS</code>.</p> <p></p> <p>In the Target creation form, provide a name for the event Target and add the following information:</p> <ul> <li>AWS Secret: Reference a TriggerMesh secret containing an AWS API key and Secret as discussed in the prerequisites.</li> <li>AWS ARN: The ARN that points to the Amazon SQS queue.</li> </ul> <p>There is an optional toggle flag indicating if the full CloudEvent should be sent to SQS. By default, this is disabled which means only the event payload will be sent.</p> <p></p> <p>After clicking the <code>Save</code> button, the console will self-navigate to the Bridge editor. Proceed by adding the remaining components to the Bridge.</p> <p></p> <p>After submitting the Bridge, and allowing for some configuration time, a green check mark on the main Bridges page indicates that the Bridge with the Amazon SQS Target was successfully created.</p> <p></p> <p>For more information about using AWS Simple Queue Service, please refer to the AWS documentation.</p>","location":"cloud/targets/awssqs/#deploying-an-instance-of-the-target"},{"title":"Event Types","text":"<p>The Amazon SQS event Target leaves the CloudEvent type definition to the discretion of the implementer given the flexible nature of Amazon SQS.</p> <p>However, the response CloudEvent would have the following payload:</p>    Name Value Description     ce-type io.triggermesh.targets.aws.sqs.result Denotes a response payload from SQS   ce-source <code>arn:aws:sqs:...</code> The SQS ARN value as configured by the target   body JSON A JSON response from the Target invocation","location":"cloud/targets/awssqs/#event-types"},{"title":"Event Target for Confluent","text":"<p>This event Target receives CloudEvents and forwards the event to a Confluent Kafka cluster.</p>","location":"cloud/targets/confluent/"},{"title":"Prerequisite(s)","text":"<ul> <li>Access to a Kafka cluster with appropriate configuration details</li> </ul> <p>If a password is required, consult the Secrets guide for additional information on how to add the password as a secret.</p>","location":"cloud/targets/confluent/#prerequisites"},{"title":"Kafka Cluster Details","text":"<p>Depending on the cluster and user permissions, the Kafka topic must exist prior to setting up the target. Otherwise, the Target will attempt to create the topic which will require setting the <code>Topic replication</code> and <code>Topic partition</code>.</p>","location":"cloud/targets/confluent/#kafka-cluster-details"},{"title":"Deploying an Instance of the Target","text":"<p>Open the Bridge creation screen and add a Target of type <code>Confluent</code>.</p> <p></p> <p>In the Target creation form, provide a name for the event Target and add the following information:</p> <ul> <li>Password Secret: Reference to a TriggerMesh secret containing the password associated with the user accessing the Kafka cluster as discussed in the prerequisites.</li> <li>Bootstrap Servers: Confluent bootstrap servers to connect to. Use the <code>ADD MORE</code> button to add additional bootstrap servers if needed.</li> <li>Topic: Confluent topic to publish events to.</li> <li>Topic Replication: Number of copies of the topic that should exist in the cluster.</li> <li>Topic Partitions: Number of partitions for the topic to allow for concurrency.</li> <li>SASL Mechanism: Denote how to authenticate against Kafka. Value can be either <code>PLAIN</code> or <code>GSSAPI</code>.</li> <li>Security Protocol: Denote whether to encrypt the password using SSL/TLS.</li> <li>Username: The username to connect to the Kafka cluster as. This field must have a value even if the cluster allows unauthenticated access.</li> </ul> <p>There is an optional toggle flag indicating if the full CloudEvent should be sent to Confluent. By default, this is disabled which means only the event payload will be sent.</p> <p></p> <p>After clicking the <code>Save</code> button, the console will self-navigate to the Bridge editor. Proceed by adding the remaining components to the Bridge.</p> <p></p> <p>After submitting the Bridge, and allowing for some configuration time, a green check mark on the main Bridges page indicates that the Bridge with a Confluent event Target was successfully created.</p> <p></p> <p>For more information on how to configure Confluent, refer to the Confluent documentation.</p>","location":"cloud/targets/confluent/#deploying-an-instance-of-the-target"},{"title":"Event Types","text":"<p>The Confluent event Target leaves the CloudEvent type definition to the discretion of the implementer. In addition, no events are produced as a response.</p>","location":"cloud/targets/confluent/#event-types"},{"title":"Event Target for Datadog","text":"<p>This event Target receives CloudEvents and sends it to Datadog.</p>","location":"cloud/targets/datadog/"},{"title":"Prerequisite(s)","text":"<ul> <li>Datadog API token</li> </ul> <p>Consult the Secrets guide for more information about how to add the Datadog API token as a secret.</p>","location":"cloud/targets/datadog/#prerequisites"},{"title":"Deploying an Instance of the Target","text":"<p>Open the Bridge creation screen and add a Target of type <code>Datadog</code>.</p> <p></p> <p>In the Target creation form, provide a name for the event Target and add the following information:</p> <ul> <li>API Key: Reference to a TriggerMesh secret containing the Datadog API key as discussed in the prerequisites.</li> <li>Metric Name Prefix (Optional): Prefix to prepend to the metrics being sent.</li> </ul> <p></p> <p>After clicking the <code>Save</code> button, the console will self-navigate to the Bridge editor. Proceed by adding the remaining components to the Bridge.</p> <p></p> <p>After submitting the Bridge, and allowing for some configuration time, a green check mark on the main Bridges page indicates that the Bridge with a Datadog event Target was successfully created.</p> <p></p> <p>For more information about using Datadog, please refer to the Datadog documentation.</p>","location":"cloud/targets/datadog/#deploying-an-instance-of-the-target"},{"title":"Event Types","text":"<p>A Datadog event Target accepts the following CloudEvent types:</p>","location":"cloud/targets/datadog/#event-types"},{"title":"io.triggermesh.datadog.event.post","text":"<p>Events of this type contain event messages to be published to Datadog.</p> <p>This type expects a JSON payload with the following properties:</p>    Name Type Comment Required     text string The body of the event. Limited to 4000 characters. The text supports markdown. true   title string The event title. Limited to 100 characters. Use msg_title with the Datadog Ruby library. true   alert_type string If an alert event is enabled, set its type. For example, error, warning, info, success, user_update, recommendation, and snapshot. Allowed enum values: error,warning,info,success,user_update,recommendation,snapshot. false   date_happened int64 POSIX timestamp of the event. Must be sent as an integer (i.e. no quotes). Limited to events no older than 7 days. false   device_name string A device name. false   host string Host name to associate with the event. Any tags associated with the host are also applied to this event. false   id int64 Integer ID of the event. false   priority string The priority of the event. For example, normal or low. Allowed enum values: normal,low. false   related_event_id int64 ID of the parent event. Must be sent as an integer (i.e. no quotes). false   source_type_name string The type of event being posted. Option examples include nagios, hudson, jenkins, my_apps, chef, puppet, git, bitbucket, etc. A complete list of source attribute values available here. false   status string A status. false   tags []string A list of tags to apply to the event. false   url string URL of the event. false","location":"cloud/targets/datadog/#iotriggermeshdatadogeventpost"},{"title":"io.triggermesh.datadog.metric.submit","text":"<p>Events of this type consist of a singular metric to be published to Datadog.</p> <p>This type expects a JSON payload with the following properties:</p>    Name Type Comment Required     host string The name of the host that produced the metric. false   interval int64 If the type of the metric is rate or count, define the corresponding interval. false   metric string The name of the timeseries. true   points [][]string Points relating to a metric. All points must be tuples with timestamp and a scalar value (cannot be a string). Timestamps should be in POSIX time in seconds, and cannot be more than ten minutes in the future or more than one hour in the past. true   tags []string A list of tags associated with the metric. false   type string The type of the metric either count, gauge, or rate. false","location":"cloud/targets/datadog/#iotriggermeshdatadogmetricsubmit"},{"title":"io.triggermesh.datadog.logs.send","text":"<p>Events of this type consist log data to be published to Datadog.</p> <p>This type expects a JSON payload with the following properties:</p>    Name Type Comment Required     ddsource string The integration name associated with your log: the technology from which the log originated. When it matches an integration name, Datadog automatically installs the corresponding parsers and facets. true   ddtags string Tags associated with your logs. false   hostname string The name of the originating host of the log. true   message string The message reserved attribute of your log. By default, Datadog ingests the value of the message attribute as the body of the log entry. That value is then highlighted and displayed in the Logstream, where it is indexed for full text search. true   service string The name of the application or service generating the log events. It is used to switch from Logs to APM, so make sure you define the same value when you use both products. false","location":"cloud/targets/datadog/#iotriggermeshdatadoglogssend"},{"title":"Event Target for Elasticsearch","text":"<p>This event Target receives CloudEvents over HTTP and writes their payload to an Elasticsearch index.</p>","location":"cloud/targets/elasticsearch/"},{"title":"Prerequisite(s)","text":"<ul> <li>An Elasticsearch cluster</li> <li>Elasticsearch credentials (username and password or API key)</li> </ul> <p>Consult the Secrets guide for more information about how to add the Elasticsearch credentials as a secret.</p>","location":"cloud/targets/elasticsearch/#prerequisites"},{"title":"Creating an Elasticsearch Cluster","text":"<p>Create an Elasticsearch cluster quickly by using either Elastic Cloud on Kubernetes or Elastic Cloud.</p>","location":"cloud/targets/elasticsearch/#creating-an-elasticsearch-cluster"},{"title":"Deploying an Instance of the Target","text":"<p>Open the Bridge creation screen and add a Target of type <code>Elasticsearch</code>.</p> <p></p> <p>In the Target creation form, provide a name for the event Target and add the following information:</p> <ul> <li>Index: Name of the index to write documents to.</li> <li>Addresses: List of URLs of Elasticsearch servers.</li> <li>Skip verify: Allow skipping of server certificate verification.</li> <li>CA certificate: CA certificate to be used by the event Target's client, in PEM format.</li> <li>Username: Elasticsearch username.</li> <li>Password:  Reference a TriggerMesh secret containing a password to communicate with the Elasticsearch API, as discussed in the prerequisites.</li> <li>API key: Reference a TriggerMesh secret containing an API token to communicate with the Elasticsearch API, as discussed in the prerequisites.</li> </ul> <p>When using a self-signed certificate you will need to either inform the CA certificate or set the Skip verify field.</p> <p></p> <p>After clicking the <code>Save</code> button, the console will self-navigate to the Bridge editor. Proceed by adding the remaining components to the Bridge.</p> <p>After submitting the Bridge, and allowing for some configuration time, a green check mark on the main Bridges page indicates that the Bridge with an Elasticsearch event Target was successfully created.</p> <p></p> <p>For more information about using Elasticsearch, please refer to the Elasticsearch documentation.</p>","location":"cloud/targets/elasticsearch/#deploying-an-instance-of-the-target"},{"title":"Event Types","text":"<p>The Elasticsearch event Target can consume events of any type.</p>","location":"cloud/targets/elasticsearch/#event-types"},{"title":"Event Target for Google Cloud Workflows","text":"<p>This event target receives CloudEvents over HTTP and sends them to Google Cloud Workflows</p>","location":"cloud/targets/googlecloudworkflows/"},{"title":"Prerequisite(s)","text":"<ul> <li>Google Cloud Console account.</li> <li>A service account and it's associated JSON credentials.</li> </ul>","location":"cloud/targets/googlecloudworkflows/#prerequisites"},{"title":"Deploying an Instance of the Target","text":"<p>Open the Bridge creation screen and add a target of type <code>Google Cloud Workflows</code>.</p> <p>In the Target creation form, give a name to the event Target and add the following information:</p> <ul> <li>Credentials: Reference to a TriggerMesh secret containing the JSON credentials of a Service Account.</li> </ul> <p>After clicking the <code>Save</code> button, you will be taken back to the Bridge editor. Proceed to adding the remaining components to the Bridge, then submit it.</p> <p>A ready status on the main Bridges page indicates that the Google Cloud Workflows target is ready to accept events.</p> <p>For more information about using Google Cloud Workflows, please refer to the [documentation][https://cloud.google.com/workflows/docs].</p>","location":"cloud/targets/googlecloudworkflows/#deploying-an-instance-of-the-target"},{"title":"Event Types","text":"","location":"cloud/targets/googlecloudworkflows/#event-types"},{"title":"io.trigermesh.google.workflows.run","text":"<p>Events of this type contain nuanced data that is used to run a Google Workflow.</p> <p>This type expects a JSON payload with the following properties:</p>    Name Type Comment Example     parent string Project and location in which the workflow should be created. Format:  <code>projects/{project}/locations/{location}</code> \"projects/ultra-hologram-297914/locations/us-central1\"   executionName string The resource name of the execution. Format: <code>projects/{project}/locations/{location}/workflows/{workflow}/executions/{execution}</code> \"demowf\"","location":"cloud/targets/googlecloudworkflows/#iotrigermeshgoogleworkflowsrun"},{"title":"Event Target for Google Firestore","text":"<p>This event target receives CloudEvents over HTTP and sends them to Google Firestore</p>","location":"cloud/targets/googlefirestore/"},{"title":"Prerequisite(s)","text":"<ul> <li>Google Cloud Console account.</li> <li>A service account and it's associated JSON credentials.</li> </ul>","location":"cloud/targets/googlefirestore/#prerequisites"},{"title":"Deploying an Instance of the Target","text":"<p>Open the Bridge creation screen and add a target of type <code>Google Firestore</code>.</p> <p>In the Target creation form, give a name to the event Target and add the following information:</p> <ul> <li>Credentials: Reference to a TriggerMesh secret containing the JSON credentials of a Service Account.</li> <li>Project ID: The Google Cloud Console Project ID.</li> <li>Default Collection: The default collection to publish data.</li> </ul> <p>After clicking the <code>Save</code> button, you will be taken back to the Bridge editor. Proceed by adding the remaining components to the Bridge, then submit it.</p> <p>A ready status on the main Bridges page indicates that the Google Firestore target is ready to accept events.</p> <p>For more information about using Google Firestore, please refer to the [documentation][https://firebase.google.com/docs/firestore].</p>","location":"cloud/targets/googlefirestore/#deploying-an-instance-of-the-target"},{"title":"Event Types","text":"","location":"cloud/targets/googlefirestore/#event-types"},{"title":"Arbitrary","text":"<p>This target will consume arbitrary events and upload them into a table with the Cloudevent ID as the document name.</p> <p>The response event type will contain the original event type with <code>.response</code> appended to the end. </p>","location":"cloud/targets/googlefirestore/#arbitrary"},{"title":"io.triggermesh.google.firestore.write","text":"<p>Events of this type contain nuanced data that is used to specify the document, collection, and data on each call to the target.</p> <p>This type expects a JSON payload with the following properties:</p>    Name Type Comment Example     collection string Defines the firebase collection to be written. \"eventtst\"   document string Defines the firebase document name to be written. \"doctestst\"   data map[string]interface{} Defines the items to be written to the document. {\"fromEmail\":\"bob@triggermesh.com\",\"hello\":\"pls\"}    <p>This event responds with an event of type: <code>io.triggermesh.google.firestore.write.response</code></p>","location":"cloud/targets/googlefirestore/#iotriggermeshgooglefirestorewrite"},{"title":"io.triggermesh.google.firestore.query.tables","text":"<p>Events of this type contain nuanced data that is used to return all tables in a provided collection.</p> <p>This type expects a JSON payload with the following properties:</p>    Name Type Comment Example     collection string Defines the firebase collection to be queried. \"eventtst\"    <p>This event responds with an event of type: <code>io.triggermesh.google.firestore.query.tables.response</code></p>","location":"cloud/targets/googlefirestore/#iotriggermeshgooglefirestorequerytables"},{"title":"io.triggermesh.google.firestore.query.table","text":"<p>Events of this type contain nuanced data that is used to specify the document, collection, and data on each call to the target.</p> <p>This type expects a JSON payload with the following properties:</p>    Name Type Comment Example     collection string Defines the firebase collection to be queried. \"eventtst\"   document string Defines the firebase document name to retrieved. \"536808d3-88be-4077-9d7a-a3f162s705f79\"    <p>This event responds with an event of type: <code>io.triggermesh.google.firestore.query.table.response</code></p>","location":"cloud/targets/googlefirestore/#iotriggermeshgooglefirestorequerytable"},{"title":"Event Target for Google Sheets","text":"<p>This event Target receives CloudEvents over HTTP and appends the event payload to a GoogleSheets Sheet.</p>","location":"cloud/targets/googlesheets/"},{"title":"Prerequisite(s)","text":"<ul> <li>Google API credentials</li> <li>GoogleSheets Sheet ID</li> </ul>","location":"cloud/targets/googlesheets/#prerequisites"},{"title":"Google API Credentials","text":"<ol> <li>Head to the Google Developers Console and create a new  project (or select the one you have).</li> <li>Under APIs &amp; Services &gt; Library, search for \u201cSheets API\u201d and enable it.</li> <li>Go to APIs &amp; Services &gt; Credentials and choose \u201cCreate credentials &gt; Service account\u201d. Enter a service account name, ID, and description. You can skip optional fields, no additional roles or  user access is required.</li> <li>On the last step of service account creation, download the JSON key file.</li> <li>Use the email from the <code>client_email</code> field within the JSON key file to share the GoogleSheets Sheet you want the Target to have access to. The Notify people checkbox should be unchecked.</li> </ol> <p>Consult the Secrets guide for more information about how to add the Google API key as a secret.</p>","location":"cloud/targets/googlesheets/#google-api-credentials"},{"title":"GoogleSheets Sheet ID","text":"<p>In your browser, navigate to the GoogleSheets Sheet you want to use. You can find the Sheet ID in one of two ways:</p> <ul> <li>From path: <code>https://docs.google.com/spreadsheets/d/&lt;SHEET_ID&gt;/edit</code></li> <li>From query string: <code>https://docs.google.com/spreadsheet/ccc?key=&lt;SHEET_ID&gt;</code></li> </ul>","location":"cloud/targets/googlesheets/#googlesheets-sheet-id"},{"title":"Deploying an Instance of the Target","text":"<p>Open the Bridge creation screen and add a Target of type <code>GoogleSheets</code>.</p> <p></p> <p>In the Target creation form, provide a name for the event Target and add the following information:</p> <ul> <li>Google Service Account Secret: Reference to a TriggerMesh secret containing a Google API key as discussed in Google API Credentials.</li> <li>ID: The GoogleSheets Sheet ID to send the event payload to.</li> <li>Default Prefix: A string used during new sheet creation when the event does not provide one.</li> </ul> <p></p> <p>After clicking the <code>Save</code> button, the console will self-navigate to the Bridge editor. Proceed by adding the remaining components to the Bridge.</p> <p></p> <p>After submitting the Bridge, and allowing for some configuration time, a green check mark on the main Bridges page indicates that the Bridge with a GoogleSheets event Target was successfully created.</p> <p></p>","location":"cloud/targets/googlesheets/#deploying-an-instance-of-the-target"},{"title":"Event Types","text":"<p>The GoogleSheets Target will accept any event type, and by default, will stringify the CloudEvent and save the data in a new row.</p>","location":"cloud/targets/googlesheets/#event-types"},{"title":"io.triggermesh.googlesheet.append","text":"<p>Events of this type contain nuanced data that is used to append the event data to a new row.</p> <p>This type expects a JSON payload with the following properties:</p>    Name Type Comment     sheet_name_prefix string The prefix to be used for creating new sheets   message string A string to append to the sheet row","location":"cloud/targets/googlesheets/#iotriggermeshgooglesheetappend"},{"title":"Event Target for Hasura","text":"<p>This event Target receives CloudEvents as either a GraphQL query or key/value pairs for a known query and sends it to Hasura.</p>","location":"cloud/targets/hasura/"},{"title":"Prerequisite(s)","text":"<ul> <li> <p>Hasura server URL to submit the query against</p> </li> <li> <p>Admin secret or JWT</p> </li> </ul>","location":"cloud/targets/hasura/#prerequisites"},{"title":"Admin Secret or JWT","text":"<p>If the Hasura server requires authentication, an admin secret or JWT signed with the server's key will be required.</p> <p>If using JWT, you may choose to add an optional user role to invoke the queries as.</p> <p>Consult the Secrets guide for more information about how to add the admin or user JWT as secrets.</p>","location":"cloud/targets/hasura/#admin-secret-or-jwt"},{"title":"Deploying an Instance of the Target","text":"<p>Open the Bridge creation screen and add a Target of type <code>Hasura</code>.</p> <p></p> <p>In the Target creation form, provide a name for the event Target and add the following information:</p> <ul> <li>Admin Token for Hasura: Reference to a TriggerMesh secret containing an admin secret or JWT to communicate with Hasura as discussed in Admin Secret or JWT.</li> <li>Hasura Server URL: URL endpoint to communicate with Hasura.</li> <li>Default Role: Specify the Hasura user role to use when querying Hasura.</li> <li>Pre-canned Queries: A key/value pair of predefined queries available for CloudEvents to specify.</li> </ul> <p></p> <p>After clicking the <code>Save</code> button, the console will self-navigate to the Bridge editor. Proceed by adding the remaining components to the Bridge.</p> <p></p> <p>After submitting the Bridge, and allowing for some configuration time, a green check mark on the main Bridges page indicates that the Bridge with a Hasura event Target was successfully created.</p> <p></p> <p>For more information about using Hasura and GraphQL, please refer to the Hasura and GraphQL documentation.</p>","location":"cloud/targets/hasura/#deploying-an-instance-of-the-target"},{"title":"Event Types","text":"<p>A Hasura event Target accepts the following CloudEvent types:</p>","location":"cloud/targets/hasura/#event-types"},{"title":"org.graphql.query.raw","text":"<p>Events of this type are raw GraphQL queries intended to be submitted directly to Hasura.</p> <p>This type expects a JSON payload with the following properties:</p>    Name Type Comment     query string The GraphQL to run against the Hasura server   operationName string The query name specified in the query attribute   variables map[string]string Key/value pairs of variables with the key defined in the query    <p>The response event will have the <code>ce-type</code> attribute set to <code>org.graphql.query.result</code> and <code>ce-source</code> attribute set to the Target's endpoint.</p>","location":"cloud/targets/hasura/#orggraphqlqueryraw"},{"title":"org.graphql.query","text":"<p>Events of this type leverage the pre-defined query defined when the Target is created. In addition to the <code>ce-type</code>, the <code>ce-subject</code> must be set to the name of the pre-defined query, otherwise the event will not be processed by the Target.</p> <p>The JSON payload for this type must consist of a string dictionary where the keys correspond to the variables defined in the query, and key's value is passed as a string.</p> <p>The response event will have the <code>ce-type</code> attribute set to <code>org.graphql.query.result</code> and <code>ce-source</code> attribute set to the Target's endpoint.</p>","location":"cloud/targets/hasura/#orggraphqlquery"},{"title":"Event Target for HTTP","text":"<p>This event Target receives CloudEvents and turns them into HTTP requests that consume external services.</p>","location":"cloud/targets/http/"},{"title":"Prerequisite(s)","text":"<ul> <li>HTTP endpoints</li> <li>Password</li> </ul>","location":"cloud/targets/http/#prerequisites"},{"title":"HTTP Endpoints","text":"<p>The HTTP event Target sends requests to arbitrary URLs and wraps responses in CloudEvents back to the caller. HTTP endpoints that are unauthenticated, use basic authentication or use custom header values for authentication, can be integrated using this target.</p> <p>Responses from external HTTP endpoints are converted into CloudEvents and sent as a reply to the TriggerMesh Broker/Channel. It is important that the HTTP Target filters received events and cares about response event type and event source to avoid loops where those responses might end up being processed by the HTTP Target.</p> <p>Requests from this HTTP Target will verify TLS certificates from the remote server if present. If the CA certificate at the server is self-signed, the public certificate needs to be added to the configuration, or alternatively mark the <code>Skip Verify</code> option.</p>","location":"cloud/targets/http/#http-endpoints"},{"title":"Password","text":"<p>If the remote endpoint requires basic authentication, the password needs to be created as a secret. Consult the Secrets guide for more information about how to add the password as a secret.</p>","location":"cloud/targets/http/#password"},{"title":"Deploying an Instance of the Target","text":"<p>Open the Bridge creation screen and add a Target of type <code>HTTP</code>.</p> <p>In the Target creation form, provide a name for the event Target and add the following information:</p> <ul> <li>Response Event Type: The event type for responses from the remote endpoint.</li> <li>EventSource: The origin for all responses. When not informed, source will be automatically set to a generated name that includes the HTTP Target component name.</li> <li>Endpoint: The full URL for the remote service, including path and query string, if any.</li> <li>Method: The method to use when executing requests against the remote endpoint.</li> <li>CA Certificate: The CA certificate configured for TLS connection.</li> <li>Skip Verify: Allow skipping the remote server TLS certificate verification.</li> <li>Username: Username when using basic authentication.</li> <li>Password: Password when using basic authentication. Needs to reference the password secret discussed in the prerequisites.</li> <li>Headers: A set of key/value pairs that will be set within the HTTP request.</li> </ul> <p>After clicking the <code>Save</code> button, the console will self-navigate to the Bridge editor. Proceed by adding the remaining components to the Bridge.</p> <p>After submitting the Bridge, and allowing for some configuration time, a green check mark on the main Bridges page indicates that the Bridge with an Elasticsearch event Target was successfully created.</p>","location":"cloud/targets/http/#deploying-an-instance-of-the-target"},{"title":"Trigger Configuration","text":"<p>Responses from the remote endpoint will generate new CloudEvents that will be returned to TriggerMesh. Those response events should not be re-processed by the HTTP Target.</p> <p>It is important that the Trigger that subscribes the HTTP Target to the Broker configures the appropriate filters to avoid these loops.</p> <p>As an example:</p> <ul> <li>We configure an HTTP Target to integrate with Workday.</li> <li>HTTP Target is interested in events whose type is <code>calendar.pto.request</code>.</li> <li>The response from Workday will generate a CloudEvent of type <code>workday.pto.response</code> and source of <code>workday.instance1</code>.</li> </ul> <p>Trigger should be configured to avoid feeding these responses into the HTTP Target. A filter key type and value of <code>calendar.pto.request</code> would provide such protection.</p>","location":"cloud/targets/http/#trigger-configuration"},{"title":"Event Types","text":"<p>The HTTP Target expects a CloudEvent request that complements the Target configured values.</p> <p>There is no requirement regarding the type header value. Any CloudEvent containing the expected data is valid to process. Data needs to be a JSON structure that might contain these optional fields:</p>    Field Description Example     query_string Key/value pairs formatted as query string <code>name=jane&amp;lastname=doe</code>   path_suffix Will be appended to the target's path <code>apparel/tshirts</code>   body String to be set as the request body <code>{\\\"size\\\":\\\"L\\\",\\\"color\\\":\\\"beige\\\"}</code>    <p>CloudEvent data examples:</p> <pre><code>{\"path_suffix\":\"world/italy/cities\", \"query_string\":\"top=10&amp;format=csv\"}\n</code></pre> <p>If body is a JSON structure, it will need to be stringified:</p> <pre><code>{\"body\": \"{\\\"records\\\":[{\\\"value\\\":{\\\"this\\\":{\\\"is\\\": \\\"sparta\\\"}}}]}\"}\n</code></pre>","location":"cloud/targets/http/#event-types"},{"title":"InfraJS Target","text":"<p>This event Target does programmatic transformations on received CloudEvents using a Javascript function.</p>","location":"cloud/targets/infrajs/"},{"title":"Prerequisite(s)","text":"<ul> <li>Basic knowledge of JavaScript ES5 is required. Please note there are limitations to the interpreter:<ul> <li>ES6 is not supported.</li> <li>Regular expressions are not fully compatible with ES5 specification.</li> <li>No imports are allowed.</li> <li>No libraries are pre-loaded.</li> </ul> </li> </ul>","location":"cloud/targets/infrajs/#prerequisites"},{"title":"Deploying an Instance of the Target","text":"<p>Open the Bridge creation screen and add a Target of type <code>InfraJS</code>.</p> <p>In the Target creation form, provide a name for the event Target and add the following information:</p> <ul> <li>JS Script: The function that contains the event manipulation.</li> <li>Timeout: The amount of milliseconds to wait before timing out the script.</li> <li>Type Loop Protection: When enabled, will raise an error if the returned CloudEvent type is the same as the incoming one.</li> </ul> <p>After clicking the <code>Save</code> button, the console will self-navigate to the Bridge editor. Proceed by adding the remaining components to the Bridge.</p> <p>After submitting the Bridge, and allowing for some configuration time, a green check mark on the main Bridges page indicates that the Bridge with an Elasticsearch event Target was successfully created.</p>","location":"cloud/targets/infrajs/#deploying-an-instance-of-the-target"},{"title":"JS Script","text":"<p>The JS Script field must include a function named <code>handle</code> with a single parameter for the incoming CloudEvent, and return the outgoing CloudEvent.</p> <ul> <li>The incoming parameter is the JSON representation of the incoming event.</li> <li>The incoming parameter can be re-used as the outgoing parameter. That is useful if we want to modify a small set of the values in the incoming event.</li> <li>The outgoing event must be a JSON structure that contains context attributes at the root and data payload at the <code>data</code> element. See JSON format reference.</li> <li>If the outgoing event is nil or no outgoing event is returned, no CloudEvent will be replied and the processing will be considered successful.</li> <li>When not present at the outgoing event, these context fields will be defaulted:<ul> <li><code>specversion</code> will be set to the incoming value.</li> <li><code>source</code> will be set to the incoming value.</li> <li><code>id</code> will be set to the incoming value.</li> <li><code>datacontenttype</code> will default to <code>application/json</code>.</li> </ul> </li> </ul>","location":"cloud/targets/infrajs/#js-script"},{"title":"XML Support","text":"<p>InfraJS scripting does not support any XML library and cannot manipulate XML. However under certain circunstances XML can be used to create outgoing events:</p> <ul> <li>Incoming event <code>data</code> element must contain a valid XML element</li> <li><code>datacontenttype</code> attribute, which is <code>Content-Type</code> HTTP header, must be set to either <code>application/xml</code> or <code>text/xml</code></li> </ul> <p>In such cases the XML data is converted to JSON element by element. If XML attributes are present the element is rendered using prefixes:</p> <ul> <li>An attribute will be rendered as a chile JSON element prepended with <code>-</code></li> <li>An element that contains attributes and also text, will render the text on a <code>#text</code> element.</li> </ul> <p>For example: - incoming event <code>&lt;A&gt;&lt;B&gt;B value&lt;/B&gt;&lt;C attr=\"C attr\"&gt;C Value&lt;/C&gt;&lt;/A&gt;</code> - will be avaliable as <code>{\"A\":{\"B\":\"B value\",\"C\":{\"#text\":\"C Value\",\"-attr\":\"C attr\"}}}</code></p>","location":"cloud/targets/infrajs/#xml-support"},{"title":"Examples","text":"<p>These examples for the InfraJS target show different usages of the <code>JS Script</code> function. The incoming parameter for all of the examples will be this CloudEvent:</p> <pre><code>{\n  \"id\": \"aabb-ccdd\",\n  \"type\": \"example.type\",\n  \"source\": \"example.source\",\n  \"specversion\" : \"1.0\",\n  \"datacontenttype\" : \"application/json\",\n  \"data\": {\"key1\":\"value1\",\"key2\":\"value2\",\"key3\": true}\n}\n</code></pre>","location":"cloud/targets/infrajs/#examples"},{"title":"Reply New Event","text":"<p>Discard the input and generate a new event. Context fields missing at the new event will be automatically filled from the input.</p> <pre><code>function handle(input) {\n  newEvent = {\n    data: {\n      \"hello\": \"world\",\n      \"nest\": {\n        \"nested1\": [1,2,3],\n        \"nested2\": \"nestedvalue\"\n      }\n    },\n    \"type\": \"test.response.type\",\n  };\n\n  return newEvent;\n}\n</code></pre> <p>Values from the input event can be used when composing the reply.</p> <pre><code>function handle(input) {\n  newEvent = {\n    data: {\n      \"hello\": \"world\",\n      \"works\": input.data.key3,\n      \"nest\": {\n        \"nested1\": [1,2,3],\n        \"nested2\": input.data.key1\n      }\n    },\n    \"type\": \"test.response.type\",\n  };\n\n  return newEvent;\n}\n</code></pre>","location":"cloud/targets/infrajs/#reply-new-event"},{"title":"Conditional Reply","text":"<p>Conditionals can be used for a range of cases. In this example the value of a field is used to decide if a reply should be emitted.</p> <pre><code>function handle(input) {\n  if (input.data.key3 == true) {\n    return;\n  }\n\n  newEvent = {\n    data: { \"hello\": \"world\" },\n    \"type\": \"test.response.type\",\n  };\n\n  return newEvent;\n}\n</code></pre> <p>Conditionals can also be used to set different CloudEvent types, which might be useful to route events, or bring complex logic composing the outgoing data payload.</p>","location":"cloud/targets/infrajs/#conditional-reply"},{"title":"Reply Using Incoming Event","text":"<p>When the output event shares structure with the incoming event, it is recommended to use the incoming parameter object as the reply.</p> <pre><code>function handle(input) {\n  // modify context type\n  input.type = \"test.response.type\";\n\n  // add context subject field\n  input.subject = \"InfraJS test\";\n\n  // add extended header to context\n  input.environment = \"production\";\n\n  // add new data field\n  input.data.key4 = Date().toString();\n\n  // replace data field\n  input.data.key3 = false;\n\n  // modify data field\n  input.data.key2 = input.data[\"key2\"] + \".extended\";\n\n  // delete data field\n  delete input.data[\"key1\"];\n\n  return input;\n}\n</code></pre>","location":"cloud/targets/infrajs/#reply-using-incoming-event"},{"title":"Using logs","text":"<p>Although the <code>console</code> object is available, the InfraJS script provides a <code>log</code> function that accepts a string message, and write logs in a format that can be processed along with the rest of logs produced at this target.</p> <pre><code>function handle(input) {\n  if (input.type == \"not.wanted.type\") {\n    log(\"we received a non wanted type!\");\n    return;\n  }\n\n  input.type = \"test.response.type\";\n\n  return input;\n}\n</code></pre>","location":"cloud/targets/infrajs/#using-logs"},{"title":"Using built-in functions","text":"<p>Javascript core functions (ES5) can be used. In this example we are preparing a JSON payload to be sent to the HTTP Target, which requires a stringified <code>body</code> element.</p> <pre><code>function handle(input) {\n  body = {\n    \"search\": [{ \"key\": input.data.key1 }]\n  };\n\n  event = {\n    type: \"searchservice.request\",\n    \"data\": { \"body\": JSON.stringify(body) }\n  };\n\n  return event;\n}\n</code></pre>","location":"cloud/targets/infrajs/#using-built-in-functions"},{"title":"Event Target for Jira","text":"<p>This event Target receives CloudEvents and invokes a Jira endpoint.</p>","location":"cloud/targets/jira/"},{"title":"Prerequisite(s)","text":"<ul> <li>Jira instance or Atlassian cloud tenant</li> <li>User API token</li> </ul>","location":"cloud/targets/jira/#prerequisites"},{"title":"User API token","text":"<ol> <li>Open Account settings &gt; Security &gt; Create and Manage API Tokens</li> <li>Click <code>Create API token</code> and fill out the token name.</li> <li>Copy the API token and create a secret for the Jira token at TriggerMesh.</li> </ol> <p>Consult the Secrets guide for more information about how to add a secret.</p>","location":"cloud/targets/jira/#user-api-token"},{"title":"Deploying an Instance of the Target","text":"<p>Open the Bridge creation screen and add a Target of type <code>Jira</code>.</p> <p></p> <p>In the Target creation form, provide a name for the event Target, and add the following information:</p> <ul> <li>User: the Jira user account that created the token.</li> <li>URL: base URL for the Jira instance.</li> </ul> <p>After clicking the <code>Save</code> button, the console will self-navigate to the Bridge editor. Proceed by adding the remaining components to the Bridge.</p> <p>After submitting the Bridge, and allowing for some configuration time, a green check mark on the main Bridges page indicates that the Bridge with a Jira event Target was successfully created.</p> <p></p>","location":"cloud/targets/jira/#deploying-an-instance-of-the-target"},{"title":"Event Types","text":"<p>The Jira event Target accepts these event types:</p>","location":"cloud/targets/jira/#event-types"},{"title":"io.triggermesh.jira.issue.create","text":"<p>The Jira event Target will create an issue when receiving this event type. The CloudEvent data must contain a Jira issue JSON formatted as defined in this schema.</p> <p>Reply contains a partially filled Jira issue with updated data.</p>","location":"cloud/targets/jira/#iotriggermeshjiraissuecreate"},{"title":"io.triggermesh.jira.issue.get","text":"<p>The Jira event Target will retrieve an issue when receiving this event type. The CloudEvent data must contain a Jira issue <code>GET</code> request JSON formatted as defined in this schema.</p> <p>Reply data contains a Jira issue.</p>","location":"cloud/targets/jira/#iotriggermeshjiraissueget"},{"title":"io.triggermesh.jira.custom","text":"<p>The Jira event Target will send a request to the Jira API when this event type is received. The CloudEvent data expects a generic API request as defined in this schema.</p> <p>For more information on the Jira API, please refer to the Jira API documentation.</p>","location":"cloud/targets/jira/#iotriggermeshjiracustom"},{"title":"Examples","text":"<p>Create a custom request to retrieve Jira projects:</p> <ul> <li>Event Type: <code>io.triggermesh.jira.custom</code></li> <li>Data: <pre><code>{\n  \"method\": \"GET\",\n  \"path\": \"/rest/api/3/project\"\n}\n</code></pre></li> </ul> <p>List assignable users for a project:</p> <ul> <li>Event Type: <code>io.triggermesh.jira.custom</code></li> <li>Data: <pre><code>{\n  \"method\": \"GET\",\n  \"path\": \"/rest/api/3/user/assignable/search\",\n  \"query\": { \"project\": \"Project1\" }\n}\n</code></pre></li> </ul> <p>Create an issue:</p> <ul> <li>Event Type: <code>io.triggermesh.jira.issue.create</code></li> <li>Data: <pre><code>{\n  \"fields\": {\n    \"project\":\n      {\n        \"key\": \"Project1\"\n      },\n      \"labels\": [\"triggermesh\",\"automated\"],\n      \"summary\": \"Delete this test ticket.\",\n      \"description\": \"This is a test issue created using TriggerMesh Jira Target\",\n      \"issuetype\": {\n        \"name\": \"Task\"\n      },\n      \"assignee\": {\n        \"accountId\": \"5fe0704c9edf280075f188f0\"\n      }\n   }\n}\n</code></pre></li> </ul> <p>Retrieve an issue:</p> <ul> <li>Event Type: <code>io.triggermesh.jira.issue.get</code></li> <li>Data: <pre><code>{ \"id\":\"IP-9\" }\n</code></pre></li> </ul>","location":"cloud/targets/jira/#examples"},{"title":"Event Target for Logz.io","text":"<p>This event Target receives CloudEvents and ships messages to Logz.io.</p>","location":"cloud/targets/logz/"},{"title":"Prerequisite(s)","text":"<ul> <li>Logz.io account</li> <li>Logz.io shipping token</li> </ul> <p>Consult the Secrets guide for more information about how to add the Logz.io shipping token as a secret.</p>","location":"cloud/targets/logz/#prerequisites"},{"title":"Deploying an Instance of the Target","text":"<p>Open the Bridge creation screen and add a Target of type <code>Logz</code>.</p> <p></p> <p>In the Target creation form, provide a name for the event Target, and add the following information:</p> <ul> <li>Shipping Token: Reference to a TriggerMesh secret containing the Logz.io shipping token as discussed in the prerequisites.</li> <li>Logs Listener URL: An API endpoint that can be found above your shipping token in the Logz.io dashboard.</li> </ul> <p></p> <p>After clicking the <code>Save</code> button, the console will self-navigate to the Bridge editor. Proceed by adding the remaining components to the Bridge.</p> <p>After submitting the Bridge, and allowing for some configuration time, a green check mark on the main Bridges page indicates that the Bridge with was successfully created.</p>","location":"cloud/targets/logz/#deploying-an-instance-of-the-target"},{"title":"Event Types","text":"<p>A Logz event Target accepts the following CloudEvent types:</p>","location":"cloud/targets/logz/#event-types"},{"title":"io.triggermesh.logz.ship","text":"<p>The Logz event Target can also consume events of type <code>io.triggermesh.logz.ship</code>, and will produce responses typed <code>io.triggermesh.logz.ship.response</code>. </p> <p>The payload contains a JSON structure with elements to execute the API request:</p> <ul> <li><code>message</code>: The message to log within Logz.io</li> </ul>","location":"cloud/targets/logz/#iotriggermeshlogzship"},{"title":"Examples","text":"<p>Create a Logz message:</p> <ul> <li>Event Type: <code>io.triggermesh.logz.ship</code></li> <li>Data: <pre><code>{ \"message\":\"hello world\" }\n</code></pre></li> </ul>","location":"cloud/targets/logz/#examples"},{"title":"Event Target for Oracle Cloud","text":"<p>This event Target sends and receives CloudEvents over HTTP and calls a targeted Oracle Cloud Service.</p>","location":"cloud/targets/oracle/"},{"title":"Prerequisite(s)","text":"<ul> <li>Oracle API signing key</li> </ul>","location":"cloud/targets/oracle/#prerequisites"},{"title":"Oracle API Signing Key","text":"<p>You can find the steps to obtain an API signing key in the Oracle Developer Guide.</p> <p>Consult the Secrets guide for more information about how to add the Oracle API signing key as a secret.</p>","location":"cloud/targets/oracle/#oracle-api-signing-key"},{"title":"Deploying an Instance of the Target","text":"<p>Open the Bridge creation screen and add a Target of type <code>Oracle</code>.</p> <p>In the Target creation form, provide a name for the event Target and add the following information:</p> <ul> <li>Oracle Secrets: Reference to a TriggerMesh secret containing the Oracle API signing key as discussed in the prerequisites.</li> <li>Oracle Tenancy: The OCID of tenant that holds the service being invoked.</li> <li>Oracle Username: The OCID of the user that owns the API key discussed in the prerequisites, and will be invoking the service.</li> <li>Oracle Region: The Oracle Cloud region hosting the service.</li> <li>Function: The OCID of the Oracle Cloud function being invoked.</li> </ul> <p>After clicking the <code>Save</code> button, the console will self-navigate to the Bridge editor. Proceed by adding the remaining components to the Bridge.</p> <p>After submitting the Bridge, and allowing for some configuration time, a green check mark on the main Bridges page indicates that the Bridge with a Datadog event Target was successfully created.</p>","location":"cloud/targets/oracle/#deploying-an-instance-of-the-target"},{"title":"Supported Oracle Cloud Service Events","text":"","location":"cloud/targets/oracle/#supported-oracle-cloud-service-events"},{"title":"Functions","text":"<p>The Oracle Cloud Functions event Target is designed to allow for free-form JSON objects to be passed directly to the function and rely on the Oracle Cloud function to perform whatever action is desired.</p> <p>The function itself can return a freeform JSON object that can be processed by another event trigger.  The CloudEvent type will always be <code>functions.oracletargets.targets.triggermesh.io</code> with the function OCID defined as a part of the CloudEvent source and a metadata ID used to uniquify the specific event that called the function.</p>","location":"cloud/targets/oracle/#functions"},{"title":"Oracle Function Example","text":"<pre><code>curl -vvv http://oracletarget \\\n  -X POST \\\n  -H 'Content-Type: application/json' \\\n  -H 'Ce-Specversion: 1.0' \\\n  -H 'Ce-Id: foo-1' \\\n  -H 'Ce-Type: testfunc.functions.oracle.triggermesh.io' \\\n  -H 'Ce-Source: h2g2.guide' \\\n  -d '{\"message\": \"A new user wants to say something: hello from triggermesh\"}'\n\n[...]\n&lt; HTTP/2 200\n&lt; ce-id: 9ab5e1f0-9713-405e-816c-1ba2739a7358\n&lt; ce-source: ocid1.fnapp.oc1.phx.aaaaaaaaaehdhsmharxvyp4pvnsgsnd35am5u7ckjzivwmsmove37eckjika\n&lt; ce-specversion: 1.0\n&lt; ce-subject: ocid1.fnfunc.oc1.phx.aaaaaaaaaajrgy4on66e6krko73h2im5qaiiagecg5hmbcqib2kpbzlcy3bq\n&lt; ce-time: 2020-08-03T19:04:55.381594978Z\n&lt; ce-type: functions.oracletargets.targets.triggermesh.io\n&lt; content-length: 86\n&lt; content-type: application/json\n&lt; date: Mon, 03 Aug 2020 19:04:55 GMT\n&lt; x-envoy-upstream-service-time: 1497\n&lt; server: istio-envoy\n&lt;\n* Connection #0 to host oracletarget left intact\n{\"processed\":{\"message\": \"A new user wants to say something: hello from triggermesh\"}}\n</code></pre>","location":"cloud/targets/oracle/#oracle-function-example"},{"title":"Event Target for Salesforce","text":"<p>This event Target receives CloudEvents and invokes a Salesforce endpoint.</p>","location":"cloud/targets/salesforce/"},{"title":"Prerequisite(s)","text":"<ul> <li>Salesforce account</li> <li>Certificate key secret</li> </ul>","location":"cloud/targets/salesforce/#prerequisites"},{"title":"Salesforce Account","text":"<p>Salesforce Target uses OAuth JWT credentials for service authentication.</p> <p>First, you will need to generate an X509 certificate for signing and verifying requests. We will be using <code>OpenSSL</code>, but any other certificate generation tool will work.</p> <pre><code>openssl req -x509 -sha256 -nodes -days 36500 -newkey rsa:2048 -keyout tm-sf.key -out tm-sf.crt\n</code></pre> <ol> <li> <p>On the Salesforce site select Setup &gt; Apps &gt; App Manager, click on New Connected App.</p> <ul> <li>Fill in mandatory fields, then click Enable OAuth Settings.</li> <li>A callback URL is mandatory but can be filled with any HTTPS data.</li> <li>Enable <code>Use digital signatures</code> and upload the public cert (<code>tm-sf.crt</code> in the example above).</li> <li>Add Scopes for <code>api</code>, <code>refresh_token</code>, and <code>offline_access</code>.</li> <li>Click <code>Save</code>.</li> </ul> <p></p> <ul> <li>Select the connected app you just created from the list and then click <code>Manage</code>.</li> <li>Click <code>Edit policies</code>.</li> <li>Set <code>Permitted users</code> to <code>Admin approved users are pre-authorized</code>.</li> <li>Click <code>Save</code>.</li> </ul> <p></p> <ul> <li>Select the connected app from the list and then click <code>Manage</code>.</li> <li>Click <code>Manage Profiles</code>.</li> <li>Add permissions on the data this user will have access to.</li> <li>Click <code>Save</code>.</li> </ul> </li> <li> <p>Retrieve OAuth data to configure TriggerMesh Target.</p> <ul> <li>Select the connected app from the list and then click <code>View</code>.</li> <li>Copy the <code>Consumer Key</code>.</li> <li>Reveal and copy the <code>Consumer Secret</code>.</li> </ul> </li> </ol>","location":"cloud/targets/salesforce/#salesforce-account"},{"title":"Certificate Key Secret","text":"<p>The TriggerMesh Salesforce integration needs a certificate key secret to sign requests for the Salesforce API. Consult the Secrets guide for more information about how to add the certificate key as a secret.</p> <p>The file name containing the key will need to be renamed to <code>certKey</code>. After that, go to Secrets &gt; Add Secret &gt; File Upload.</p> <p></p>","location":"cloud/targets/salesforce/#certificate-key-secret"},{"title":"Deploying an Instance of the Target","text":"<p>Open the Bridge creation screen and add a Target of type Salesforce.</p> <p></p> <p>In the Target creation form, provide a name for the event Target, and add the following information:</p> <ul> <li>Client ID: The client ID as retrieved from the Salesforce connected app.</li> <li>Server: The server used for Salesforce authentication.</li> <li>User: User for the Salesforce account.</li> <li>Reply Events Policy: Indicates when event responses should be sent back from this target.</li> </ul> <p>After clicking the <code>Save</code> button, the console will self-navigate to the Bridge editor. Proceed by adding the remaining components to the Bridge.</p> <p>After submitting the Bridge, and allowing for some configuration time, a green check mark on the main Bridges page indicates that the Bridge with was successfully created.</p> <p></p>","location":"cloud/targets/salesforce/#deploying-an-instance-of-the-target"},{"title":"Event Types","text":"<p>The Salesforce event Target expects an event type of <code>io.triggermesh.salesforce.apicall</code> to perform a request against the Salesforce API, and will producedresponses typed <code>io.triggermesh.salesforce.apicall.response</code>. The CloudEvent data should contain a request as defined in this schema.</p> <p>This type expects a JSON payload with the following properties:</p>    Name Comment     action The HTTP verb to use (Required)   resource The object family to use   object The object type to operate on   record The object instance   query Parameterized key/values for the API request   payload Body contents for the request    <p>All of the parameters, except for payload, are put together sequentially to build the request that will be sent to the Salesforce API:</p> <pre><code>https://&lt;salesforce-host&gt;/services/data/&lt;version&gt;/&lt;resource&gt;/&lt;object&gt;/&lt;record&gt;?query\n</code></pre> <p>For more information about using the Salesforce API, please refer to the Salesforce API documentation.</p>","location":"cloud/targets/salesforce/#event-types"},{"title":"Reply Events Policy","text":"<p>When a request is sent using this Target, a response might be produced containing the reply from Salesforce or an error. Depending on if there are other Targets listening to these new events you might want to configure the reply behavior from this component. There are three possible values for the reply events policy:</p> <ul> <li><code>Never</code>: No response will be produced.</li> <li><code>Error</code>: Only errors will be returned from the Target.</li> <li><code>Always</code>: External responses or errors will be produced.</li> </ul> <p>When a response is produced from a Target, the extended attribute <code>category</code> is added which will contain one of two values:</p> <ul> <li><code>Success</code>: For when the request succeeds.</li> <li><code>Error</code>: For when an error occurs.</li> </ul> <p>Returned errors structure is defined in this schema.</p>","location":"cloud/targets/salesforce/#reply-events-policy"},{"title":"Examples","text":"<p>Create a Salesforce Account object:</p> <ul> <li>Event Type: <code>io.triggermesh.salesforce.apicall</code></li> <li>Data: <pre><code>{\n  \"action\": \"POST\",\n  \"resource\": \"sobjects\",\n  \"object\": \"account\",\n  \"payload\": { \"Name\": \"Jane Doe\" }\n}\n</code></pre></li> </ul> <p>Update a Salesforce Account object:</p> <ul> <li>Event Type: <code>io.triggermesh.salesforce.apicall</code></li> <li>Data: <pre><code>{\n  \"action\": \"PATCH\",\n  \"resource\": \"sobjects\",\n  \"object\": \"account\",\n  \"record\": \"0014x000005Y9SNAA0\",\n  \"payload\": { \"Name\": \"Janet Does\", \"BillingCity\" : \"San Francisco\" }\n}\n</code></pre></li> </ul> <p>Retrieve specific fields of a Salesforce Account:</p> <ul> <li>Event Type: <code>io.triggermesh.salesforce.apicall</code></li> <li>Data: <pre><code>{\n  \"action\": \"GET\",\n  \"resource\": \"sobjects\",\n  \"object\": \"account\",\n  \"record\": \"0014x000005Y9SNAA0\",\n  \"query\": { \"fields\": \"AccountNumber,BillingCity\" }\n}\n</code></pre></li> </ul> <p>Delete a Salesforce Account object: - Event Type: <code>io.triggermesh.salesforce.apicall</code> - Data: <pre><code>{\n  \"action\": \"DELETE\",\n  \"resource\": \"sobjects\",\n  \"object\": \"account\",\n  \"record\": \"0014x000005Y9SNAA0\"\n}\n</code></pre></p>","location":"cloud/targets/salesforce/#examples"},{"title":"Event Target for SendGrid","text":"<p>This event Target receives CloudEvents and utilizes SendGrid to enable the creation and delivery of email messages via event data and event occurrence, respectively.</p>","location":"cloud/targets/sendgrid/"},{"title":"Prerequisite(s)","text":"<ul> <li>SendGrid account</li> <li>SendGrid API token</li> </ul> <p>Consult the Secrets guide for more information about how to add the SendGrid API token as a secret.</p>","location":"cloud/targets/sendgrid/#prerequisites"},{"title":"Deploying an Instance of the Target","text":"<p>Open the Bridge creation screen and add a target of type <code>SendGrid</code>.</p> <p></p> <p>In the Target creation form, provide a name for the event Target, and add the following information:</p> <ul> <li>Default sender name: Define a default 'name' to be assigned in the <code>From:</code> section of the email to be created, if the received event does not contain a <code>FromName</code> property.</li> <li>Default sender email: Define a default email address to be assigned in the <code>From:</code> section of the email to be created, if the received event does not contain a <code>FromEmail</code> property.</li> <li>Default recipient name: Define a default name to be assigned in the <code>To:</code> section of the email to be created, if the received event does not contain a <code>FromEmail</code> property.</li> <li>Default recipient email: Define a default 'email address' to be assigned in the <code>To:</code> section of the email to be created, if the received event does not contain a <code>ToEmail</code> property.</li> <li>Default subject: Define a default subject to be assigned to the outgoing email to be created, if the received event does not contain a <code>subject</code> property.</li> <li>API Secret: Reference to a TriggerMesh secret containing an API token for authenticating requests.</li> </ul> <p>Note: If there is not a default value specified for all of the optional fields, the event received by that deployment MUST contain all of the information noted in the Event Types, except for <code>Message</code>, or the Target will fail.</p> <p></p> <p>After clicking the <code>Save</code> button, the console will self-navigate to the Bridge editor. Proceed by adding the remaining components to the Bridge.</p> <p>After submitting the Bridge, and allowing for some configuration time, a green check mark on the main Bridges page indicates that the Bridge with a SendGrid event Target was successfully created.</p> <p></p> <p>For more information about using SendGrid, please refer to the SendGrid documentation.</p>","location":"cloud/targets/sendgrid/#deploying-an-instance-of-the-target"},{"title":"Event Types","text":"<p>Depending on how the Target is to be used, defaults can be configured for all available parameters and the Target can accept arbitrary events. Or none of the defaults can be set and these parameters can be passed in at runtime via the event payload.</p> <p>The SendGrid event Target accepts a JSON payload with the following properties that will overwrite their respective <code>spec</code> parameters:</p>    Name Type Comment Required     FromName string Sender's name false   FromEmail string Sender's email false   ToName string Recipient's name false   ToEmail string Recipient's email false   Message string Contents of the message body false   Subject string Assigns a subject to the email false    <p>When a <code>Message</code> property is not present, the entire cloud event is passed into the email <code>body</code> by default.</p> <p>Note: If there is not a default value specified for all of the optional fields, the event received by that deployment MUST contain all of the information noted in the Event Types, save <code>Message</code>, or the Target will fail.</p>","location":"cloud/targets/sendgrid/#event-types"},{"title":"Example","text":"<p>An email sent from the SendGrid event Target with the <code>Message</code> parameter omitted will look as follows:</p> <pre><code>from: richard &lt;richard@triggermesh.com&gt;\nto: bob &lt;bob@gmail.com&gt;\ndate:   Sep 12, 2020, 12:41 AM\nsubject: Hello World\n\nValidation: valid Context Attributes, specversion: 1.0 type: dev.knative.samples.helloworld source: dev.knative.samples/helloworldsource id: 536808d3-88be-4077-9d7a-a3f162705f79 time: 2020-09-12T04:41:00.000610299Z datacontenttype: application/json Extensions, knativearrivaltime: 2020-09-12T04:41:00.006331845Z knativehistory: default-kne-trigger-kn-channel.midimansland.svc.cluster.local Data, { \"event\":\"data\"} \n</code></pre>","location":"cloud/targets/sendgrid/#example"},{"title":"Event Target for Slack","text":"<p>This event Target receives CloudEvents over HTTP and sends them to Slack using the Slack Web API.</p>","location":"cloud/targets/slack/"},{"title":"Prerequisite(s)","text":"<ul> <li>Slack user that can manage applications</li> <li>Pre-existing Slack App</li> <li>Slack API token</li> </ul> <p>Consult the Secrets guide for more information about how to add a Slack API token as a secret.</p>","location":"cloud/targets/slack/#prerequisites"},{"title":"Configuring Your Slack App","text":"<ol> <li>Create a new Slack App.</li> <li>Go to Basic Information &gt; Add features and functionality and select the <code>Permissions</code> pane.</li> <li>Under Bot Token Scopes add <code>chat:write</code>.</li> <li>From the Install App menu follow steps to deploy to your workspace.</li> <li>Copy the Bot OAuth Access token, it should begin with <code>xoxb-...</code></li> </ol>","location":"cloud/targets/slack/#configuring-your-slack-app"},{"title":"Deploying an Instance of the Target","text":"<p>From TriggerMesh, open the Bridge creation screen and add a Target of type <code>Slack</code>.</p> <p></p> <p>In the Target creation form, provide a name for the event Target, and add the following information:</p> <ul> <li>Slack Secret: Reference a TriggerMesh secret containing a Slack API token.</li> </ul> <p></p> <p>After clicking the <code>Save</code> button, the console will self-navigate to the Bridge editor. Proceed by adding the remaining components to the Bridge.</p> <p></p> <p>After submitting the Bridge, and allowing for some configuration time, a green check mark on the main Bridges page indicates that the Bridge with the Slack Target was successfully created.</p> <p></p> <p>For more information about using the Slack API, please refer to the Slack API documentation.</p>","location":"cloud/targets/slack/#deploying-an-instance-of-the-target"},{"title":"Event Types","text":"<p>CloudEvents consumed by this Target must be of one of these types:</p> <ul> <li><code>com.slack.webapi.chat.postMessage</code></li> <li><code>com.slack.webapi.chat.scheduleMessage</code></li> <li><code>com.slack.webapi.chat.update</code></li> </ul> <p>These types expect a [JSON][ce-jsonformat] payload with the following properties:</p> <ul> <li>chat.postMessage</li> <li>chat.scheduleMessage</li> <li>chat.update</li> </ul>","location":"cloud/targets/slack/#event-types"},{"title":"Example","text":"<p>Post message:</p> <pre><code>curl -v http://slack-target:8080 \\\n -X POST \\\n -H \"Content-Type: application/json\" \\\n -H \"Ce-Specversion: 1.0\" \\\n -H \"Ce-Type: com.slack.webapi.chat.postMessage\" \\\n -H \"Ce-Source: awesome/instance\" \\\n -H \"Ce-Id: aabbccdd11223344\" \\\n -d '{\"channel\":\"C01112A09FT\", \"text\": \"Hello from TriggerMesh!\"}'\n</code></pre> <p>Schedule message:</p> <pre><code>curl -v http://slack-target:8080 \\\n -X POST \\\n -H \"Content-Type: application/json\" \\\n -H \"Ce-Specversion: 1.0\" \\\n -H \"Ce-Type: com.slack.webapi.chat.scheduleMessage\" \\\n -H \"Ce-Source: awesome/instance\" \\\n -H \"Ce-Id: aabbccdd11223344\" \\\n -d '{\"channel\":\"C01112A09FT\", \"text\": \"Hello from scheduled TriggerMesh!\", \"post_at\": 1593430770}'\n</code></pre>","location":"cloud/targets/slack/#example"},{"title":"Event Target for Splunk","text":"<p>This event target receives arbitrary CloudEvents over HTTP and sends them to a Splunk HTTP Event Collector in a JSON format.</p>","location":"cloud/targets/splunk/"},{"title":"Prerequisite(s)","text":"<ul> <li>Enable HTTP Event Collector Input</li> <li>HEC token</li> </ul> <p>Consult the Secrets guide for more information about how to add the HEC token as a secret.</p>","location":"cloud/targets/splunk/#prerequisites"},{"title":"HTTP Event Collector Input","text":"<p>In order to be able to use the TriggerMesh event Target for Splunk, an administrator must:</p> <ol> <li>Enable the HTTP Event Collector data input in the Splunk installation.</li> <li>Create a token for receiving data over HTTP.</li> </ol> <p>To do so, open the Splunk web console, then navigate to Settings &gt; Data &gt; Data inputs.</p> <p></p> <p>In the list of local inputs, click HTTP Event Collector.</p> <p></p> <p>Click New token in order to generate a new token with custom settings, then take note of the value of that token. The default HEC token (<code>splunk_hec_token</code>) is also suitable for use with the TriggerMesh event Target for Splunk.</p> <p></p> <p>This procedure is described in more detail in the Splunk documentation: Set up and use HTTP Event Collector in Splunk Web.</p>","location":"cloud/targets/splunk/#http-event-collector-input"},{"title":"Deploying an Instance of the Target","text":"<p>Open the Bridge creation screen and add a Target of type <code>Splunk</code>.</p> <p></p> <p>In the Target creation form, give a name to the event Target and add the following information:</p> <ul> <li>HEC Endpoint: URL of the HTTP Event Collector (HEC). This URL varies depending on the type of Splunk installation   (Enterprise, self-service Cloud, managed Cloud). Only the scheme, hostname, and port (optionally) are evaluated, the   URL path is trimmed if present.</li> <li>HEC Token: Reference to a TriggerMesh secret containing a token for authenticating requests against   the HEC, as discussed in the prerequisites.</li> <li>Index: Name of the index to send events to. When undefined, events are sent to the default index defined   in the HEC token's configuration.</li> </ul> <p></p> <p>After clicking the <code>Save</code> button, you will be taken back to the Bridge editor. Proceed to adding the remaining components to the Bridge, then submit it.</p> <p></p> <p>After submitting the Bridge, and allowing for some configuration time, a green check mark on the main Bridges page indicates that the Bridge with the Splunk Target was successfully created.</p> <p></p> <p>New events should now be visible in the Search &amp; Reporting app inside Splunk.</p> <p> </p> <p>For more information about using Splunk, please refer to the Splunk documentation.</p>","location":"cloud/targets/splunk/#deploying-an-instance-of-the-target"},{"title":"Event Types","text":"<p>The Splunk event Target can consume events of any type.</p>","location":"cloud/targets/splunk/#event-types"},{"title":"Event Targets","text":"<p>The following is a list of TriggerMesh event destinations known as <code>Targets</code>. Some are available as open source projects, some as hosted solutions on our Cloud.</p>","location":"cloud/targets/targets/"},{"title":"Current TriggerMesh Targets","text":"<ul> <li>Alibaba<ul> <li>Alibaba OSS: Forward arbitrary events to an Alibaba Cloud OSS bucket.</li> </ul> </li> <li>AWS<ul> <li>Amazon Comprehend: Perform sentiment analysis on cloudevents.</li> <li>AWS Lambda: Forward event payload to AWS Lambda.</li> <li>Amazon S3: Forward event payload to Amazon S3 bucket.</li> <li>Amazon SNS: Forward event payload to AWS Simple Notification Service (SNS).</li> <li>Amazon SQS: Forward event payload to AWS Simple Queueing Service (SQS).</li> <li>Amazon Kinesis: Forward event payload to Amazon Kinesis.</li> <li>Amazon EventBridge: Forward arbitrary events to Amazon EventBridge.</li> </ul> </li> <li>Confluent: Forward events to Confluent Kafka.</li> <li>Datadog: Forward event payload to Datadog.</li> <li>Elasticsearch: Send events to Elasticsearch to be indexed.</li> <li>Google Cloud Workflows: Execute Google Cloud Workflows with Cloudevents. </li> <li>Google Firestore: Send events to Google Firestore</li> <li>Google Sheets: Append events to a GoogleSheets Sheet row.</li> <li>Hasura: Send GraphQL queries to Hasura.</li> <li>HTTP: Send HTTP queries to external services.</li> <li>InfraJS: Advanced manipulation of CloudEvents.</li> <li>Jira: Send requests to Jira API.</li> <li>Logz.io: Forward events to Logz.io</li> <li>Oracle: Forward events to the Oracle Cloud.</li> <li>Salesforce: Forward arbitrary events to Salesforce.</li> <li>SendGrid: Forward arbitrary events to SendGrid.</li> <li>Slack: Forward events to Slack as messages to deliver immediately, scheduled, or as an update to a pre-existing message.</li> <li>Splunk: Forward arbitrary events to Splunk.</li> <li>Tekton: Use event to submit a Tekton build.</li> <li>Twilio: Send an SMS via Twilio in response to events.</li> <li>Zendesk: Perform actions in Zendesk upon reception of certain events.</li> </ul>","location":"cloud/targets/targets/#current-triggermesh-targets"},{"title":"Event Target for Tekton Pipeline","text":"<p>This event Target receives CloudEvents over HTTP and will use it to create a Tekton <code>TaskRun</code> or <code>PipelineRun</code> object.</p>","location":"cloud/targets/tekton/"},{"title":"Prerequisite(s)","text":"<ul> <li>Tekton Task</li> </ul>","location":"cloud/targets/tekton/#prerequisites"},{"title":"Creating a Tekton Task","text":"<p>Refer to the Tekton documentation for information about how to create tasks and pipelines.</p>","location":"cloud/targets/tekton/#creating-a-tekton-task"},{"title":"Deploying an Instance of the Target","text":"<p>From TriggerMesh, open the Bridge creation screen and add a Target of type <code>Tekton</code>.</p> <p></p> <p>In the Target creation form, provide a name for the event Target, and click <code>Save</code>.</p> <p></p> <p>After clicking the <code>Save</code> button, the console will self-navigate to the Bridge editor. Proceed by adding the remaining components to the Bridge.</p> <p></p> <p>After submitting the Bridge, and allowing for some configuration time, a green check mark on the main Bridges page indicates that the Bridge with the Tekton Target was successfully created.</p> <p></p>","location":"cloud/targets/tekton/#deploying-an-instance-of-the-target"},{"title":"Event Types","text":"","location":"cloud/targets/tekton/#event-types"},{"title":"io.triggermesh.targets.tekton","text":"<p>Events of this type intend to create a new Tekton <code>PipelineRun</code> or <code>TaskRun</code> object.</p> <p>This type expects a JSON payload with the following properties:</p>    Name Type Comment     buildType string The run object type consisting of <code>task</code> or <code>pipeline</code>   name string The Tekton <code>task</code> or <code>pipeline</code> object to invoke   params map[string]string Dictionary mapping of parameters to pass to the Tekton task or pipeline    <p>No response events are created with this Target type.</p>  <p>NOTE: <code>TaskRun</code> and <code>PipelineRun</code> objects nor their associated pods are deleted after execution. It is up to the user to perform the clean-up.</p>","location":"cloud/targets/tekton/#iotriggermeshtargetstekton"},{"title":"Event Target for Twilio","text":"<p>This event Target receives CloudEvents and utilizes Twilio to enable the creation and delivery of SMS messages via event data and event occurrence, respectively.</p>","location":"cloud/targets/twilio/"},{"title":"Prerequisite(s)","text":"<ul> <li>Twilio account with access to the Account SID &amp; API Access Token</li> <li>Phone number</li> </ul> <p>Consult the Secrets guide for more information about how to add the Twilio Account SID and API Access Token as secrets.</p>","location":"cloud/targets/twilio/#prerequisites"},{"title":"Deploying an Instance of the Target","text":"<p>Open the Bridge creation screen and add a Target of type <code>Twilio</code>.</p> <p></p> <p>In the Target creation form, give a name to the event Target and add the following information:</p> <ul> <li>Default source phone number (Optional): Sender's phone number, usually configured to the phone number purchased at   Twilio.</li> <li>Default destination (Optional): Phone number to send messages to by default.</li> <li>SID Secret: Reference to a TriggerMesh secret containing the SID of the Twilio account.</li> <li>Token Secret: Reference to a TriggerMesh secret containing an API Access token for   authenticating requests against the Twilio API.</li> </ul> <p>Both the Default source phone number and Default destination configurations may be overridden by any CloudEvent message received by the Target.</p> <p>For more information about using Twilio, please refer to the Twilio documentation.</p> <p></p> <p>After submitting the Bridge, and allowing for some configuration time, a green check mark on the main Bridges page indicates that the Bridge was successfully created.</p> <p></p>","location":"cloud/targets/twilio/#deploying-an-instance-of-the-target"},{"title":"Event Types","text":"<p>A Twilio event Target accepts the following CloudEvent types:</p>","location":"cloud/targets/twilio/#event-types"},{"title":"io.triggermesh.twilio.sms.send","text":"<p>Events of this type intend to send a SMS message via Twilio.</p> <p>This type expects a JSON payload with the following properties:</p>    Name Type Description     message string Text to be sent in the body of the SMS message.   media_urls string Array of URLs pointing to JPEG, GIF or PNG resources.   from string Phone number sourcing the communication. Takes precedence over the value from the Twilio Target spec.   to string Phone number of the destination. Takes precedence over the value from the Twilio Target spec.","location":"cloud/targets/twilio/#iotriggermeshtwiliosmssend"},{"title":"Event Target for Zendesk","text":"<p>This event Target receives CloudEvents and uses the Zendesk API to either create a new ticket or tag an existing one.</p>","location":"cloud/targets/zendesk/"},{"title":"Prerequisite(s)","text":"<ul> <li>Zendesk API token</li> </ul>","location":"cloud/targets/zendesk/#prerequisites"},{"title":"Zendesk API Token","text":"<p>You can find the steps to obtain an API token in the Zendesk API Docs.</p> <p>Consult the Secrets guide for more information about how to add the Zendesk API token as a secret.</p>","location":"cloud/targets/zendesk/#zendesk-api-token"},{"title":"Deploying an Instance of the Target","text":"<p>Open the Bridge creation screen and add a Target of type <code>Zendesk</code>.</p> <p></p> <p>In the Target creation form, provide a name to the event Target, and add the following information:</p> <ul> <li>Default Ticket Subject: An optional ticket subject fallback if one is not provided in an incoming event.</li> <li>Zendesk Subdomain: Name of the Zendesk Subdomain, without the <code>zendesk.com</code> domain or <code>https://</code> scheme.</li> <li>Zendesk Email: Email address associated with the Zendesk account.</li> <li>Zendesk API Token: Reference to a TriggerMesh secret containing a token to communicate with the Zendesk API, as discussed in the prerequisites.</li> </ul> <p></p> <p>After clicking the <code>Save</code> button, the console will self-navigate to the Bridge editor. Proceed by adding the remaining components to the Bridge.</p> <p></p> <p>After submitting the Bridge, and allowing for some configuration time, a green check mark on the main Bridges page indicates that the Bridge with a Zendesk event Target was successfully created.</p> <p></p> <p>For more information about using Zendesk, please refer to the Zendesk documentation.</p>","location":"cloud/targets/zendesk/#deploying-an-instance-of-the-target"},{"title":"Event Types","text":"<p>A Zendesk event Target accepts the following CloudEvent types:</p>","location":"cloud/targets/zendesk/#event-types"},{"title":"com.zendesk.ticket.create","text":"<p>Events of this type intend to create a new Zendesk ticket.</p> <p>This type expects a JSON payload with the following properties:</p>    Name Type Comment     subject string The value of the subject field for this ticket   body string The value of the body field for this ticket    <p>An example response from the Zendesk Target after consuming an event of this type:</p> <pre><code>{\n \"id\":165,\n \"url\":\"https://triggermesh.zendesk.com/api/v2/tickets/165.json\",\n \"subject\":\"Hello\",\n \"raw_subject\":\"Hello\",\n \"description\":\"World\",\n \"status\":\"open\",\n \"requester_id\":412584624334,\n \"submitter_id\":412584624334,\n \"assignee_id\":412584624334,\n \"group_id\":360010761434,\n \"due_at\":\"0001-01-01T00:00:00Z\",\n \"via\":\n   {\n     \"channel\":\"api\",\n     \"source\":{\"from\":{},\"to\":{},\"rel\":\"\"},\n     \"satisfaction_rating\":{\"id\":0,\"score\":\"\",\"comment\":\"\"},\n     \"brand_id\":360004879834,\n     \"allow_attachments\":true,\n     \"is_public\":true,\n     \"created_at\":\"2020-08-05T20:00:11Z\",\n     \"updated_at\":\"2020-08-05T20:00:11Z\",\n     \"collaborators\":{},\n     \"comment\":{\"created_at\":\"0001-01-01T00:00:00Z\"}\n   }\n}\n</code></pre>","location":"cloud/targets/zendesk/#comzendeskticketcreate"},{"title":"com.zendesk.ticket.tag.add","text":"<p>Events of this type intend to assign a tag to a pre-existing Zendesk ticket.</p> <p>This type expects a JSON payload with the following properties:</p>    Name Type Comment     id int64 The value of the id field for the ticket to be updated   tag string The value of the tag to assign to this ticket","location":"cloud/targets/zendesk/#comzendesktickettagadd"},{"title":"Functions","text":"<p>Functions may be used to implement custom event flow logic and may act as a source, transformation, or target. Python, NodeJS, and Ruby are the currently supported Function types.</p>","location":"concepts/functions/"},{"title":"Examples","text":"<ul> <li>NodeJS empty field transformation</li> <li>Python random even/odd events</li> <li>Ruby date and time event</li> </ul> <p>There is another example of Writing a Function in the Guides.</p>","location":"concepts/functions/#examples"},{"title":"API Reference","text":"<p>Function is documented in the API Reference</p>","location":"concepts/functions/#api-reference"},{"title":"Specifications","text":"<p>The specification of each target is available through <code>kubectl explain</code>. For example:</p> <pre><code>kubectl explain function.spec\nKIND:     Function\nVERSION:  extensions.triggermesh.io/v1alpha1\n\nRESOURCE: spec &lt;Object&gt;\n\nDESCRIPTION:\n     Desired state of the function.\n\nFIELDS:\n   ceOverrides  &lt;Object&gt;\n     Defines overrides to control modifications of the event attributes.\n\n   code &lt;string&gt; -required-\n     Function code.\n\n   entrypoint   &lt;string&gt; -required-\n     Function name to use as an entrypoint.\n\n   eventStore   &lt;Object&gt;\n     EventStore service connection string.\n\n   public   &lt;boolean&gt;\n     Should the function be publicly available.\n\n   responseIsEvent  &lt;boolean&gt;\n     Whether function responds with CE payload only or with full event.\n\n   runtime  &lt;string&gt; -required-\n     Function runtime name. Python, Ruby or Node runtimes are currently\n     supported.\n\n   sink &lt;Object&gt;\n     Sink is a reference to an object that will resolve to a uri to use as the\n     sink.\n</code></pre>","location":"concepts/functions/#specifications"},{"title":"Routing: Filters and Splitters","text":"<p>TriggerMesh provides routing by event content (Filter) or dividing incoming events into multiple distinct events as necessary (Splitter).</p>","location":"concepts/routing/"},{"title":"Filter","text":"<p>The Filter determines which events to process based on their content. Content-based event filtering is expressed in Google's Common Expression Language. Multiple filters may be used as necessary. Filters do not modify the content of the processed events.</p>","location":"concepts/routing/#filter"},{"title":"Filter Examples","text":"<p>Examples include dropping log messages outside of a time window or only processing events containing a particular substring.</p> <p>There is an example of Writing a Filter available under Guides.</p>","location":"concepts/routing/#filter-examples"},{"title":"Filter Specification","text":"<p>The Filter specification is available through <code>kubectl explain</code>.</p> <pre><code>kubectl explain filter.spec\nKIND:     Filter\nVERSION:  routing.triggermesh.io/v1alpha1\n\nRESOURCE: spec &lt;Object&gt;\n\nDESCRIPTION:\n     Desired state of the filter.\n\nFIELDS:\n   expression   &lt;string&gt; -required-\n     Google CEL-like expression string.\n\n   sink &lt;Object&gt; -required-\n     Sink is a reference to an object that will resolve to a uri to use as the\n     sink.\n</code></pre>","location":"concepts/routing/#filter-specification"},{"title":"Splitter","text":"<p>The Splitter separates events into multiple events which may then be processed individually.</p>","location":"concepts/routing/#splitter"},{"title":"Splitter Examples","text":"<p>JSON events frequently have arrays of events that need to be split.</p> <p>There is an example of Creating a Splitter available under Guides.</p>","location":"concepts/routing/#splitter-examples"},{"title":"Splitter Specification","text":"<p>The Splitter specification is available through <code>kubectl explain</code>.</p> <pre><code>kubectl explain splitter.spec\nKIND:     Splitter\nVERSION:  routing.triggermesh.io/v1alpha1\n\nRESOURCE: spec &lt;Object&gt;\n\nDESCRIPTION:\n     Desired state of the splitter.\n\nFIELDS:\n   ceContext    &lt;Object&gt; -required-\n     Context attributes to set on produced CloudEvents.\n\n   path &lt;string&gt;\n     JSONPath expression representing the key containing the data array to\n     split. Defaults to the root.\n\n   sink &lt;Object&gt; -required-\n     Sink is a reference to an object that will resolve to a uri to use as the\n     sink.\n</code></pre>","location":"concepts/routing/#splitter-specification"},{"title":"API Reference","text":"<p>Filters and Splitters are listed and documented in the Routing API reference.</p>","location":"concepts/routing/#api-reference"},{"title":"Component Scaling","text":"<p>TriggerMesh Components that are able to spin up replicas without leading to missing or duplicated events will scale under heavy load.</p> <p>In contrast those components whose external system imposes a model where multiple instances of a client are not allowed or require distributed coordination won't scale.</p> <p>As a general rule scaling per component type defaults to:</p>    Type Scalable Exceptions     Source No SlackSource, TwilioSource, WebhookSource and ZendeskSource   Target Yes    Transformation Yes    Routing Yes      <p>Tip</p> <p>When a component that does not support scaling reaches its maximum capacity it is usually a good practice to partition the external service/data and configure multiple components.</p>","location":"concepts/scaling/"},{"title":"Scaling behavior","text":"<p>Scaling components are configured with the following parameters:</p> <ul> <li>Scaler metrics: requests per second (RPS).</li> <li>Minimum scale: 0, allows scale to zero.</li> <li>Maximum scale: 30 instances.</li> <li>Scale down delay: 5m, an scaled up instance will wait for 5m before being considered for retiring.</li> <li>Requests per second: 300.</li> <li>Time window: 1m, the window to aggregate metrics and take actions.</li> </ul> <p>As an example a load test for a single TriggerMesh component looks like this:</p>  <p>Scale to 0</p> <p>Components that are able to scale are also able to scale to zero, saving resources when there is no load. A scaled to zero component can still receive data, that will be buffered by an activator agent while the backend is created (which usually takes ~ 1 second).</p> <p>A component that has received no data for the last minute is a candidate for downscaling.</p>   <p>Example</p> <p></p> <ul> <li>Ramp up: the load for the first half of the test, the autoscaler creates replicas of the component based on demand.</li> <li>Stabilizing requests: there are some adjustments but the number of replicas is kept around 16 in the example.</li> <li>Ramp down: replicas start to be removed as long as they are not needed.</li> <li>Zero load: replicas are kept for 5 minutes receiving no requests, then they are removed.</li> </ul>","location":"concepts/scaling/#scaling-behavior"},{"title":"Sources","text":"<p>Sources are the origin of data and events for ingestion into TriggerMesh. An event source often acts as a gateway between an external service and the Bridge. Sources may be irregular events, periodic data updates, batch processes, or even continuous event streams.</p>","location":"concepts/sources/"},{"title":"Examples","text":"<p>Examples of Sources include GitHub, IBM DB2 and Oracle databases, Salesforce, ZenDesk, or any number of cloud-based events such as Amazon S3, Azure Activity Log, or Google Cloud Audit Logs.</p> <p>All sources available can be found by listing the CRDs like so:</p> <pre><code>$ kubectl get crd -o jsonpath='{.items[?(@.spec.group==\"sources.triggermesh.io\")].spec.names.kind}'\nAWSCloudWatchLogsSource AWSCloudWatchSource AWSCodeCommitSource AWSCognitoIdentitySource AWSCognitoUserPoolSource AWSDynamoDBSource AWSKinesisSource AWSPerformanceInsightsSource AWSS3Source AWSSNSSource AWSSQSSource AzureActivityLogsSource AzureBlobStorageSource AzureEventGridSource AzureEventHubSource AzureIOTHubSource AzureQueueStorageSource AzureServiceBusQueueSource GoogleCloudAuditLogsSource GoogleCloudBillingSource GoogleCloudPubSubSource GoogleCloudRepositoriesSource GoogleCloudStorageSource HTTPPollerSource OCIMetricsSource SalesforceSource SlackSource TwilioSource WebhookSource ZendeskSource\n</code></pre> <p>There is an example of Creating a Source available under Guides.</p>","location":"concepts/sources/#examples"},{"title":"API Reference","text":"<p>All TriggerMesh-provided sources are listed and documented in the API Reference.</p>","location":"concepts/sources/#api-reference"},{"title":"Knative Event Sources","text":"<p>There are a number of additional event sources provided by Knative.</p>","location":"concepts/sources/#knative-event-sources"},{"title":"Specifications","text":"<p>The specification of each source is available through <code>kubectl explain</code>. For example:</p> <pre><code>kubectl explain googlecloudstoragesource.spec\nKIND:     GoogleCloudStorageSource\nVERSION:  sources.triggermesh.io/v1alpha1\n\nRESOURCE: spec &lt;Object&gt;\n\nDESCRIPTION:\n     Desired state of the event source.\n\nFIELDS:\n   bucket   &lt;string&gt; -required-\n     Name of the Cloud Storage bucket to receive change notifications from. Must\n     meet the naming requirements described at\n     https://cloud.google.com/storage/docs/naming-buckets\n\n   eventTypes   &lt;[]string&gt;\n     Types of events to receive change notifications for. Accepted values are\n     listed at\n     https://cloud.google.com/storage/docs/pubsub-notifications#events. All\n     types are selected when this attribute is not set.\n\n   pubsub   &lt;Object&gt; -required-\n     Attributes related to the configuration of Pub/Sub resources associated\n     with the Cloud Storage bucket.\n\n   serviceAccountKey    &lt;Object&gt; -required-\n     Service account key used to authenticate the event source and allow it to\n     interact with Google Cloud APIs. Only the JSON format is supported.\n\n   sink &lt;Object&gt; -required-\n     The destination of events received via change notifications.\n</code></pre>","location":"concepts/sources/#specifications"},{"title":"Targets","text":"<p>A target is an event receiver which performs some processing on the received data. An event target may act as a gateway between the Bridge and an external service.</p> <p>Although a target may be considered the destination for an event, it may in turn reply with another event (acknowledgment, error, ...) generating further events. These additional events may need to be managed with separate Bridges.</p>","location":"concepts/targets/"},{"title":"Examples","text":"<p>Examples of Targets include Datadog, Elasticsearch, Salesforce, Twilio, Zendesk, or any number of cloud-based destinations such as Amazon SQS or Google Cloud Firestore.</p> <p>All targets available can be found by listing the CRDs like so</p> <pre><code>$ kubectl get crd -o jsonpath='{.items[?(@.spec.group==\"targets.triggermesh.io\")].spec.names.kind}'\nAlibabaOSSTarget AWSComprehendTarget AWSDynamoDBTarget AWSEventBridgeTarget AWSKinesisTarget AWSLambdaTarget AWSS3Target AWSSNSTarget AWSSQSTarget ConfluentTarget DatadogTarget ElasticsearchTarget GoogleCloudFirestoreTarget GoogleCloudStorageTarget GoogleCloudWorkflowsTarget GoogleSheetTarget HasuraTarget HTTPTarget InfraTarget JiraTarget LogzTarget OracleTarget SalesforceTarget SendGridTarget SlackTarget SplunkTarget TektonTarget TwilioTarget UiPathTarget ZendeskTarget\n</code></pre> <p>There is an example of Creating a Target available under Guides.</p>","location":"concepts/targets/#examples"},{"title":"API Reference","text":"<p>All TriggerMesh-provided targets are listed and documented in the API Reference</p>","location":"concepts/targets/#api-reference"},{"title":"Specifications","text":"<p>The specification of each target is available through <code>kubectl explain</code>. For example:</p> <pre><code>kubectl explain awslambdatarget.spec\nKIND:     AWSLambdaTarget\nVERSION:  targets.triggermesh.io/v1alpha1\n\nRESOURCE: spec &lt;Object&gt;\n\nDESCRIPTION:\n     Desired state of event target.\n\nFIELDS:\n   arn  &lt;string&gt;\n     ARN of the Lambda function that will receive events. The expected format is\n     documented at\n     https://docs.aws.amazon.com/service-authorization/latest/reference/list_awslambda.html\n\n   awsApiKey    &lt;Object&gt;\n     API Key to interact with the Amazon Lambda API. For more information about\n     AWS security credentials, please refer to the AWS General Reference at\n     https://docs.aws.amazon.com/general/latest/gr/aws-security-credentials.html\n\n   awsApiSecret &lt;Object&gt;\n     API Secret to interact with the Amazon Lambda API. For more information\n     about AWS security credentials, please refer to the AWS General Reference\n     at\n     https://docs.aws.amazon.com/general/latest/gr/aws-security-credentials.html\n\n   discardCloudEventContext &lt;boolean&gt;\n     Produce a new cloud event based on the response from the lambda function.\n</code></pre>","location":"concepts/targets/#specifications"},{"title":"Transformation","text":"<p>A Transformation translates the message contained in incoming events and publishes them into a different format.</p>","location":"concepts/transformation/"},{"title":"Examples","text":"<p>Transformation examples include annotating incoming events with timestamps, dropping fields, or rearranging data to fit an expected format.</p> <p>There is an example of Doing a Transformation available under Guides.</p> <p>Transformations may be done declaratively or through a function.</p>","location":"concepts/transformation/#examples"},{"title":"API Reference","text":"<p>Transformation is documented in the API Reference</p>","location":"concepts/transformation/#api-reference"},{"title":"Specifications","text":"<p>The specification of each target is available through <code>kubectl explain</code>. For example:</p> <pre><code>kubectl explain transformation.spec\nKIND:     Transformation\nVERSION:  flow.triggermesh.io/v1alpha1\n\nRESOURCE: spec &lt;Object&gt;\n\nDESCRIPTION:\n     Desired state of the transformation object.\n\nFIELDS:\n   context  &lt;[]Object&gt;\n     CloudEvents Context attributes transformation spec.\n\n   data &lt;[]Object&gt;\n     CloudEvents Data transformation spec.\n\n   sink &lt;Object&gt;\n     The destination of events sourced from the transformation object.\n</code></pre>","location":"concepts/transformation/#specifications"},{"title":"Actions","text":"","location":"guides/actions/"},{"title":"Actions","text":"<p>TriggerMesh Actions are based on Tekton Pipeline. Tekton builds the container images used to run application pipelines expressed as GitHub Actions.</p>","location":"guides/actions/#actions"},{"title":"Create a Task","text":"<p>You can express a Task in a manifest. For example, the following manifest represents a Task that will echo Hello World:</p> <pre><code>apiVersion: tekton.dev/v1alpha1\nkind: Task\nmetadata:\n  name: echo-hello-world\nspec:\n  steps:\n    - name: echo\n      image: ubuntu\n      command:\n        - echo\n      args:\n        - \"hello world\"\n</code></pre> <p>The TM console provides an easy to use YAML window for deploying Tasks from the browser. This is accessed by selecting Tasks from the Navigation menu.</p> <p></p> <p>Click on the Create Task button and select from YAML, to create a new task.</p> <p></p> <p>You will be presented with the following view in which you can paste your Task manifest.</p> <p></p>","location":"guides/actions/#create-a-task"},{"title":"Execute a Task","text":"<p>Clicking on the green RUN button will launch the execution of the Task</p> <p></p> <p>Once executed, the TaskRun view will show a green TaskRun object as below:</p> <p></p> <p>Clicking on the object name will lead you to the Task Run Details here we can view our YAML as well as the Logs. Navigate to the logs to find the a magnificent <code>hello world</code>:</p> <p></p>","location":"guides/actions/#execute-a-task"},{"title":"CLI lovers can use use <code>kubectl</code> and <code>tm</code> to create Tasks from the CLI.","text":"","location":"guides/actions/#cli-lovers-can-use-use-kubectl-and-tm-to-create-tasks-from-the-cli"},{"title":"Continuous Deployment of Your Functions","text":"<p>The TriggerMesh console provides an interface called Repositories. Here the user is able to select a codebase, from a linked repository provider, to be continuously deployed. This codebase must contain a deployment manifest[^1] .</p>","location":"guides/cd/"},{"title":"Register the Repository","text":"","location":"guides/cd/#register-the-repository"},{"title":"The following example uses this sample repository. To follow along begin by forking the example to your repository provider.","text":"<ol> <li>Select the Repositories section from the Navigation menu and then CREATE NEW</li> </ol> <p></p> <ol> <li>Select a source control provider. Upon submission of this form you will be asked to authenticate with the chosen provider.</li> </ol> <p></p> <ol> <li>Select the  sample repository from the drop down list.</li> </ol> <p></p> <ol> <li>Here you can specify the location of the <code>serverless.yaml</code> manifest as well as select specific Branch and Tag name's from the repository.</li> </ol> <p></p> <ol> <li>Once registration is complete the Repositories view will contain your function project. You can disable the registration at any time by clicking on the Trash Can icon located on the right hand side of the item you would like to disable. </li> </ol> <p></p>","location":"guides/cd/#the-following-example-uses-this-sample-repository-to-follow-along-begin-by-forking-the-example-to-your-repository-provider"},{"title":"Viewing the Deployment","text":"<p>After every successful registration of a new repository a Task will be created for it.</p> <ul> <li>Navigate to the Tasks view in the Actions section and click on the Task name.</li> </ul> <p></p> <ul> <li>This will display the manifest of the Task.</li> </ul> <p></p>","location":"guides/cd/#viewing-the-deployment"},{"title":"Deploying on Push Events","text":"<ul> <li>A Task will execute on each push event to its respective repository. You can view the details of the Task in the Task Runs section</li> </ul> <p></p> <ul> <li>Any push event on the registered repository will trigger a new build described in your <code>serverless.yaml</code> manifest.</li> </ul> <p></p>","location":"guides/cd/#deploying-on-push-events"},{"title":"Service Creation","text":"<ul> <li>On successful execution of the Task the service will be available and you will be able to see and use the function by navigating to the Services tab.</li> </ul> <p></p> <p>[^1]: A sample manifest can be found here -&gt; https://github.com/sebgoa/transform/blob/master/serverless.yaml</p>","location":"guides/cd/#service-creation"},{"title":"Receiving External CloudEvents","text":"<p>The Trigermesh <code>CloudEventsSource</code> API object is used to ingest Cloudevents produced from external sources via HTTP.</p>","location":"guides/cloudeventssource/"},{"title":"Configuring a CloudEventsSource Object","text":"<p>The CloudEventsSource accepts parameters to set authentication, URL path and rate limiter. When succesfuly created it exposes an HTTP endpoint to listen for CloudEvents.</p>","location":"guides/cloudeventssource/#configuring-a-cloudeventssource-object"},{"title":"Configuring Credentials (Optional)","text":"<p>Credentials can be configured using Basic Authentication using Kubernetes secrets to manage passwords.</p> <p>Credentials are defined as arrays, allowing clients to use multiple user/password items.</p> <p>The credentials are defined under <code>spec.credentials.basicAuths</code>:</p>  <p>Credentials for 2 users</p> <pre><code>spec:\n  credentials:\n    basicAuths:\n    - username: user1\n      password:\n        valueFromSecret:\n          name: password1\n          key: password\n    - username: user2\n      password:\n        valueFromSecret:\n          name: password2\n          key: password\n</code></pre>","location":"guides/cloudeventssource/#configuring-credentials-optional"},{"title":"Configuring Path (Optional)","text":"<p>The <code>spec.path</code> parameter is used configure the URL path where CloudEvents will be accepted. When specified clients using this component must add the designated <code>path</code> to the URL, obtaining a 404 for any other requested location.</p>  <p>Rate limit at 1000 RPS</p> <pre><code>spec:\n  path: /mypath\n</code></pre>   <p>Using path</p> <p>Path is not usually needed. Configure it when an existing CloudEvents producer is already emitting events using that path and cannot be re-configured.</p>","location":"guides/cloudeventssource/#configuring-path-optional"},{"title":"Configuring Rate Limiter (Optional)","text":"<p>Rate Limiter is used to filter the quantity of requests per second that an adapter instance can receive. When the configured limit per time window is reached, HTTP code 429 is returned along information on when the client should retry.</p>  <p>Example response when rate limit reached</p> <pre><code>HTTP/1.1 429 Too Many Requests\nretry-after: 1650204469582011930\n</code></pre>  <p>To configure the Rate Limiter use the <code>spec.rateLimiter.requestsPerSecond</code> parameter:</p>  <p>Rate limit at 1000 RPS</p> <pre><code>spec:\n  rateLimiter:\n    requestsPerSecond: 1000\n</code></pre>  <p>It must be noted when configuring the Rate Limiter that:</p>  <p>Rate limiter is per instance</p> <p>The CloudEventsSource component is able to scale under load. The rate limiter value is set individualy per each scaled instance, which means that setting this value does not limit the total ammount of requests that can be received, but protects each instance from receiving more the configured value while informing the caller to re-issue the request.</p>   <p>Rate limiter and scaling</p> <p>A low value of the rate limiter might prevent the adapter from scaling if the configured value is below the scaling rate.</p>","location":"guides/cloudeventssource/#configuring-rate-limiter-optional"},{"title":"Configuring CloudEvents Sink","text":"<p>The <code>spec.sink</code> parameter is a destination that points to an object or URL that will receive the ingested CloudEvents.</p>  <p>Using a reference</p> <pre><code>spec:\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: default\n</code></pre>   <p>Using a URL</p> <pre><code>spec:\n  sink:\n    uri: https://mybroker-woodford.triggermesh.io\n</code></pre>","location":"guides/cloudeventssource/#configuring-cloudevents-sink"},{"title":"Using the CloudEventsSource","text":"<p>Given the CloudEventsSource configuration options depicted in the preceding sections we can create this example CloudEventsSource by creating this object at a TriggerMesh cluster:</p>  <p>Example CloudEventsSource</p> <pre><code>apiVersion: sources.triggermesh.io/v1alpha1\nkind: CloudEventsSource\nmetadata:\n  name: sample\nspec:\n  credentials:\n    basicAuths:\n    - username: user1\n      password:\n        valueFromSecret:\n          name: password1\n          key: password\n    - username: user2\n      password:\n        valueFromSecret:\n          name: password2\n          key: password\n  path: /mypath\n  rateLimiter:\n    requestsPerSecond: 1000\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: default\n</code></pre>  <p>A CloudEvent can be ingested in the cluster using <code>curl</code> and Basic Authentication:</p>  <p>Calling the CloudEventsSource</p> <pre><code>curl -sSL -u user2:pw2 \"http://cloudeventssource.mycluster.io/mypath\" \\\n  -H \"Ce-Specversion: 1.0\" \\\n  -H \"Ce-Type: json.document\" \\\n  -H \"Ce-Source: curl.shell\" \\\n  -H \"Ce-MyAttribute: my value\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Ce-Id: 1234-abcd-x\" \\\n  -d '{\"Hello\":\"world\"}'\n</code></pre>","location":"guides/cloudeventssource/#using-the-cloudeventssource"},{"title":"Exporting CloudEvents","text":"<p>The TriggerMesh <code>CloudEventsTarget</code> API object is used to export CloudEvents to external systems via HTTP.</p>","location":"guides/cloudeventstarget/"},{"title":"Configuring a CloudEventsTarget Object","text":"<p>The CloudEventsTarget accepts parameters to set the endpoint where CloudEvents will be sent and authentication.</p>","location":"guides/cloudeventstarget/#configuring-a-cloudeventstarget-object"},{"title":"Configuring CloudEvents Endpoint","text":"<p>The <code>spec.endpoint</code> parameter is a destination that points to an HTTP URL that will receive the ingested CloudEvents.</p>  <p>Using a reference</p> <pre><code>spec:\n  endpoint: https://external.systen/mypath\n</code></pre>","location":"guides/cloudeventstarget/#configuring-cloudevents-endpoint"},{"title":"Configuring Credentials (Optional)","text":"<p>If the external system requires Basic Authentication this component can be configured to use credentials by means of Kubernetes secrets.</p> <p>The credentials are defined under <code>spec.credentials.basicAuths</code>:</p>  <p>Credentials</p> <pre><code>spec:\n  credentials:\n    basicAuth:\n      username: user\n      password:\n        valueFromSecret:\n          name: ce-target-password\n          key: password\n</code></pre>","location":"guides/cloudeventstarget/#configuring-credentials-optional"},{"title":"Using the CloudEventsTarget","text":"<p>Lets now create a complete CloudEventsTarget Given the configuration options depicted in the preceding sections we can create this example CloudEventsTarget by creating this object at a TriggerMesh cluster:</p>  <p>Example CloudEventsTarget</p> <pre><code>apiVersion: targets.triggermesh.io/v1alpha1\nkind: CloudEventsTarget\nmetadata:\n  name: sample\nspec:\n  endpoint: https://external.systen/mypath\n  credentials:\n    basicAuth:\n      username: user\n      password:\n        # The ce-target-password secret containing a password key must exist.\n        valueFromSecret:\n          name: ce-target-password\n          key: password\n</code></pre>  <p>Write the example YAML object above to a file replacing endpoint and credentials to suit your needs, then apply it to your cluster:</p> <pre><code>kubectl apply -f my-cloudeventstarget.yaml\n</code></pre> <p>The running object might be used now as a Trigger's subscriptor to consume CloudEvents from a Broker and forward them to an external endpoint.</p>","location":"guides/cloudeventstarget/#using-the-cloudeventstarget"},{"title":"Connecting TriggerMesh Clusters","text":"<p>Installation</p> <p>Make sure you have completed the installation procedure before proceeding with any of the guides.</p>  <p>In this guide we will connect 2 TriggerMesh clusters that will be able to interchange CloudEvents flowing through them. You might want to connect multiple TriggerMesh instances to:</p> <ul> <li>Move events between environments. For example from production to staging in order to perform tests with actual events.</li> <li>Geographically distribute events among clusters.</li> <li>Perform Cluster migrations.</li> <li>Integrate heterogenous applications through real time events.</li> </ul>","location":"guides/connectingclusters/"},{"title":"Scenario","text":"<p>For this scenario we will need to setup 2 TriggerMesh clusters that we will call at this document <code>ClusterSender</code> and <code>ClusterReceiver</code>.</p> <p>ClusterSender components:</p> <ul> <li><code>Broker</code> is the temporary storage for CloudEvents.</li> <li><code>PingSource</code> is a peridic CloudEvents producer that will send them to the Broker.</li> <li><code>CloudEventsTarget</code> will listen to CloudEvents and send them to an external location.</li> <li><code>Trigger</code> will subscribe to CloudEvents at the Broker and send them to the CloudEventsTarget.</li> </ul> <p>ClusterReceiver components:</p> <ul> <li><code>Broker</code> is the temporary storage for CloudEvents.</li> <li><code>CloudEventsSource</code> will listen to CloudEvents from remote locations and send them to the Broker.</li> <li><code>event-display</code> service will listen to CloudEvents and log them at the output console.</li> <li><code>Trigger</code> will subscribe to CloudEvents at the Broker and send them to the EventDisplay.</li> </ul> <p></p> <p>Events produced at the PingSource will flow as depicted above until they reach the EventDisplay at the second cluster.</p>","location":"guides/connectingclusters/#scenario"},{"title":"Setup","text":"<p>Local setup</p> <p>You can use a local setup by creating 2 kind clusters.</p> <pre><code>$ kind create cluster --name clustersender\n...\n\n$ kind create cluster --name clusterreceiver\n...\n</code></pre> <p>Add LoadBalancer support to the receiver cluster by following kind instructions.</p> <p>You can switch to each configured cluster using <code>kubectl config use-context</code> command.</p> <pre><code>$ kubectl config use-context kind-clustersender\n\n$ kubectl config use-context kind-clusterreceiver\n</code></pre>","location":"guides/connectingclusters/#setup"},{"title":"Receiver Cluster","text":"<p>Receiver cluster</p> <p>Make sure your kubectl configuration is pointing to the receiver cluster.</p>  <p>Create the Broker as the host for this cluster's CloudEvents:</p> <pre><code>apiVersion: eventing.knative.dev/v1\nkind: Broker\nmetadata:\n  name: receiver\n</code></pre> <p>Create a Knative service that runs the <code>event_display</code> image. We will look for received events by looking at the logs of this service.</p> <pre><code>apiVersion: serving.knative.dev/v1\nkind: Service\nmetadata:\n  name: event-display\nspec:\n  template:\n    metadata:\n      annotations:\n        autoscaling.knative.dev/min-scale: \"1\"\n    spec:\n      containers:\n      - image: gcr.io/knative-releases/knative.dev/eventing/cmd/event_display\n</code></pre> <p>Using a Trigger we can link the <code>event-display</code> service with the broker to subscribe to all events flowing through it.</p> <pre><code>kind: Trigger\napiVersion: eventing.knative.dev/v1\nmetadata:\n  name: all-events-to-event-display\nspec:\n  broker: receiver\n  subscriber:\n    ref:\n      apiVersion: serving.knative.dev/v1\n      kind: Service\n      name: event-display\n</code></pre> <p>The <code>CloudEventsSource</code> component will expose an HTTP endpoint that ingest CloudEvents from external systems. We will configure this component to send ingested CloudEvents to the broker.</p> <pre><code>apiVersion: sources.triggermesh.io/v1alpha1\nkind: CloudEventsSource\nmetadata:\n  name: gateway-in\nspec:\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: receiver\n</code></pre> <p>After completing the setup for all the receiver cluster components, any CloudEvent sent to the <code>CloudEventsSource</code> public endpoint will flow throw the broker and be delivered to the <code>event-display</code> service.</p> <p>We will retrieve and take note of the exposed URL at the <code>CloudEventsSource</code>, it will be used later at the the sender cluster.</p> <pre><code>kubectl get cloudeventssources.sources.triggermesh.io gateway-in -ojsonpath='{.status.address.url}'\n</code></pre>","location":"guides/connectingclusters/#receiver-cluster"},{"title":"Sender Cluster","text":"<p>Sender cluster</p> <p>Make sure your kubectl configuration is pointing to the sender cluster.</p>  <p>Create the Broker that as the host for this cluster's CloudEvents:</p> <pre><code>apiVersion: eventing.knative.dev/v1\nkind: Broker\nmetadata:\n  name: sender\n</code></pre> <p>A <code>PingSource</code> produces periodic events based on a cron expression. We will send the produced events to the broker object.</p> <pre><code>apiVersion: sources.knative.dev/v1\nkind: PingSource\nmetadata:\n  name: periodic-event-producer\nspec:\n  schedule: \"*/1 * * * *\"\n  contentType: \"application/json\"\n  data: '{\"message\": \"greetings from sender cluster\"}'\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: sender\n</code></pre> <p>The <code>CloudEventsTarget</code> component is able to subscribe to a broker (using a trigger), and forward events to a remote destination. We will configure this component using the endpoint exposed by the <code>CloudEventsSource</code> at the destination cluster, make sure you replace the placeholder text at the following command.</p> <pre><code>apiVersion: targets.triggermesh.io/v1alpha1\nkind: CloudEventsTarget\nmetadata:\n  name: gateway-out\nspec:\n  endpoint: &lt;REPLACE-WITH-CLOUDEVENTSSOURCE-HTTP-ENDPOINT&gt;\n</code></pre> <p>Subscribing the <code>CloudEventsTarget</code> to CloudEvents flowing through a broker is done via a trigger.</p> <pre><code>kind: Trigger\napiVersion: eventing.knative.dev/v1\nmetadata:\n  name: all-events-to-cloudeventstarget\nspec:\n  broker: sender\n  subscriber:\n    ref:\n      apiVersion: targets.triggermesh.io/v1alpha1\n      kind: CloudEventsTarget\n      name: gateway-out\n</code></pre>","location":"guides/connectingclusters/#sender-cluster"},{"title":"Receiving Events","text":"<p>With all components being setup CloudEvents should be flowing from <code>PingSource</code> at the sender cluster to the <code>event-display</code> service at the receiver cluster. We can make sure by looking at the receiving service logs.</p> <pre><code>$ kubectl logs -l serving.knative.dev/service=event-display -c user-container -f\n...\nContext Attributes,\n  specversion: 1.0\n  type: dev.knative.sources.ping\n  source: /apis/v1/namespaces/default/pingsources/periodic-event-producer\n  id: eddd0d10-64ef-4c82-bfc0-c0caea63a510\n  time: 2022-05-26T12:44:00.265933805Z\n  datacontenttype: application/json\nExtensions,\n  knativearrivaltime: 2022-05-26T12:44:00.272805675Z\nData,\n  {\n    \"message\": \"greetings from sender cluster\"\n  }\n...\n</code></pre>","location":"guides/connectingclusters/#receiving-events"},{"title":"Further improvements","text":"<p>Triggers can be configured with filters to make sure only allowed CloudEvents travels between clusters. Refer to trigger's documentation for configuration options.</p> <p>CloudEventsSource and CloudEventsTarget can be configured with HTTP Basic Authentication.</p>  <p>HTTP Basic Authentication</p> <p>HTTP Basic Authentication is not enctrypted. When used it is thoroughly recommended that Knative Serving is configured with TLS capabilities.</p>","location":"guides/connectingclusters/#further-improvements"},{"title":"Creating a Wiretap","text":"<p>In this guide we will create a Wiretap to monitor the Cloudevent traffic happening within our bridge.</p>","location":"guides/createawiretap/"},{"title":"What is a Wiretap?","text":"<p>A Wiretap is a powerful debugging tool/methodology that can be used to understand the flow of events through the system by subscribing to all of the events that pass through the associated <code>Broker</code>. This is accomplished by the use of a <code>Trigger</code> to route all of the events into a logging service.</p> <p>Consider the following illustration:</p> <p></p>","location":"guides/createawiretap/#what-is-a-wiretap"},{"title":"Implementing a Wiretap","text":"","location":"guides/createawiretap/#implementing-a-wiretap"},{"title":"Creating an Example Bridge","text":"<p>Lets consider this example Bridge as a starting point. This example is currently configured with a <code>PingSource</code> and a <code>Broker</code>.</p> <pre><code>apiVersion: eventing.knative.dev/v1\nkind: Broker\nmetadata:\n  name: events\n\n---\n\napiVersion: sources.knative.dev/v1\nkind: PingSource\nmetadata:\n  name: ping-sockeye\nspec:\n  data: '{\"name\": \"triggermesh\"}'\n  schedule: \"*/1 * * * *\"\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: events\n</code></pre>","location":"guides/createawiretap/#creating-an-example-bridge"},{"title":"Implement a Wiretap","text":"<p>Now that we have a bridge to work with, lets go ahead and modify our manifest to include a Wiretap. We can do this by adding a <code>Trigger</code> and a <code>Service</code> to our manifest. The <code>Service</code> we will be using will be using is called Sockeye, this is a simple web application that will log the events it receives.</p> <p>We can accomplish this by adding the following to the manifest under the <code>PingSource</code> object:</p> <pre><code>apiVersion: eventing.knative.dev/v1\nkind: Trigger\nmetadata:\n  name: sockeye\nspec:\n  broker: events\n  subscriber:\n    ref:\n      apiVersion: serving.knative.dev/v1\n      kind: Service\n      name: sockeye\n\n---\n\napiVersion: serving.knative.dev/v1\nkind: Service\nmetadata:\n  name: sockeye\nspec:\n  template:\n    spec:\n      containers:\n        - image: docker.io/n3wscott/sockeye:v0.7.0@sha256:e603d8494eeacce966e57f8f508e4c4f6bebc71d095e3f5a0a1abaf42c5f0e48\n</code></pre>","location":"guides/createawiretap/#implement-a-wiretap"},{"title":"Using the Wiretap","text":"<p>Now that we have all the parts in place, we can utilize our <code>Wiretap</code> to monitor the events that are being sent through our bridge by the <code>PingSource</code> Object. We can do this in two ways.</p> <ol> <li>View the pod logs of the <code>sockeye</code> service:</li> <li><code>kubectl get pods</code> will show the pods that are running. Retrieve the sockeye pod name from the output.</li> <li> <p><code>kubectl logs &lt;SOCKEYE_POD_NAME&gt; user-container</code> By replacing the <code>&lt;SOCKEYE_POD_NAME&gt;</code> with the pod name you can view the logs of the sockeye pod.</p> </li> <li> <p>View the web service exposed by the <code>sockeye</code> service:</p> </li> <li><code>kubectl get ksvc</code> will show the KSVC's that are running. Retrieve the sockeye public URL from the <code>URL</code> column and navigate to it in your browser.</li> </ol>","location":"guides/createawiretap/#using-the-wiretap"},{"title":"Creating a Bridge With a Dead Letter Sink (DLS)","text":"","location":"guides/creatingadls/"},{"title":"What is a Dead Letter Sink?","text":"<p>A Dead Letter Sink is a Knative construct that allows the user to configure a destination for events that would otherwise be dropped due to some delivery failure. This is useful for scenarios where you want to ensure that events are not lost due to a failure in the underlying system.</p>","location":"guides/creatingadls/#what-is-a-dead-letter-sink"},{"title":"Scenario Debriefing","text":"<p>In this example we are going to create a Bridge that contains a PingSource object that will emit an event on a regular basis to a Broker named <code>demo</code>. A Service, named <code>event-success-capture</code> will subscribe to PingSource events flowing through the Broker using a Trigger.</p> <p>The Broker delivery options will be set to use a Dead Letter Sink so that in the case of a delivery error the event will be forwarded to another Service named <code>event-failure-capture</code> instead of being lost into the void.</p> <p></p> <p>We will test the bridge to make sure events are delivered to <code>event-success-capture</code>, then we will break the bridge by removing the <code>event-success-capture</code> service, in which case we expect the Dead Letter Sink to receive all events that were not delivered.</p>","location":"guides/creatingadls/#scenario-debriefing"},{"title":"Creating a Bridge with a Dead Letter Sink","text":"<p>Creating objects</p> <p>All objects mentioned at this guide are intended to be created at kubernetes. When using <code>kubectl</code> write the provided YAML manifests to a file and write at a console:</p> <pre><code>$ kubectl apply -f my-file.yaml\n</code></pre> <p>Alternatively if you don't want to write the manifests to a file you can use this command:</p> <pre><code>$ kubectl apply -f - &lt;&lt;EOF\napiVersion: some.api/v1\nkind: SomeObject\nmetadata:\n  name: some-name\nspec:\n  some: property\nEOF\n</code></pre>   <p>Bridge manifest</p> <p>The next steps configure and explain the Bridge to build to demonstrate the usage of the Dead Letter Sink. A single manifest containing all the objects in the bridge can be downloaded here.</p>","location":"guides/creatingadls/#creating-a-bridge-with-a-dead-letter-sink"},{"title":"Step 1: Create the Broker","text":"<p>Create a new Broker with following configuration:</p> <pre><code>apiVersion: eventing.knative.dev/v1\nkind: Broker\nmetadata:\n  name: demo\nspec:\n  delivery:\n    deadLetterSink:\n      ref:\n          apiVersion: serving.knative.dev/v1\n          kind: Service\n          name: event-failure-capture\n    backoffDelay: \"PT0.5S\"     # ISO8601 duration\n    backoffPolicy: exponential # exponential or linear\n    retry: 2\n</code></pre> <p>Here a Broker named <code>demo</code> is configured with the following delivery options:</p> <ul> <li>2 retries on failure, backing off exponentialy with a 0.5 seconds factor. This is not the focus of this article but it is recommended to setup retries before giving up on delivery and sending to the DLS.</li> <li>Dead Letter Sink pointing to a service named <code>event-failure-capture</code>. Kubernetes can be requested the creation of this object even if the DLS service does not exists yet.</li> </ul>","location":"guides/creatingadls/#step-1-create-the-broker"},{"title":"Step 2: Create the PingSource","text":"<p>Create a PingSource object with the following configuration:</p> <pre><code>apiVersion: sources.knative.dev/v1\nkind: PingSource\nmetadata:\n  name: say-hi\nspec:\n  data: '{\"hello\": \"triggermesh\"}'\n  schedule: \"*/1 * * * *\"\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: demo\n</code></pre> <p>This object will emit an event every minute to the Broker created in the previous step.</p>","location":"guides/creatingadls/#step-2-create-the-pingsource"},{"title":"Step 3: Create the <code>event-success-capture</code> Service","text":"<p>Create a Service named <code>event-success-capture</code> with the following configuration:</p> <pre><code>apiVersion: serving.knative.dev/v1\nkind: Service\nmetadata:\n  name: event-success-capture\nspec:\n  template:\n    metadata:\n      annotations:\n        autoscaling.knative.dev/min-scale: \"1\"\n    spec:\n      containers:\n      - image: gcr.io/knative-releases/knative.dev/eventing/cmd/event_display\n</code></pre> <p>That service will write to its standard output any CloudEvent received. We will use a Trigger to subscribe to all events flowing through the Broker.</p>","location":"guides/creatingadls/#step-3-create-the-event-success-capture-service"},{"title":"Step 4: Create the <code>demo-to-display</code> Trigger","text":"<p>Create a Trigger to route events to the <code>event-success-capture</code> Service with the following configuration:</p> <pre><code>apiVersion: eventing.knative.dev/v1\nkind: Trigger\nmetadata:\n  name: demo-to-display\nspec:\n  broker: demo\n  subscriber:\n    ref:\n      apiVersion: serving.knative.dev/v1\n      kind: Service\n      name: event-success-capture\n</code></pre> <p>This Trigger configures the Broker to send all flowing events to the <code>event-success-capture</code> service.</p>","location":"guides/creatingadls/#step-4-create-the-demo-to-display-trigger"},{"title":"Step 5: Create the <code>event-failure-capture</code> Service","text":"<p>Create the Service named <code>event-failure-capture</code> that was configured at the Broker as the Dead Letter Sink parameter:</p> <pre><code>apiVersion: serving.knative.dev/v1\nkind: Service\nmetadata:\n  name: event-failure-capture\nspec:\n  template:\n    metadata:\n      annotations:\n        autoscaling.knative.dev/min-scale: \"1\"\n    spec:\n      containers:\n      - image: gcr.io/knative-releases/knative.dev/eventing/cmd/event_display\n</code></pre> <p>This service should only receive messages that could not be delivered to a destination.</p>","location":"guides/creatingadls/#step-5-create-the-event-failure-capture-service"},{"title":"Test the Bridge","text":"<p>Make sure that all created objects are ready by inspecting the <code>READY</code> column after this command:</p> <pre><code>$ kubectl get ksvc,broker,trigger\n\nNAME                                                URL                                                          LATESTCREATED                 LATESTREADY                   READY   REASON\nservice.serving.knative.dev/event-failure-capture   http://event-failure-capture.default.192.168.49.2.sslip.io   event-failure-capture-00001   event-failure-capture-00001   True\nservice.serving.knative.dev/event-success-capture   http://event-success-capture.default.192.168.49.2.sslip.io   event-success-capture-00001   event-success-capture-00001   True\n\nNAME                               URL                                                                     AGE     READY   REASON\nbroker.eventing.knative.dev/demo   http://broker-ingress.knative-eventing.svc.cluster.local/default/demo   3m20s   True\n\nNAME                                           BROKER   SUBSCRIBER_URI                                           AGE     READY   REASON\ntrigger.eventing.knative.dev/demo-to-display   demo     http://event-success-capture.default.svc.cluster.local   3m20s   True\n</code></pre> <p>Each minute a CloudEvent should be produced by PingSource and sent to the Broker, which in turns would deliver it to the <code>event-success-capture</code>, while <code>event-failure-capture</code> should not be receiving any event. We can confirm that by reading each of those services output:</p>  <p>Retrieving logs command</p> <p>Kubernetes generates dynamic Pod names, but we can use <code>kubectl</code> with the <code>-l</code> flag to filter by a label that identifies the Service.</p> <p>We also add the <code>-f</code> flag to keep receiving logs as they are produced, this way we can see the live feed of events arriving at the Service.</p>  <pre><code>$ kubectl logs -l serving.knative.dev/service=event-success-capture  -c user-container -f\n\n\u2601\ufe0f  cloudevents.Event\nContext Attributes,\n  specversion: 1.0\n  type: dev.knative.sources.ping\n  source: /apis/v1/namespaces/default/pingsources/say-hi\n  id: efcaa3b7-bcdc-4fa9-a0b3-05d9a3c4a9f9\n  time: 2022-06-01T19:54:00.339597948Z\nExtensions,\n  knativearrivaltime: 2022-06-01T19:54:00.340295729Z\nData,\n  {\"hello\": \"triggermesh\"}\n</code></pre> <p>As expected the <code>event-success-capture</code> is receiving events produced by PingSource.</p> <pre><code>$ kubectl logs -l serving.knative.dev/service=event-failure-capture  -c user-container -f\n2022/06/01 19:36:45 Failed to read tracing config, using the no-op default: empty json tracing config\n</code></pre> <p>Meanwhile <code>event-failure-capture</code> is not showing any event.</p>","location":"guides/creatingadls/#test-the-bridge"},{"title":"Test Failing Bridge","text":"<p>To make the Bridge fail will be removing the <code>event-success-capture</code> service. That will make the delivery fail and (after 2 retries) be sent to the Dead Letter Queue.</p> <pre><code>$ kubectl delete ksvc event-success-capture\nservice.serving.knative.dev \"event-success-capture\" deleted\n</code></pre> <p>After doing so, all events not delivered by Broker through the configured Trigger will be shown at the <code>event-failure-capture</code>:</p> <pre><code>$ kubectl logs -l serving.knative.dev/service=event-failure-capture  -c user-container -f\n\n\u2601\ufe0f  cloudevents.Event\nContext Attributes,\n  specversion: 1.0\n  type: dev.knative.sources.ping\n  source: /apis/v1/namespaces/default/pingsources/say-hi\n  id: 7e11c3ac-2b00-49af-9602-59575f410b9f\n  time: 2022-06-01T20:14:00.054244562Z\nExtensions,\n  knativearrivaltime: 2022-06-01T20:14:00.055027909Z\n  knativebrokerttl: 255\n  knativeerrorcode: 500\n  knativeerrordata:\n  knativeerrordest: http://broker-filter.knative-eventing.svc.cluster.local/triggers/default/demo-to-display/bd303253-c341-4d43-b5e2-bc3adf70122a\nData,\n  {\"hello\": \"triggermesh\"}\n</code></pre>","location":"guides/creatingadls/#test-failing-bridge"},{"title":"Clean up","text":"<p>Clean up the remaining resources by issuing this command:</p> <pre><code>kubectl delete ksvc event-failure-capture\nkubectl delete triggers demo-to-display\nkubectl delete pingsource say-hi\nkubectl delete broker demo\n</code></pre>","location":"guides/creatingadls/#clean-up"},{"title":"Creating a Service","text":"<p>To get you up and running quickly we are going to run a sample Hello service.</p>","location":"guides/creatingaservice/"},{"title":"Starting a Service via the Console","text":"<p>Click on the Create Service button on the bottom on the home page of the console.</p> <p></p> <p>Click on Create Service and select from image</p> <p></p> <p>We are going to do two things:</p> <ol> <li>Set a name for our service: hello</li> <li>Specify a container image: gcr.io/cloudrun/hello</li> </ol> <p></p> <p>After a few seconds a URL will appear similar to:</p> <p></p> <p>Clicking on it will get you to the Hello web application shown below:</p> <p></p> <p>Congratulations you will have started your first service, if you do not use it, it will automatically scale to zero and wake up when you need to.</p>","location":"guides/creatingaservice/#starting-a-service-via-the-console"},{"title":"Creating a Service with its Manifest","text":"<p>If you know the Knative API already you can choose to paste the Service YAML manifest in the wizard directly.</p> <p>For example, given this manifest:</p> <pre><code>apiVersion: serving.knative.dev/v1\nkind: Service\nmetadata:\n    name: hello\n    namespace: sebgoa\nspec:\n    template:\n        spec:\n            containers:\n            - name: hello\n              image: gcr.io/cloudrun/hello\n</code></pre> <p>You would create the service From YAML as in the snapshot below:</p> <p></p>  <p>Note that a namespace with your username needs to be specified. Hence replace sebgoa in the snapshot above with your own username.</p>","location":"guides/creatingaservice/#creating-a-service-with-its-manifest"},{"title":"Creating a Source","text":"<p>Installation</p> <p>Make sure you have completed the installation procedure before continuing with any of the guides.</p>  <p>In this guide we will create a point to point Bridge between an AWS SQS queue and a microservice application called <code>sockeye</code> which displays events in a web interface. This simple flow is depicted below.</p> <p></p> <p>We will create:</p> <ul> <li> The <code>sockeye</code> target which serves as an event display.</li> <li> The <code>AWSSQSSource</code> which consumes events from an AWS SQS queue.</li> </ul>  <p>Kubernetes namespace</p> <p>All objects mentioned in this guide must be created inside the same Kubernetes namespace.</p>","location":"guides/creatingasource/"},{"title":"Sockeye CloudEvents viewer display","text":"<p>First of all, we need to have a tool to see the events that come from our source.</p> <p>Create a <code>sockeye</code> deployment and service by saving the following YAML manifest in a file called <code>sockeye.yaml</code> and applying it to your Kubernetes cluster:</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: sockeye\nspec:\n  selector:\n    app.kubernetes.io/name: sockeye\n  ports:\n  - port: 80\n    protocol: TCP\n    targetPort: 8080\n\n---\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sockeye\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: sockeye\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: sockeye\n    spec:\n      containers:\n      - name: sockeye\n        image: docker.io/n3wscott/sockeye:v0.7.0@sha256:e603d8494eeacce966e57f8f508e4c4f6bebc71d095e3f5a0a1abaf42c5f0e48\n</code></pre> <pre><code>$ kubectl apply -f sockeye.yaml\n</code></pre> <p>Forward the sockeye service locally to be able to open it in your web browser. Open a dedicated console and issue the following command:</p> <pre><code>$ kubectl port-forward svc/sockeye 8080:80\n</code></pre> <p>Sockeye should be not avaialble at <code>http://localhost:8080/</code></p>","location":"guides/creatingasource/#sockeye-cloudevents-viewer-display"},{"title":"Create a AWS SQS Event source","text":"<p>You can explore the specification of the object using the <code>kubectl explain</code> command. You will see that you need the ARN (i.e Amazon Resource Name) of your AWS SQS queue and the AWS API keys that give you access to SQS.</p> <pre><code>$ kubectl explain awssqssource.spec\nKIND:     AWSSQSSource\nVERSION:  sources.triggermesh.io/v1alpha1\n\nRESOURCE: spec &lt;Object&gt;\n\nDESCRIPTION:\n     Desired state of the event source.\n\nFIELDS:\n   adapterOverrides     &lt;Object&gt;\n     Kubernetes object parameters to apply on top of default adapter values.\n\n   arn  &lt;string&gt; -required-\n     ARN of the Amazon SQS queue to consume messages from. The expected format\n     is documented at\n     https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazonsqs.html#amazonsqs-resources-for-iam-policies.\n\n   auth &lt;Object&gt;\n     Authentication method to interact with the Amazon SQS API.\n\n   endpoint     &lt;Object&gt;\n     Customizations of the AWS REST API endpoint.\n\n   messageProcessor     &lt;string&gt;\n     Name of the message processor to use for converting SQS messages to\n     CloudEvents. Supported values are \"default\" and \"s3\".\n\n   receiveOptions       &lt;Object&gt;\n     Options that control the behavior of message receivers.\n\n   sink &lt;Object&gt; -required-\n     The destination of events sourced from Amazon SQS.\n</code></pre> <p>Create a secret called <code>awscreds</code> which contains your access key and your secret key like so:</p> <pre><code>kubectl create secret generic awscreds \\\n  --from-literal=access_key_id=&lt;ACCESS_KEY_ID&gt; \\\n  --from-literal=secret_access_key=&lt;SECRET_ACCESS_KEY&gt;\n</code></pre>  <p>AWS Credentials</p> <p>Instructions about setting up AWS security credentials can be found in the documentation page for the Amazon SQS source.</p>  <p>Then, write a YAML manifest for your SQS source similar to the one below. The following sample points to a SQS queue, referenced by its ARN and a secret called <code>awscreds</code>.</p> <pre><code>apiVersion: sources.triggermesh.io/v1alpha1\nkind: AWSSQSSource\nmetadata:\n  name: sqs-guide\nspec:\n  arn: arn:aws:sqs:us-east-1:123456789012:triggermesh\n  auth:\n    credentials:\n      accessKeyID:\n        valueFromSecret:\n          name: awscreds\n          key: access_key_id\n      secretAccessKey:\n        valueFromSecret:\n          name: awscreds\n          key: secret_access_key\n  sink:\n    ref:\n      apiVersion: serving.knative.dev/v1\n      kind: Service\n      name: sockeye\n</code></pre> <p>Create this source with the <code>kubectl apply -f</code> command.</p>","location":"guides/creatingasource/#create-a-aws-sqs-event-source"},{"title":"Results","text":"<p>Verify that your source is ready with:</p> <pre><code>$ kubectl get awssqssource\nNAME          READY   REASON   SINK                                      AGE\nsqs-guide     True             http://sockeye.sebgoa.svc.cluster.local   3m57s\n</code></pre> <p>You can go to the AWS SQS console and put a message in the queue as shown in the following screenshot:</p> <p></p> <p>The message will get consumed by the source and sent directly to Sockeye in a CloudEvent format. Below is a screenshot of Sockeye displaying the received event.</p> <p></p>","location":"guides/creatingasource/#results"},{"title":"More about Sources","text":"<p>Learn more about Sources on the Concepts page.</p>","location":"guides/creatingasource/#more-about-sources"},{"title":"Creating an Event Splitter","text":"<p>An event <code>Splitter</code> is part of the TriggerMesh routing solution. It has the simple purpose of splitting JSON arrays into multiple CloudEvents for further processing.</p>  <p>Tip</p> <p>You can verify that the API is available with the following command:</p> <pre><code>$ kubectl get crd splitters.routing.triggermesh.io\nNAME                               CREATED AT\nsplitters.routing.triggermesh.io   2021-10-06T09:01:38Z\n</code></pre> <p>You can also explore the API specification with: <pre><code>$ kubectl explain splitter\n</code></pre></p>  <p></p> <p>Let's create the required objects:</p> <ul> <li> The <code>sockeye</code> target which serves as an event display.</li> <li> The <code>PingSource</code> which produces a JSON array in its payload.</li> <li> The <code>Splitter</code> to generate the multiple events.</li> </ul>","location":"guides/creatingasplitter/"},{"title":"Event display","text":"<p>First of all, we need to have a tool to see the split events. Create a <code>sockeye</code> service by saving the following YAML manifest in a file called <code>sockeye.yaml</code> and applying it to your Kubernetes cluster:</p> <pre><code>apiVersion: serving.knative.dev/v1\nkind: Service\nmetadata:\n  name: sockeye\nspec:\n  template:\n    spec:\n      containers:\n        - image: docker.io/n3wscott/sockeye:v0.7.0@sha256:e603d8494eeacce966e57f8f508e4c4f6bebc71d095e3f5a0a1abaf42c5f0e48\n</code></pre> <pre><code>kubectl apply -f sockeye.yaml\n</code></pre> <p>Open the web interface in a browser at the URL found with the following command:</p> <pre><code>$ kubectl get ksvc sockeye -o=jsonpath='{.status.url}'\n</code></pre>","location":"guides/creatingasplitter/#event-display"},{"title":"Events producer","text":"<p>Next we create the PingSource which produces CloudEvents that contain a list in their payload. Save the following YAML manifest in a file and apply it to your Kubernetes cluster with <code>kubectl apply</code>.</p> <pre><code>apiVersion: sources.knative.dev/v1\nkind: PingSource\nmetadata:\n  name: ps-splitter-demo\nspec:\n  schedule: \"*/1 * * * *\"\n  contentType: \"application/json\"\n  data: '{\n      \"message\":\"hello\",\n      \"items\":[\n          {\n              \"id\":5,\n              \"name\":\"foo\"\n          },{\n              \"id\":10,\n              \"name\":\"bar\"\n          }\n        ]\n      }'\n  sink:\n    ref:\n      apiVersion: routing.triggermesh.io/v1alpha1\n      kind: Splitter\n      name: splitter-demo\n</code></pre>","location":"guides/creatingasplitter/#events-producer"},{"title":"The Splitter","text":"<p>Finally, create the <code>Splitter</code> that will produce two events from every single CloudEvent received from the PingSource by saving the following YAML manifest and applying it to your Kubernetes cluster.</p> <pre><code>apiVersion: routing.triggermesh.io/v1alpha1\nkind: Splitter\nmetadata:\n  name: splitter-demo\nspec:\n  path: items\n  ceContext:\n    type: foo.bar.type\n    source: splitter\n  sink:\n    ref:\n      apiVersion: serving.knative.dev/v1\n      kind: Service\n      name: sockeye\n</code></pre> <p>Note that you define the path where you are going to find a list in the incoming event and you define the CloudEvent attributes of the generated events (i.e splitter as the source and foo.bar.type as the type).</p> <p>Verify that your splitter is ready with <code>kubectl</code> like so:</p> <pre><code>$ kubectl get splitter\nNAME            ADDRESS                                                          READY   REASON\nsplitter-demo   http://splitter-adapter.sebgoa.svc.cluster.local/splitter-demo   True\n</code></pre> <p>In the sockeye application you will see two individual events that have been generated from the original list emitted by the source. The snapshot below shows you what you should see:</p> <p></p>  <p>Play with your Splitter as Code</p> <p>You can play around by modifying the <code>Splitter</code> object and re-applying it with <code>kubectl</code>. This gives you a declarative event splitter which you can manage with your GitOps workflow</p>","location":"guides/creatingasplitter/#the-splitter"},{"title":"More about Splitters","text":"<p>Learn more about Splitters on the Concepts page.</p>","location":"guides/creatingasplitter/#more-about-splitters"},{"title":"Creating a Target","text":"<p>A <code>Target</code> is an API object defining an event receiver, processing the event, and interacting with a third-party service. See the concepts page for further details.</p> <p>In this getting started guide on targets we are going to create a Bridge between a <code>PingSource</code> and AWS Lambda. The source will emit an event on a repeating schedule and we will send this event to an AWS Lambda function.</p> <p></p> <p>We will:</p> <ul> <li> Write a simple AWS Lambda function</li> <li> Write an <code>AWSLambdaTarget</code> object pointing to the function we created</li> <li> Write a <code>PingSource</code> which will emit an event to the Target.</li> </ul>","location":"guides/creatingatarget/"},{"title":"Creating an AWS Lambda function","text":"<p>For full details with using the Lambda console follow these official steps.</p> <p>Our function is written in Python 3.9 and will print the payload of the incoming event to stdout.</p> <p></p> <p>This function is uniquely identified by its Amazon Resource Name (i.e ARN).</p>","location":"guides/creatingatarget/#creating-an-aws-lambda-function"},{"title":"Writing the <code>AWSLambdaTarget</code> specification","text":"<p>To learn how to write a Target, use <code>kubectl explain</code> to explore the specification. Looking specifically into the <code>spec</code> section we see that the ARN of the Lambda is needed</p> <pre><code>$ kubectl explain awslambdatarget.spec\nKIND:     AWSLambdaTarget\nVERSION:  targets.triggermesh.io/v1alpha1\n\nRESOURCE: spec &lt;Object&gt;\n\nDESCRIPTION:\n     Desired state of event target.\n\nFIELDS:\n   arn  &lt;string&gt;\n     ARN of the Lambda function that will receive events. The expected format is\n     documented at\n     https://docs.aws.amazon.com/service-authorization/latest/reference/list_awslambda.html\n\n   awsApiKey    &lt;Object&gt;\n     API Key to interact with the Amazon Lambda API. For more information about\n     AWS security credentials, please refer to the AWS General Reference at\n     https://docs.aws.amazon.com/general/latest/gr/aws-security-credentials.html\n\n   awsApiSecret &lt;Object&gt;\n     API Secret to interact with the Amazon Lambda API. For more information\n     about AWS security credentials, please refer to the AWS General Reference\n     at\n     https://docs.aws.amazon.com/general/latest/gr/aws-security-credentials.html\n\n   discardCloudEventContext &lt;boolean&gt;\n     Produce a new cloud event based on the response from the lambda function.\n</code></pre> <p>In addition to be able to interact with AWS you need to have your AWS API keys available. You may specify them in an object manifest but for better security you will want to use a Kubernetes secret.</p> <p>Create a Kubernetes secret called <code>awscreds</code> from the command line like so:</p> <pre><code>kubectl create secret generic awscreds \\\n  --from-literal=access_key_id=&lt;ACCESS_KEY_ID&gt; \\\n  --from-literal=secret_access_key=&lt;SECRET_ACCESS_KEY&gt;\n</code></pre> <p>Then, create the following object by saving the YAML manifest in a file and using the <code>kubectl apply</code> command.</p> <pre><code>apiVersion: targets.triggermesh.io/v1alpha1\nkind: AWSLambdaTarget\nmetadata:\n  name: lambda-guide\nspec:\n  arn: arn:aws:lambda:us-east-1:587264368683:function:triggermesh\n  awsApiKey:\n    secretKeyRef:\n      key: access_key_id\n      name: awscreds\n  awsApiSecret:\n    secretKeyRef:\n      key: secret_access_key\n      name: awscreds\n  discardCloudEventContext: false\n</code></pre>","location":"guides/creatingatarget/#writing-the-awslambdatarget-specification"},{"title":"Creating the event source","text":"<p>For the event source we use a <code>PingSource</code> which emits a CloudEvent every minute.</p> <pre><code>apiVersion: sources.knative.dev/v1\nkind: PingSource\nmetadata:\n  name: ping-lambda\nspec:\n  data: '{\"name\": \"triggermesh\"}'\n  schedule: '*/1 * * * *'\n  sink:\n    ref:\n      apiVersion: targets.triggermesh.io/v1alpha1\n      kind: AWSLambdaTarget\n      name: lambda-guide\n</code></pre> <p>Note the definition of the <code>sink</code> in the manifest above, it points to the <code>AWSLambdaTarget</code> created before.</p>","location":"guides/creatingatarget/#creating-the-event-source"},{"title":"Verifying the Results","text":"<p>You can verify that your objects are ready:</p> <pre><code>$ kubectl get pingsource\nNAME               SINK                                                                      SCHEDULE      AGE     READY   REASON\nping-lambda        http://broker-ingress.knative-eventing.svc.cluster.local/sebgoa/default   */1 * * * *   7m52s   True\n\n$ kubectl get awslambdatarget\nNAME          URL   READY   REASON               AGE\nlambda-guide         True                         3m12s\n</code></pre> <p>Finally, go to the AWS Lambda console and see the logs of your Lambda function invocation in a CloudWatch log stream like in the screenshot below:</p> <p></p>","location":"guides/creatingatarget/#verifying-the-results"},{"title":"More about Targets","text":"<p>Learn more about Targets on the Concepts page.</p>","location":"guides/creatingatarget/#more-about-targets"},{"title":"Transforming using DataWeave","text":"<p>The TriggerMesh <code>DataWeaveTransformation</code> API object can be used to process a Cloudevent containing JSON or XML and transform the document using DataWeave.</p> <p>This guide shows you how to configure an event flow that transforms an incoming CloudEvent in XML by parsing it with a DataWeave Spell. It has five steps:</p> <ul> <li>Deploy a Broker that will receive the transformed data.</li> <li>Deploy the <code>EventDisplay</code> service.</li> <li>Deploy the <code>DataWeaveTransformation</code> object.</li> <li>Configure the Triggers</li> <li>Deploy a curl pod that will allow us to send events to the broker.</li> </ul>","location":"guides/dataweavetransformation/"},{"title":"How to use a DataWeaveTransformation","text":"<p>A <code>DataWeaveTransformation</code> object can be configured to either reply to the event sender or to send the  transformed data to a <code>Sink</code>, if one is provided. In this guide, we will deploy without a <code>Sink</code> and  configure the replies from the transformation to route to the <code>EventDisplay</code> service using a <code>Broker</code> and a <code>Trigger</code>.</p> <p>The <code>DataWeaveTransformation</code> can have a pre-defined parameters configured in the YAML but it also allows to send the parameters as part of the request. In this guide we will use both ways; we will configure the pre-defined parameters in the YAML but we will also use other parameters in the request, which is made possible by enabling the <code>allowPerEventDwSpell</code> parameter.</p>","location":"guides/dataweavetransformation/#how-to-use-a-dataweavetransformation"},{"title":"DataWeaveTransformation parameters","text":"<ul> <li><code>allowPerEventDwSpell</code>: Allow to send the DataWeaveSpell as part of the request. (Optional)</li> <li><code>dwSpell</code>: DataWeave spell used to transform incoming CloudEvents. (Optional)</li> <li><code>inputContentType</code>: Content type for transformation ['application/json', 'application/xml']. (Optional)</li> <li><code>outputContentType</code>: Content type for transformation output. ['application/json', 'application/xml']. (Optional)</li> </ul> <p>Below is a sample DataWeave spell that will be used throughout the guide. <pre><code>%dw 2.0\noutput application/json\n---\n{\n    email: payload.order.buyer.email,\n    name: payload.order.buyer.name,\n}\n</code></pre></p> <p>It transforms the following XML: <pre><code>&lt;order&gt;\n    &lt;product&gt;\n        &lt;price&gt;5&lt;/price&gt;\n        &lt;model&gt;Company 2020&lt;/model&gt;\n    &lt;/product&gt;\n    &lt;item_amount&gt;3&lt;/item_amount&gt;\n    &lt;payment&gt;\n        &lt;payment-type&gt;credit-card&lt;/payment-type&gt;\n        &lt;currency&gt;USD&lt;/currency&gt;\n        &lt;installments&gt;1&lt;/installments&gt;\n    &lt;/payment&gt;\n    &lt;buyer&gt;\n        &lt;email&gt;james@hotmail.com&lt;/email&gt;\n        &lt;name&gt;James&lt;/name&gt;\n        &lt;address&gt;Cocodrile Boulevard 61&lt;/address&gt;\n        &lt;city&gt;Seattle&lt;/city&gt;\n        &lt;state&gt;CA&lt;/state&gt;\n        &lt;postCode&gt;98101&lt;/postCode&gt;\n        &lt;nationality&gt;USA&lt;/nationality&gt;\n    &lt;/buyer&gt;\n    &lt;shop&gt;main branch&lt;/shop&gt;\n    &lt;salesperson&gt;Liam Smith&lt;/salesperson&gt;\n&lt;/order&gt;\n</code></pre></p> <p>Into this new JSON document: <pre><code>{\n  \"email\": \"james@hotmail.com\",\n  \"name\": \"James\"\n}\n</code></pre></p> <p>Let's go step by step to see how we can deploy this transformation as part of a TriggerMesh Bridge.</p> <p>Below is a diagram of the Bridge we will construct.</p> <p></p>","location":"guides/dataweavetransformation/#dataweavetransformation-parameters"},{"title":"Deploy the Broker","text":"<p>Deploy a Broker by writing the following YAML in a file: <pre><code>apiVersion: eventing.knative.dev/v1\nkind: Broker\nmetadata:\n  name: demo\n</code></pre></p> <p>Create the Broker with the following command: <pre><code>kubectl apply -f &lt;manifest.yaml&gt;\n</code></pre></p>","location":"guides/dataweavetransformation/#deploy-the-broker"},{"title":"Deploying the <code>EventDisplay</code> Service","text":"<p>Let's now deploy the Sink of our event flow. The <code>EventDisplay</code> is a simple application that can be used to display CloudEvents. It can  be deployed by writing the following YAML in a file and using <code>kubectl apply -f &lt;manifest.yaml&gt;</code>:</p> <pre><code>apiVersion: serving.knative.dev/v1\nkind: Service\nmetadata:\n    name: event-display\nspec:\n  template:\n    spec:\n      containers:\n        - image: gcr.io/knative-releases/knative.dev/eventing/cmd/event_display\n</code></pre>","location":"guides/dataweavetransformation/#deploying-the-eventdisplay-service"},{"title":"Deploy the <code>DataWeaveTransformation</code> Object","text":"<p>With the <code>event-display</code> in place, the <code>DataWeaveTransformation</code> object can now be deployed in the same manner using the following manifest. It contains an inline DataWeave spell that will be used by default but can be overridden by passing a spell in the CloudEvent payload.</p> <pre><code>apiVersion: flow.triggermesh.io/v1alpha1\nkind: DataWeaveTransformation\nmetadata:\n  name: demo\nspec:\n  allowPerEventDwSpell: true\n  dwSpell:\n    value: |-\n      %dw 2.0\n      output application/json\n      ---\n      {\n          email: payload.order.buyer.email,\n          name: payload.order.buyer.name,\n      }\n  inputContentType: application/xml\n  outputContentType: application/json\n</code></pre>","location":"guides/dataweavetransformation/#deploy-the-dataweavetransformation-object"},{"title":"Configure the Triggers","text":"<p>Next, Triggers need to be configured to route our Cloudevents to the <code>DataWeaveTransformation</code> and <code>EventDisplay</code> objects. This can be done by writing the following YAML in a file and using <code>kubectl apply -f &lt;manifest.yaml&gt;</code>. We have two triggers, one to send events containing XML to the transformation and one to send all events to the event display.</p> <pre><code>kind: Trigger\napiVersion: eventing.knative.dev/v1\nmetadata:\n  name: event-display\nspec:\n  broker: demo\n  subscriber:\n    ref:\n      apiVersion: serving.knative.dev/v1\n      kind: Service\n      name: event-display\n---\nkind: Trigger\napiVersion: eventing.knative.dev/v1\nmetadata:\n  name: dataweavetransformation-xmldoc\nspec:\n  broker: demo\n  filter:\n    attributes:\n      # setting a filter to process only events of type `xml.document`\n      type: xml.document\n  subscriber:\n    ref:\n      apiVersion: flow.triggermesh.io/v1alpha1\n      kind: DataWeaveTransformation\n      name: demo\n</code></pre>","location":"guides/dataweavetransformation/#configure-the-triggers"},{"title":"Deploy a Curl Pod","text":"<p>Finally, an event source can be deployed that will emit CloudEvents with XML data in the payload. We can do this in two steps:</p> <pre><code>1. Deploy a curl pod that will emit the CloudEvents by writing the following YAML in a file and apply it with `kubectl apply -f &lt;manifest.yaml&gt;`.\n</code></pre> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    run: curl\n  name: curl\nspec:\n  containers:\n  - image: radial/busyboxplus:curl\n    imagePullPolicy: IfNotPresent\n    name: curl\n    stdin: true\n    tty: true\n</code></pre> <pre><code>2. Execute the following command to emit a cloudevent to the broker we created:\n</code></pre> <pre><code>kubectl exec -ti curl -- curl -v \"http://broker-ingress.knative-eventing.svc.cluster.local/default/demo\" \\\n  -H \"Ce-Specversion: 1.0\" \\\n  -H \"Ce-Type: xml.document\" \\\n  -H \"Ce-Source: curl.shell\" \\\n  -H \"Content-Type: application/xml\" \\\n  -H \"Ce-Id: 1234-abcd\" \\\n  -d '&lt;?xml version=\"1.0\"?&gt;\n&lt;order&gt;&lt;product&gt;&lt;price&gt;5&lt;/price&gt;&lt;model&gt;Company 2020&lt;/model&gt;&lt;/product&gt;&lt;item_amount&gt;3&lt;/item_amount&gt;&lt;payment&gt;&lt;payment-type&gt;credit-card&lt;/payment-type&gt;&lt;currency&gt;USD&lt;/currency&gt;&lt;installments&gt;1&lt;/installments&gt;&lt;/payment&gt;&lt;buyer&gt;&lt;email&gt;james@hotmail.com&lt;/email&gt;&lt;name&gt;James&lt;/name&gt;&lt;address&gt;Cocodrile Boulevard 61&lt;/address&gt;&lt;city&gt;Seattle&lt;/city&gt;&lt;state&gt;CA&lt;/state&gt;&lt;postCode&gt;98101&lt;/postCode&gt;&lt;nationality&gt;USA&lt;/nationality&gt;&lt;/buyer&gt;&lt;shop&gt;main branch&lt;/shop&gt;&lt;salesperson&gt;Liam Smith&lt;/salesperson&gt;&lt;/order&gt;'\n</code></pre>","location":"guides/dataweavetransformation/#deploy-a-curl-pod"},{"title":"Viewing the Transformation's Output in the Event Display","text":"<p>With our event flow in place, we can now view the transformed data in the <code>EventDisplay</code>.</p> <p>We need to retrieve the <code>EventDisplay</code> Pod name by running the following command:</p> <p><pre><code>kubectl get pods                                                          \nNAME                                                   READY   STATUS    RESTARTS   AGE\ncurl                                                   1/1     Running   0          4m36s\nevent-display-00001-deployment-fb48c8d7c-g7bmv        2/2     Running   0          3s\ndataweavetransformation-demo-00001-deployment-7978655d45-jsfbr   2/2     Running   0          3s\n</code></pre> With the Pod name, we can run the following command to view the transformed data in the <code>EventDisplay</code> Pod logs:</p> <pre><code>kubectl logs event-display-00001-deployment-fb48c8d7c-g7bmv user-container\n\u2601\ufe0f  cloudevents.Event\nContext Attributes,\n  specversion: 1.0\n  type: xml.document\n  source: curl.shell\n  id: 1234-abcd\n  datacontenttype: application/xml\nExtensions,\n  knativearrivaltime: 2022-05-09T10:32:43.32759997Z\nData,\n  &lt;?xml version=\"1.0\"?&gt;\n&lt;order&gt;&lt;product&gt;&lt;price&gt;5&lt;/price&gt;&lt;model&gt;Company 2020&lt;/model&gt;&lt;/product&gt;&lt;item_amount&gt;3&lt;/item_amount&gt;&lt;payment&gt;&lt;payment-type&gt;credit-card&lt;/payment-type&gt;&lt;currency&gt;USD&lt;/currency&gt;&lt;installments&gt;1&lt;/installments&gt;&lt;/payment&gt;&lt;buyer&gt;&lt;email&gt;james@hotmail.com&lt;/email&gt;&lt;name&gt;James&lt;/name&gt;&lt;address&gt;Cocodrile Boulevard 61&lt;/address&gt;&lt;city&gt;Seattle&lt;/city&gt;&lt;state&gt;CA&lt;/state&gt;&lt;postCode&gt;98101&lt;/postCode&gt;&lt;nationality&gt;USA&lt;/nationality&gt;&lt;/buyer&gt;&lt;shop&gt;main branch&lt;/shop&gt;&lt;salesperson&gt;Liam Smith&lt;/salesperson&gt;&lt;/order&gt;\n\u2601\ufe0f  cloudevents.Event\nContext Attributes,\n  specversion: 1.0\n  type: xml.document.response\n  source: curl.shell\n  id: 1234-abcd\n  time: 2022-05-09T10:32:44.697405628Z\n  datacontenttype: application/json\nExtensions,\n  knativearrivaltime: 2022-05-09T10:32:44.699348327Z\nData,\n  {\n    \"email\": \"james@hotmail.com\",\n    \"name\": \"James\"\n  }\n</code></pre> <p>We now see the incoming event and the transformed data, as expected. </p>","location":"guides/dataweavetransformation/#viewing-the-transformations-output-in-the-event-display"},{"title":"Sending the parameters in the request.","text":"<p>Now we can try passing parameters such as the DataWeave spell and input and output content types as part of the Cloud Event.</p> <pre><code>1. Execute the following command to emit a cloudevent to the broker we created:\n</code></pre> <pre><code>kubectl exec -ti curl -- curl -v \"http://broker-ingress.knative-eventing.svc.cluster.local/default/demo\" \\\n  -H \"Ce-Specversion: 1.0\" \\\n  -H \"Ce-Type: xml.document\" \\\n  -H \"Ce-Source: curl.shell\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Ce-Id: 1234-abcd\" \\\n  -d '{\n  \"input_data\": \"&lt;order&gt;&lt;product&gt;&lt;price&gt;5&lt;/price&gt;&lt;model&gt;Company 2020&lt;/model&gt;&lt;/product&gt;&lt;item_amount&gt;3&lt;/item_amount&gt;&lt;payment&gt;&lt;payment-type&gt;credit-card&lt;/payment-type&gt;&lt;currency&gt;USD&lt;/currency&gt;&lt;installments&gt;1&lt;/installments&gt;&lt;/payment&gt;&lt;buyer&gt;&lt;email&gt;james@hotmail.com&lt;/email&gt;&lt;name&gt;James&lt;/name&gt;&lt;address&gt;Cocodrile Boulevard 61&lt;/address&gt;&lt;city&gt;Seattle&lt;/city&gt;&lt;state&gt;CA&lt;/state&gt;&lt;postCode&gt;98101&lt;/postCode&gt;&lt;nationality&gt;USA&lt;/nationality&gt;&lt;/buyer&gt;&lt;shop&gt;main branch&lt;/shop&gt;&lt;salesperson&gt;Liam Smith&lt;/salesperson&gt;&lt;/order&gt;\",\n  \"spell\": \"{address1:payload.order.buyer.address,city:payload.order.buyer.city,country:payload.order.buyer.nationality,email:payload.order.buyer.email,name:payload.order.buyer.name,postalCode:payload.order.buyer.postCode,stateOrProvince:payload.order.buyer.state}\",\n  \"input_content_type\": \"application/xml\",\n  \"output_content_type\": \"application/json\"\n}'\n</code></pre>","location":"guides/dataweavetransformation/#sending-the-parameters-in-the-request"},{"title":"Viewing the Transformation's Output in the Event Display","text":"<pre><code>kubectl logs event-display-00001-deployment-fb48c8d7c-2h444 user-container\n\u2601\ufe0f  cloudevents.Event\nContext Attributes,\n  specversion: 1.0\n  type: xml.document\n  source: curl.shell\n  id: 1234-abcd\n  datacontenttype: application/json\nExtensions,\n  knativearrivaltime: 2022-05-09T10:39:47.80922913Z\nData,\n  {\n    \"input_data\": \"&lt;order&gt;&lt;product&gt;&lt;price&gt;5&lt;/price&gt;&lt;model&gt;Company 2020&lt;/model&gt;&lt;/product&gt;&lt;item_amount&gt;3&lt;/item_amount&gt;&lt;payment&gt;&lt;payment-type&gt;credit-card&lt;/payment-type&gt;&lt;currency&gt;USD&lt;/currency&gt;&lt;installments&gt;1&lt;/installments&gt;&lt;/payment&gt;&lt;buyer&gt;&lt;email&gt;james@hotmail.com&lt;/email&gt;&lt;name&gt;James&lt;/name&gt;&lt;address&gt;Cocodrile Boulevard 61&lt;/address&gt;&lt;city&gt;Seattle&lt;/city&gt;&lt;state&gt;CA&lt;/state&gt;&lt;postCode&gt;98101&lt;/postCode&gt;&lt;nationality&gt;USA&lt;/nationality&gt;&lt;/buyer&gt;&lt;shop&gt;main branch&lt;/shop&gt;&lt;salesperson&gt;Liam Smith&lt;/salesperson&gt;&lt;/order&gt;\",\n    \"spell\": \"{address1:payload.order.buyer.address,city:payload.order.buyer.city,country:payload.order.buyer.nationality,email:payload.order.buyer.email,name:payload.order.buyer.name,postalCode:payload.order.buyer.postCode,stateOrProvince:payload.order.buyer.state}\",\n    \"input_content_type\": \"application/xml\",\n    \"output_content_type\": \"application/json\"\n  }\n\u2601\ufe0f  cloudevents.Event\nContext Attributes,\n  specversion: 1.0\n  type: xml.document.response\n  source: curl.shell\n  id: 1234-abcd\n  time: 2022-05-09T10:39:47.852857516Z\n  datacontenttype: application/json\nExtensions,\n  knativearrivaltime: 2022-05-09T10:39:47.86469464Z\nData,\n  {\n    \"address1\": \"Cocodrile Boulevard 61\",\n    \"city\": \"Seattle\",\n    \"country\": \"USA\",\n    \"email\": \"james@hotmail.com\",\n    \"name\": \"James\",\n    \"postalCode\": \"98101\",\n    \"stateOrProvince\": \"CA\"\n  }\n</code></pre> <p>We now see the incoming event and the transformed data, as expected with the parameters set in the request.</p>","location":"guides/dataweavetransformation/#viewing-the-transformations-output-in-the-event-display_1"},{"title":"Doing a Transformation","text":"<p>The <code>Transformation</code> object in TriggerMesh defines a set of operations that are sequentially applied to incoming CloudEvents. In this guide, we will create a simple Bridge with an event producer and a transformation to see the declarative syntax that is used for modifying events.</p>  <p>Tip</p> <p>You can verify that the API is available with the following command:</p> <pre><code>$ kubectl get crd transformations.flow.triggermesh.io\nNAME                                  CREATED AT\ntransformations.flow.triggermesh.io   2021-10-06T09:01:40Z\n</code></pre> <p>You can also explore the API specification with: <pre><code>$ kubectl explain transformation\n</code></pre></p>  <p></p> <p>Let's create all the required objects:</p> <ul> <li> The sockeye target which serves as an event display.</li> <li> The <code>PingSource</code> which serves as an event producer.</li> <li> The <code>Transformation</code> to modify the produced events.</li> </ul>","location":"guides/doingatransformation/"},{"title":"Event display","text":"<p>First of all, we need to have a tool to see the transformed events. Create a <code>sockeye</code> service by saving the following YAML manifest in a file called <code>sockeye.yaml</code> and applying it to your Kubernetes cluster:</p> <pre><code>apiVersion: serving.knative.dev/v1\nkind: Service\nmetadata:\n  name: sockeye\nspec:\n  template:\n    spec:\n      containers:\n        - image: docker.io/n3wscott/sockeye:v0.7.0@sha256:e603d8494eeacce966e57f8f508e4c4f6bebc71d095e3f5a0a1abaf42c5f0e48\n</code></pre> <pre><code>kubectl apply -f sockeye.yaml\n</code></pre> <p>Open the web interface in a browser at the URL that you find with the following command:</p> <pre><code>$ kubectl get ksvc sockeye -o=jsonpath='{.status.url}'\n</code></pre>","location":"guides/doingatransformation/#event-display"},{"title":"Events producer","text":"<p>Next, we need to create a PingSource to produce CloudEvents by saving the following YAML manifests in a file and applying it to your Kubernetes cluster with <code>kubectl apply</code>:</p> <pre><code>apiVersion: sources.knative.dev/v1\nkind: PingSource\nmetadata:\n  name: ps-transformation-demo\nspec:\n  schedule: \"*/1 * * * *\"\n  contentType: \"application/json\"\n  data: '{\n    \"First Name\": \"Alice\",\n    \"Last Name\": \"Wonderland\",\n    \"Date of birth\": {\n      \"year\": 1955,\n      \"month\": 1,\n      \"day\" : 23\n    },\n    \"Married\": true,\n    \"Children\":\n    [\n        {\"Name\": \"Martin\", \"Year of birth\": 1980},\n        {\"Name\": \"Margaret\", \"Year of birth\": 1983}\n    ],\n    \"Mobile phone\": null\n  }'\n  sink:\n    ref:\n      apiVersion: flow.triggermesh.io/v1alpha1\n      kind: Transformation\n      name: trn-transformation-demo\n</code></pre>","location":"guides/doingatransformation/#events-producer"},{"title":"Transformation","text":"<p>And finally the transformation object that will receive CloudEvents from the PingSource defined above, apply its operations and forward modified events to the <code>sockeye</code> service:</p> <pre><code>apiVersion: flow.triggermesh.io/v1alpha1\nkind: Transformation\nmetadata:\n  name: trn-transformation-demo\nspec:\n  sink:\n    ref:\n      apiVersion: serving.knative.dev/v1\n      kind: Service\n      name: sockeye\n\n  context:\n  - operation: store\n    paths:\n    - key: $time\n      value: time\n    - key: $id\n      value: id\n  - operation: add\n    paths:\n    - key: id\n      value: $person-$id\n    - key: type\n      value: io.triggermesh.transformation.pingsource\n\n  data:\n  - operation: store\n    paths:\n    - key: $person\n      value: First Name\n  - operation: add\n    paths:\n    - key: event.ID\n      value: $id\n    - key: event.time\n      value: $time\n  - operation: shift\n    paths:\n    - key: Date of birth:birthday\n    - key: First Name:firstname\n    - key: Last Name:lastname\n  - operation: delete\n    paths:\n    - key: Mobile phone\n    - key: Children[1].Year of birth\n    - value: Martin\n</code></pre> <p>Once created with <code>kubectl apply</code> verify that the transformation is ready:</p> <pre><code>$ kubectl get transformation -w\nNAME                      ADDRESS                                                   READY   REASON\ntrn-transformation-demo   http://trn-transformation-demo.sebgoa.svc.cluster.local   True\n</code></pre> <p>If all the components of the Bridge are ready, the <code>sockeye</code> web interface will start showing modified events shortly:</p> <p></p> <p>You will notice that the CloudEvent attributes have beeen modified according to the <code>context</code> section in the specification of the <code>Transformation</code> object. The event type was modified and the <code>id</code> was prepended with the string <code>Alice</code>.</p> <p>The payload was also transformed according to the <code>data</code> section of the <code>Transformation</code> object. For example the mobile phone was deleted, a key <code>event</code> was added and a few keys were shifted: \"Date of Birth\" became \"birthday\".</p>  <p>Play with your Transformation as Code</p> <p>You can play around by modifying the <code>Transformation</code> object and re-applying it with <code>kubectl</code>. This gives you a declarative event transformer which you can manage with your GitOps workflow.</p>","location":"guides/doingatransformation/#transformation"},{"title":"More about Transformations","text":"<p>Learn more about Transformations on the Concepts page.</p>","location":"guides/doingatransformation/#more-about-transformations"},{"title":"TriggerMesh AMI","text":"<p>This document walks you through deploying the TriggerMesh AMI (beta) on the Amazon AWS platform.</p>  <p>Warning</p> <p>This installation method is meant to provide a fast mechanism to test TriggerMesh on AWS. It is not meant to be used in a production environment.</p>","location":"guides/installation-ami/"},{"title":"Pre-requisites","text":"<ul> <li>Amazon AWS account</li> </ul>","location":"guides/installation-ami/#pre-requisites"},{"title":"Creating the TriggerMesh EC2 Instance","text":"<p>Log in to the Amazon AWS console and create a new EC2 instance in the <code>us-west-1</code> region.</p> <p>Search for the TriggerMesh AMI in Community AMIs and select it for the EC2 instance.</p> <p></p> <p>The TriggerMesh AMI runs the TriggerMesh Cloud Native Integration Platform (and its dependencies) on top of a single node Kubernetes cluster using (k3s). The recommended instance type for the EC2 instance is <code>t2.2xlarge</code> or higher.</p> <p>The instance requires <code>32GiB</code> or higher as required.</p> <p>For the Knative services to be accessible externally over the HTTP protocol, configure the EC2 instance security group to allow HTTP traffic to the instance as shown in the screenshot below:</p> <p></p> <p>Launch the EC2 instance after specifying the SSH keypair for logging into the instance.</p>","location":"guides/installation-ami/#creating-the-triggermesh-ec2-instance"},{"title":"Logging into the instance","text":"<p>As the user <code>rancher</code>, SSH into the EC2 instance using its public IPv4 address.</p> <p></p>","location":"guides/installation-ami/#logging-into-the-instance"},{"title":"Verifying the deployment","text":"<p>After logging into the EC2 instance, verify that the <code>triggermesh-controller</code> and the <code>triggermesh-webhook</code> deployments are running successfully in the <code>triggermesh</code> namespace.</p> <pre><code>$ kubectl get deploy -n triggermesh\nNAME                     READY   UP-TO-DATE   AVAILABLE   AGE\ntriggermesh-controller   1/1     1            1           29m\ntriggermesh-webhook      1/1     1            1           29m\n</code></pre> <p>To check if Knative services are accessible externally, deploy Sockeye to the cluster.</p> <pre><code>$ kubectl apply -f https://github.com/n3wscott/sockeye/releases/download/v0.7.0/release.yaml\nservice.serving.knative.dev/sockeye configured\n</code></pre> <p>Now try to access the <code>sockeye</code> Knative service you just deployed using the URL listed by the following command:</p> <pre><code>$ kubectl get ksvc sockeye\nNAME      URL                                             LATESTCREATED   LATESTREADY     READY   REASON\nsockeye   http://sockeye.default.54.219.32.xxx.sslip.io   sockeye-00001   sockeye-00001   True\n</code></pre> <p>If the deployment was successful, the Sockeye webpage should load without any errors.</p> <p>You may now delete the <code>sockeye</code> Knative service:</p> <pre><code>$ kubectl delete ksvc sockeye\nservice.serving.knative.dev \"sockeye\" deleted\n</code></pre>","location":"guides/installation-ami/#verifying-the-deployment"},{"title":"Next steps","text":"<ul> <li>Getting started</li> </ul>","location":"guides/installation-ami/#next-steps"},{"title":"Using Helm","text":"<p>This chart installs the TriggerMesh Cloud Native Integration Platform on a Kubernetes cluster.</p>  <p>Note</p> <p>This is an alternative method of installation. A straight forward <code>kubectl apply</code> is actually all it takes to get TriggerMesh up and running.</p>","location":"guides/installation-helm/"},{"title":"TL;DR;","text":"<p>If you are familiar with Helm just go for it:</p> <pre><code>$ helm repo add triggermesh https://storage.googleapis.com/triggermesh-charts\n$ helm install -n triggermesh triggermesh triggermesh/triggermesh --create-namespace\n</code></pre>","location":"guides/installation-helm/#tldr"},{"title":"Prerequisites","text":"<ul> <li>Kubernetes 1.22+</li> <li>Helm 3.0+</li> <li>Knative v1.4.0+</li> </ul>","location":"guides/installation-helm/#prerequisites"},{"title":"Installing the Chart","text":"<p>Add the TriggerMesh chart repository to Helm:</p> <pre><code>$ helm repo add triggermesh https://storage.googleapis.com/triggermesh-charts\n</code></pre> <p>To install the chart with the release name <code>my-release</code>:</p> <pre><code>$ helm install --name my-release triggermesh/triggermesh\n</code></pre>  <p>Info</p> <p>If you face any issues please let us know about it and create an issue</p>  <p>The command deploys the TriggerMesh open source components in the default configuration. Refer to the configuration section for the complete list of parameters that can be specified to customize the deployment of the controller.</p>","location":"guides/installation-helm/#installing-the-chart"},{"title":"Uninstalling the Chart","text":"<p>To uninstall/delete the <code>my-release</code> deployment:</p> <pre><code>$ helm uninstall my-release\n</code></pre> <p>The Kubernetes resources associated with chart will be removed and the Helm release will be deleted.</p>","location":"guides/installation-helm/#uninstalling-the-chart"},{"title":"Configuration","text":"Parameter Description Default     <code>nameOverride</code> Override the name for controller resources <code>\"\"</code>   <code>fullnameOverride</code> Override the fullname for controller resources <code>\"\"</code>   <code>image.registry</code> Image registry name <code>gcr.io/triggermesh</code>   <code>image.tag</code> Image tag <code>.Chart.AppVersion</code>   <code>image.pullPolicy</code> Image pull policy <code>IfNotPresent</code>   <code>imagePullSecrets</code> Specify image pull secrets <code>[]</code>   <code>replicaCount</code> Number of replicas <code>1</code>   <code>rbac.create</code> Create RBAC resources <code>true</code>   <code>serviceAccount.create</code> Create service account for the controller <code>true</code>   <code>serviceAccount.annotations</code> Annotations to add to controller service account <code>{}</code>   <code>serviceAccount.name</code> Override the name for the service account <code>nil</code>   <code>podAnnotations</code> Annotations to add to the controller pod <code>{}</code>   <code>podSecurityContext</code> Security context for controller pods <code>{}</code>   <code>securityContext</code> Security context for controller containers <code>{}</code>   <code>resources</code> Resource requests/limits for the controller <code>{}</code>   <code>nodeSelector</code> Controller node selector <code>{}</code>   <code>tolerations</code> Tolerations for use with node taints <code>[]</code>   <code>affinity</code> Assign custom affinity rules to the controller pods <code>{}</code>   <code>webhook.podAnnotations</code> Annotations to add to the webhook pod <code>{sidecar.istio.io/inject: 'false'}</code>   <code>webhook.podSecurityContext</code> Security context for webhook pods <code>{}</code>   <code>webhook.securityContext</code> Security context for webhook containers <code>{}</code>   <code>webhook.resources</code> Resource requests/limits for the webhook <code>{}</code>   <code>webhook.nodeSelector</code> Webhook node selector <code>{}</code>   <code>webhook.tolerations</code> Tolerations for use with node taints <code>[]</code>   <code>webhook.affinity</code> Assign custom affinity rules to the webhook pods <code>{}</code>","location":"guides/installation-helm/#configuration"},{"title":"TriggerMesh Installation for Tanzu Community Edition","text":"<p>Tanzu Community Edition is a free and open source Kubernetes platform provided by VMware.</p>  <p>Tanzu Community Edition package repository versions</p> <p>The <code>knative-serving</code> version currently in the Tanzu Community Edition package repository is <code>0.22</code>, which does not meet TriggerMesh's minimum requirements. Additionally, at the time of writing, a <code>knative-eventing</code> package is not available in the repository. Follow the instructions below for installing a supported version of Knative.</p>","location":"guides/installation-tce/"},{"title":"Installation","text":"<p>This guide walks you through the deployment of Knative version 1.4.0 using YAML files. Please refer to the upstream Knative documentation for other deployment options.</p> <ol> <li> <p>Follow the Getting Started with Tanzu Community Edition installation instructions and create your Tanzu cluster on your platform of choice.</p> </li> <li> <p>Ensure you are in the context of your Tanzu cluster</p> </li> </ol> <pre><code>kubectl config use-context &lt;STANDALONE-CLUSTER-NAME&gt;-admin@&lt;STANDALONE-CLUSTER-NAME&gt;\n</code></pre> <ol> <li>Install Knative Serving following the Installing Knative Serving using YAML files instructions.</li> </ol> <pre><code>kubectl apply -f https://github.com/knative/serving/releases/download/knative-v1.4.0/serving-crds.yaml\nkubectl apply -f https://github.com/knative/serving/releases/download/knative-v1.4.0/serving-core.yaml\n</code></pre> <ol> <li>Wait until the pods have started before proceeding.</li> </ol> <pre><code>kubectl get pods -n knative-serving\n</code></pre> <ol> <li>The version of Contour provided with the Tanzu Community Edition package repository is older than the version of <code>knative-serving</code> we have installed, so install it from YAML as well.</li> </ol> <pre><code>kubectl apply -f https://github.com/knative-sandbox/net-contour/releases/download/knative-v1.4.0/contour.yaml\nkubectl apply -f https://github.com/knative-sandbox/net-contour/releases/download/knative-v1.4.0/net-contour.yaml\n</code></pre> <ol> <li>Verify the pods have started before proceeding.</li> </ol> <pre><code>kubectl get pods -n contour-external\nkubectl get pods -n contour-internal\n</code></pre> <ol> <li>Configure Knative Serving to use Contour by default by running the command:</li> </ol> <pre><code>kubectl patch configmap/config-network \\\n  --namespace knative-serving \\\n  --type merge \\\n  --patch '{\"data\":{\"ingress-class\":\"contour.ingress.networking.knative.dev\"}}'\n</code></pre> <ol> <li>Get the External IP address or CNAME by running the command:</li> </ol> <pre><code>kubectl --namespace contour-external get service envoy\n</code></pre> <ol> <li> <p>You will need to configure DNS following the Knative Serving DNS instructions for your requirements.</p> </li> <li> <p>Install Knative Eventing following the Installing Knative Eventing using YAML files instructions.</p> </li> </ol> <pre><code>kubectl apply -f https://github.com/knative/eventing/releases/download/knative-v1.4.2/eventing-crds.yaml\nkubectl apply -f https://github.com/knative/eventing/releases/download/knative-v1.4.2/eventing-core.yaml\n</code></pre> <ol> <li>Verify your installation.</li> </ol> <pre><code>kubectl get pods -n knative-eventing\n</code></pre> <p>At this point you have the TriggerMesh prerequisites installed and can continue with the standard installation instructions.</p>","location":"guides/installation-tce/#installation"},{"title":"TriggerMesh Installation","text":"<p>The TriggerMesh Cloud Native Integration Platform is composed of a set of APIs implemented as Kubernetes Custom Resource Definitions (CRDs) and a controller.</p> <p>Installing TriggerMesh consists of:</p> <ul> <li> Having a Kubernetes cluster up and running</li> <li> Having the Knative project deployed in that cluster</li> <li> Installing the TriggerMesh CRDs</li> <li> Installing the TriggerMesh controller</li> </ul> <p>These four steps are highlighted below. The first two steps (i.e Access to a Kubernetes cluster and installation of Knative are not described in details in this documentation). After completing those four steps you can validate your TriggerMesh installation.</p>  <p>Alternative Installation Options</p> <p>You may also use the TriggerMesh AMI to test the platform in a AWS EC2 instance. You may also use our Helm Chart.</p>","location":"guides/installation/"},{"title":"Pre-requisites","text":"<p>The Knative project is a dependency of TriggerMesh, install it using the instructions in the Knative documentation</p> <ul> <li>A Kubernetes cluster version <code>v1.22+</code></li> <li>Knative <code>v1.4.0+</code></li> </ul> <p>If you are using VMware's Tanzu Community Edition, please refer to the Installation for Tanzu Community Edition.</p>","location":"guides/installation/#pre-requisites"},{"title":"Install the CRDs","text":"<p>All TriggerMersh APIs are implemented as Kubernetes CRDs, which we need to create before deploying the controller. The following <code>kubectl apply</code> command will create all of the CRDs.</p> <pre><code>kubectl apply -f https://github.com/triggermesh/triggermesh/releases/latest/download/triggermesh-crds.yaml\n</code></pre>","location":"guides/installation/#install-the-crds"},{"title":"Install the controller","text":"<p>By default, the controller gets deployed in the <code>triggermesh</code> namespace. Deploy the controller with the following <code>kubectl apply</code> command:</p> <pre><code>kubectl apply -f https://github.com/triggermesh/triggermesh/releases/latest/download/triggermesh.yaml\n</code></pre>","location":"guides/installation/#install-the-controller"},{"title":"Verifying the installation","text":"<p>Upon successful creation of the CRDs and successful deployment of the controller you should see two pods running in the <code>triggermesh</code> namespace</p> <pre><code>$ kubectl get pods -n triggermesh\nNAME                                                   READY   STATUS    RESTARTS   AGE\ntriggermesh-controller-5cd97f4c8f-z6r2r                1/1     Running   0          57m\ntriggermesh-webhook-79cd8d6f5d-gf2lj                   1/1     Running   0          57m\n</code></pre> <p>All event sources and targets will be available to you as new API objects. For example, you can list all AWS related sources and targets with:</p> <pre><code>$ kubectl get crds |grep triggermesh |grep aws\nawscloudwatchlogssources.sources.triggermesh.io         2021-10-06T09:01:27Z\nawscloudwatchsources.sources.triggermesh.io             2021-10-06T09:01:27Z\nawscodecommitsources.sources.triggermesh.io             2021-10-06T09:01:27Z\nawscognitoidentitysources.sources.triggermesh.io        2021-10-06T09:01:27Z\nawscognitouserpoolsources.sources.triggermesh.io        2021-10-06T09:01:27Z\nawscomprehendtargets.targets.triggermesh.io             2021-10-06T09:01:28Z\nawsdynamodbsources.sources.triggermesh.io               2021-10-06T09:01:28Z\nawsdynamodbtargets.targets.triggermesh.io               2021-10-06T09:01:28Z\nawseventbridgetargets.targets.triggermesh.io            2021-10-06T09:01:28Z\nawskinesissources.sources.triggermesh.io                2021-10-06T09:01:28Z\nawskinesistargets.targets.triggermesh.io                2021-10-06T09:01:29Z\nawslambdatargets.targets.triggermesh.io                 2021-10-06T09:01:29Z\nawsperformanceinsightssources.sources.triggermesh.io    2021-10-06T09:01:29Z\nawss3sources.sources.triggermesh.io                     2021-10-06T09:01:29Z\nawss3targets.targets.triggermesh.io                     2021-10-06T09:01:29Z\nawssnssources.sources.triggermesh.io                    2021-10-06T09:01:30Z\nawssnstargets.targets.triggermesh.io                    2021-10-06T09:01:30Z\nawssqssources.sources.triggermesh.io                    2021-10-06T09:01:30Z\nawssqstargets.targets.triggermesh.io                    2021-10-06T09:01:30Z\n</code></pre> <p>A handy way to start exploring the API is to use <code>kubectl explain</code> on a specific <code>kind</code>, for example the AWS SQS source like below:</p> <pre><code>$ kubectl explain awssqssources\nKIND:     AWSSQSSource\nVERSION:  sources.triggermesh.io/v1alpha1\n\nDESCRIPTION:\n     TriggerMesh event source for Amazon SQS.\nFIELDS:\n   apiVersion   &lt;string&gt;\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind &lt;string&gt;\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata &lt;Object&gt;\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec &lt;Object&gt;\n     Desired state of the event source.\n\n   status   &lt;Object&gt;\n     Reported status of the event source.\n</code></pre>","location":"guides/installation/#verifying-the-installation"},{"title":"Using Kong with TriggerMesh","text":"<p>The Kong Ingress Controller can be configured as the network layer for TriggerMesh, enabling it to perform internal and external routing.</p> <p>The steps in this article guide you through the installation and configuration process, referring to external links when information beyond this scope is needed.</p>","location":"guides/kong-ingress/"},{"title":"Pre-requisite","text":"<p>Knative Serving needs to be installed on a Kubernetes cluster, follow the instructions at the documentation to install it, skipping the network layer.</p>  <p>Knative networking layer</p> <p>Kong is a networking layer option for Knative, you don't need to install any of the other choices at the project's documentation.</p>  <p>This guide was written using:</p> <ul> <li>Kubernetes <code>v1.21</code></li> <li>Knative <code>v1.4.0</code></li> <li>Kong Ingress Controller <code>2.3.1</code> (includes Kong <code>2.8</code>)</li> </ul>","location":"guides/kong-ingress/#pre-requisite"},{"title":"Install Kong Ingress Controller","text":"<p>Kong Ingress Controller can be installed using either the YAML manifest at their repository or helm charts.</p> <p>When using YAML, apply the provided manifest:</p> <pre><code>kubectl apply -f https://bit.ly/k4k8s\n</code></pre> <p>When using Helm follow their installation instructions.</p> <p>Once Kong is installed take note of the IP address or public CNAME of the <code>kong-proxy</code> service at the <code>kong</code> namespace.</p> <pre><code>kubectl -n kong get svc kong-proxy\n\nNAME         TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE\nkong-proxy   LoadBalancer   10.98.223.191   35.141.22.45     80:30119/TCP,443:31585/TCP   1m\n</code></pre> <p>In the example above the external IP address <code>35.141.22.45</code> was provisioned.</p>","location":"guides/kong-ingress/#install-kong-ingress-controller"},{"title":"Configure Kong Network Layer For Knative","text":"","location":"guides/kong-ingress/#configure-kong-network-layer-for-knative"},{"title":"Knative Ingress Class","text":"<p>We will configure Knative to use <code>kong</code> as the Ingress class:</p> <pre><code>kubectl patch configmap/config-network \\\n  --namespace knative-serving \\\n    --type merge \\\n      --patch '{\"data\":{\"ingress.class\":\"kong\"}}'\n</code></pre>","location":"guides/kong-ingress/#knative-ingress-class"},{"title":"Setup Knative Domain","text":"<p>Use the Kong Ingress external IP or CNAME to configure your the domain name resolution as explained at Knative's documentation.</p> <p>In this example we are not configuring a real DNS but using free wildcard domain tools like sslip.io or nip.io</p> <pre><code>kubectl patch configmap/config-domain \\\n  --namespace knative-serving \\\n  --type merge \\\n  --patch '{\"data\":{\"35.141.22.45.nip.io\":\"\"}}'\n</code></pre> <p>Once this is done, the setup is complete.</p>","location":"guides/kong-ingress/#setup-knative-domain"},{"title":"Try It","text":"","location":"guides/kong-ingress/#try-it"},{"title":"Test Connectivity","text":"<p>Send a request to the configured domain and make sure that a 404 response is returned:</p> <pre><code>curl -i http://35.141.22.45.nip.io/\nHTTP/1.1 404 Not Found\nDate: Wed, 11 May 2022 12:01:21 GMT\nContent-Type: application/json; charset=utf-8\nConnection: keep-alive\nContent-Length: 48\nX-Kong-Response-Latency: 0\nServer: kong/2.8.1\n\n{\"message\":\"no Route matched with those values\"}\n</code></pre> <p>The 404 response is expected since we have not configured any services yet.</p>","location":"guides/kong-ingress/#test-connectivity"},{"title":"Test Service","text":"<p>Deploy a Knative Service:</p> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: serving.knative.dev/v1\nkind: Service\nmetadata:\n  name: helloworld-go\n  namespace: default\nspec:\n  template:\n    spec:\n      containers:\n        - image: gcr.io/knative-samples/helloworld-go\n          env:\n            - name: TARGET\n              value: TriggerMesh\nEOF\n</code></pre> <p>Wait for the service to be ready, then get it's exposed URL. The URL should be a sub-domain of the configured CNAME:</p> <pre><code>kubectl get ksvc\nNAME            URL                                             LATESTCREATED         LATESTREADY           READY   REASON\nhelloworld-go   http://helloworld-go.default.35.141.22.45.nip.io   helloworld-go-00001   helloworld-go-00001   True\n</code></pre> <p>A call to the URL using a web browser or <code>curl</code> should return a successful text response:</p> <pre><code>curl -v http://helloworld-go.default.35.141.22.45.nip.io\nHTTP/1.1 200 OK\nContent-Type: text/plain; charset=utf-8\nContent-Length: 20\nConnection: keep-alive\nDate: Wed, 11 May 2022 12:10:26 GMT\nX-Kong-Upstream-Latency: 16\nX-Kong-Proxy-Latency: 1\nVia: kong/2.8.1\n\nHello TriggerMesh!\n</code></pre> <p>By inspecting the returned headers for the request above we can tell that it was proxied by Kong, latency headers being added to the response.</p>","location":"guides/kong-ingress/#test-service"},{"title":"Test Kong Plugins For Knative Services","text":"<p>Kong supports plugins to customize knative services requests and responses.</p> <p>First, let's create a KongPlugin resource:</p> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: configuration.konghq.com/v1\nkind: KongPlugin\nmetadata:\n  name: add-response-header\nconfig:\n  add:\n    headers:\n    - 'demo: injected-by-kong'\nplugin: response-transformer\nEOF\n</code></pre> <p>Next, we will update the Knative service created before and add an annotation to the template:</p> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: serving.knative.dev/v1\nkind: Service\nmetadata:\n  name: helloworld-go\n  namespace: default\nspec:\n  template:\n    metadata:\n      annotations:\n        konghq.com/plugins: add-response-header\n    spec:\n      containers:\n        - image: gcr.io/knative-samples/helloworld-go\n          env:\n            - name: TARGET\n              value: TriggerMesh\nEOF\n</code></pre>  <p>Kubernetes namespace</p> <p>Note that the annotation <code>konghq.com/plugins</code> is not added to the Service definition itself but to the <code>spec.template.metadata.annotations</code>.</p>  <p>Let's make the request again:</p> <pre><code>curl -i http://helloworld-go.default.35.241.22.45.nip.io/\nHTTP/1.1 200 OK\nContent-Type: text/plain; charset=utf-8\nContent-Length: 20\nConnection: keep-alive\nDate: Wed, 11 May 2022 13:48:53 GMT\ndemo:  injected-by-kong\nX-Kong-Upstream-Latency: 3\nX-Kong-Proxy-Latency: 0\nVia: kong/2.8.1\n\nHello TriggerMesh!\n</code></pre> <p>As we can see, the response has the <code>demo</code> header injected.</p>","location":"guides/kong-ingress/#test-kong-plugins-for-knative-services"},{"title":"Using Kuma Service Mesh with TriggerMesh","text":"<p>Kuma can be configured as a Service Mesh for TriggerMesh, providing security, observability and routing among other features.</p> <p>The steps in this article guide you through the installation and configuration process, referring to external links when information beyond this scope is needed.</p>","location":"guides/kuma/"},{"title":"Pre-requisites","text":"<p>Knative Serving needs to be installed on a Kubernetes cluster. We will also install Kong as the networking layer for Knative Serving since it is an ideal companion for Kuma.</p> <p>To install Knative Serving with Kong follow our guide at the documentation.</p> <p>This guide was written using:</p> <ul> <li>Kubernetes <code>v1.21</code></li> <li>Knative <code>v1.4.0</code></li> <li>Kong Ingress Controller <code>2.3.1</code> (includes Kong <code>2.8</code>)</li> <li>Kuma <code>v1.5</code></li> </ul>","location":"guides/kuma/#pre-requisites"},{"title":"Install Kuma Service Mesh","text":"<p>Kuma can be installed using their command line tool. Follow the instructions at the documentation to install <code>kumactl</code>.</p> <p>Once installed execute this command to deploy Kuma Service Mesh in the cluster.</p> <pre><code>kumactl install control-plane --version=1.5.0 --env-var KUMA_RUNTIME_KUBERNETES_VIRTUAL_PROBES_ENABLED=false| kubectl apply -f -\n</code></pre>  <p>Kuma Virtual Probes</p> <p>The command provided at this guide disables Kuma Virtual Probes. If you have an existing Kuma installation make sure virtual probes are disabled.</p>  <p>Once Kuma Service Mesh is installed you should see the pod running in the <code>kuma-system</code> namespace:</p> <pre><code>kumactl -n kuma-system get pods\nNAME                                 READY   STATUS    RESTARTS   AGE\nkuma-control-plane-bd98c89dc-kwj97   1/1     Running   0          19s\n</code></pre>","location":"guides/kuma/#install-kuma-service-mesh"},{"title":"Add Kong to Kuma Mesh","text":"<p>We will add the label <code>kuma.io/sidecar-injection</code> to the kong namespace, so kong will be running in the mesh:</p> <pre><code>kubectl label namespace kong kuma.io/sidecar-injection=enabled\n</code></pre> <p>The kong-ingress deployment needs the following annotation to be running as a Kuma gateway.</p> <pre><code>annotations: \n  kuma.io/gateway: enabled \n</code></pre> <p>Make sure that the annotation exists by issuing this command:</p> <pre><code>kubectl -n kong patch deploy ingress-kong --type='json' -p='[{\"op\": \"add\", \"path\": \"/spec/template/metadata/annotations/kuma.io~1gateway\", \"value\":\"enabled\"}]'\n</code></pre> <p>We should restart kong to be running in the mesh and acting as the kuma gateway.</p> <pre><code>kubectl -n kong rollout restart deployment ingress-kong\n</code></pre> <p>After the restart the respawned Kong pods will be running inside the Kuma mesh.</p>","location":"guides/kuma/#add-kong-to-kuma-mesh"},{"title":"Add Knative Serving to Kuma Mesh","text":"<p>We will add the label <code>kuma.io/sidecar-injection</code> to the knative-serving namespace, so knative-serving will be running in the mesh:</p> <pre><code>kubectl label namespace knative-serving kuma.io/sidecar-injection=enabled\n</code></pre>","location":"guides/kuma/#add-knative-serving-to-kuma-mesh"},{"title":"Configure Kuma service Mesh to Strict mode","text":"<p>Knative needs some pre-requisites to be able to work in the Kuma Mesh with mTLS set to <code>STRICT</code>. We are going to add some port-exclusions</p> <pre><code>kubectl -n knative-serving patch deploy webhook --type='json' -p='[{\"op\": \"add\", \"path\": \"/spec/template/metadata/annotations/traffic.kuma.io~1exclude-inbound-ports\", \"value\":\"8443\"}]'\n</code></pre> <pre><code>kubectl -n knative-serving patch deploy domainmapping-webhook --type='json' -p='[{\"op\": \"add\", \"path\": \"/spec/template/metadata/annotations/traffic.kuma.io~1exclude-inbound-ports\", \"value\":\"8443\"}]'\n</code></pre> <pre><code>kubectl -n knative-serving patch deploy autoscaler --type='json' -p='[{\"op\": \"add\", \"path\": \"/spec/template/metadata/annotations/traffic.kuma.io~1exclude-inbound-ports\", \"value\":\"8080\"}]'\n</code></pre> <pre><code>kubectl -n knative-serving patch deploy activator --type='json' -p='[{\"op\": \"add\", \"path\": \"/spec/template/metadata/annotations/traffic.kuma.io~1exclude-inbound-ports\", \"value\":\"8012\"}]'\n</code></pre> <pre><code>kubectl -n knative-serving patch deploy activator --type='json' -p='[{\"op\": \"add\", \"path\": \"/spec/template/metadata/annotations/traffic.kuma.io~1exclude-outbound-ports\", \"value\":\"8080\"}]'\n</code></pre> <p>Now we should restart the only two pods that we haven't added the port-exclusion to add them to the mesh like the rest:</p> <pre><code>kubectl -n knative-serving rollout restart deployment controller domain-mapping\n</code></pre> <pre><code>kubectl -n knative-serving get pods\nNAME                                     READY   STATUS    RESTARTS   AGE\nactivator-554875ff7c-hqb8t               2/2     Running   0          69s\nautoscaler-698589b568-qrjk9              2/2     Running   0          78s\ncontroller-6956c9bb6-spqpm               2/2     Running   0          57s\ndomain-mapping-8548c6cfdf-m2m66          2/2     Running   0          57s\ndomainmapping-webhook-7ff76f9bfb-6jdgz   2/2     Running   0          81s\nwebhook-564974959d-vpd42                 2/2     Running   0          86s\n</code></pre> <p>Now the knative-serving pods are running in the mesh and ready to work with mtls Strict.</p>","location":"guides/kuma/#configure-kuma-service-mesh-to-strict-mode"},{"title":"Configure Kuma mTLS to Strict mode","text":"<p>We are going to modify the Kuma Mesh to enable the mTLS with Strict mode:</p> <pre><code>kubectl apply -f - &lt;&lt;EOF                            \napiVersion: kuma.io/v1alpha1\nkind: Mesh\nmetadata:\n  name: default\nspec:\n  mtls:\n    enabledBackend: ca-1\n    backends:\n      - name: ca-1\n        type: builtin\n        mode: STRICT\nEOF\n</code></pre>","location":"guides/kuma/#configure-kuma-mtls-to-strict-mode"},{"title":"Test Service","text":"<p>Deploy a Knative Service:</p>  <p>Knative Services</p> <p>The knative services also needs port-exclusions</p>  <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: serving.knative.dev/v1\nkind: Service\nmetadata:\n  name: helloworld-go\n  namespace: default\nspec:\n  template:\n    metadata:\n      annotations:\n        traffic.kuma.io/exclude-inbound-ports: \"8012\"\n    spec:\n      containers:\n        - image: gcr.io/knative-samples/helloworld-go\n          env:\n            - name: TARGET\n              value: Go Sample v1\nEOF\n</code></pre> <p>Wait for the service to be ready, then get it's exposed URL. The URL should be a sub-domain of the configured CNAME:</p> <pre><code>kubectl get ksvc\nNAME URL LATESTCREATED LATESTREADY READY REASON\nhelloworld-go   http://helloworld-go.default.10.101.62.158.nip.io   helloworld-go-00001   helloworld-go-00001   True \n</code></pre> <p>A call to the URL using a web browser or <code>curl</code> should return a successful text response:</p> <pre><code>curl -v http://helloworld-go.default.10.101.62.158.nip.io\n*   Trying 10.101.62.158:80...\n* Connected to helloworld-go.default.10.101.62.158.nip.io (10.101.62.158) port 80 (#0)\n&gt; GET / HTTP/1.1\n&gt; Host: helloworld-go.default.10.101.62.158.nip.io\n&gt; User-Agent: curl/7.81.0\n&gt; Accept: */*\n&gt; \n* Mark bundle as not supporting multiuse\n&lt; HTTP/1.1 200 OK\n&lt; Content-Type: text/plain; charset=utf-8\n&lt; Content-Length: 20\n&lt; Connection: keep-alive\n&lt; Date: Wed, 30 Mar 2022 11:22:29 GMT\n&lt; X-Kong-Upstream-Latency: 1\n&lt; X-Kong-Proxy-Latency: 1\n&lt; Via: kong/2.7.1\n&lt; \nHello Go Sample v1!\n* Connection #0 to host helloworld-go.default.10.101.62.158.nip.io left intact\n</code></pre>","location":"guides/kuma/#test-service"},{"title":"Kuma UI","text":"<p>Kuma includes a dashboard that shows information about mesh, gateway and proxies status. You can use <code>kubectl</code> to forward the exposed port locally.</p> <pre><code>kubectl port-forward svc/kuma-control-plane -n kuma-system 5681:5681\n</code></pre> <p>To access the UI opening http://localhost:5681/gui with a web browser:</p> <p></p>","location":"guides/kuma/#kuma-ui"},{"title":"Structured Logging","text":"<p>TriggerMesh components communicate their internal events through a flexible logging system. Output format, structure, and granularity are adjustable through a configuration file. Information produced by the TriggerMesh logging system can be collected and stored by a centralized log management platform, such as the ELK stack or AWS CloudWatch, and used for further processing.</p>","location":"guides/observability-logging/"},{"title":"Logging configuration","text":"","location":"guides/observability-logging/#logging-configuration"},{"title":"Log levels","text":"<p>Log level configuration allows you to adjust the amount and detail of the logs produced by the TriggerMesh components. Logging configuration parameters are set through the configmap in the system namespace and applied on TriggerMesh components across all cluster namespaces.</p> <p>Since TriggerMesh core components are heavily based on the Knative libraries, logging also complies with the upstream configuration approach described here.</p>","location":"guides/observability-logging/#log-levels"},{"title":"Level definitions","text":"<p>Log levels supported by TriggerMesh components are:</p> <ul> <li><code>debug</code> - fine-grained debugging</li> <li><code>info</code> - normal logging</li> <li><code>warn</code> - unexpected but non-critical errors</li> <li><code>error</code> - critical errors; unexpected during normal operation</li> <li><code>dpanic</code> - in debug mode, trigger a panic (crash)</li> <li><code>panic</code> - trigger a panic (crash)</li> <li><code>fatal</code> - immediately exit with exit status 1 (failure)</li> </ul> <p>Each logging level in this hierarchy includes all levels below, i.e. setting the <code>error</code> level will silence the output tagged as debug, info, and warn, but will keep error, panic, and fatal. Most information is produced at the <code>debug</code> level - it can come in handy during integration development and tests. In the <code>error</code> logging level nothing but errors that require the operator's attention is emitted. By default, all components are set to the <code>info</code> level that provides general initialization information and some additional outputs that may be useful for the operator.</p>","location":"guides/observability-logging/#level-definitions"},{"title":"Configuring log levels","text":"<p>TriggerMesh components log levels are currently set from the <code>config-logging</code> configmap in <code>triggermesh</code> namespace. To update the component\u2019s logging level, the configuration must be either edited in place by executing this command:</p> <pre><code>kubectl -n triggermesh edit configmap config-logging\n</code></pre> <p>Or it can be changed in the project\u2019s source and applied with:</p> <pre><code>kubectl apply -f config-logging.yaml\n</code></pre> <p>Components logging configuration is propagated through the containers environment and picked up at the initialization step, hence switching between levels may require resource re-creation.</p> <p>The sample configuration fragment below sets the individual log levels for some of the TriggerMesh resources:</p> <pre><code># Logging level overrides for the TriggerMesh control plane.\nloglevel.triggermesh-controller: error\nloglevel.triggermesh-webhook: error\n\n# Logging level overrides for TriggerMesh components.\n# The name of the logger is the Kubernetes kind of the component.\nloglevel.awss3target: debug\nloglevel.ibmmqsource: debug\nloglevel.transformation: debug\n</code></pre> <p>After we apply this configuration, TriggerMesh controller and webhook will switch to the <code>error</code> level, while all newly created AWS S3 targets, IBM MQ sources, and Transformations will have a <code>debug</code> logging level.</p>","location":"guides/observability-logging/#configuring-log-levels"},{"title":"Telemetry Metrics","text":"<p>Metrics allow operators to understand the internal state of a system by observing its outputs.</p> <p>In TriggerMesh, telemetry is achieved by exposing a variety of time-based numeric measurements \u2014 also referred to as time-series \u2014 that can be collected and analyzed by third-party monitoring solutions.</p> <p>This guide provides an overview of the nature and format of the telemetry metrics exposed by the TriggerMesh platform, as well as detailed examples of approaches for collecting and analyzing them.</p>","location":"guides/observability-metrics/"},{"title":"Exposed Telemetry Data","text":"","location":"guides/observability-metrics/#exposed-telemetry-data"},{"title":"Metrics Categories","text":"<p>Here is an overview of the types of metrics that are exposed by TriggerMesh components. The list is deliberately broad and generic, as some categories of metrics may only be exposed by certain types of components.</p> <ul> <li>Processing of events<ul> <li>Successes and errors</li> <li>Latency distribution</li> </ul> </li> <li>Delivery of events<ul> <li>Successes and errors</li> <li>Latency distribution</li> </ul> </li> <li>Software runtime<ul> <li>Heap memory usage</li> <li>Garbage collection</li> </ul> </li> </ul> <p>Later in this document, we will explore how metrics in these different categories can be collected, analyzed and visualized.</p>","location":"guides/observability-metrics/#metrics-categories"},{"title":"Data Model","text":"<p>Metrics are exposed by TriggerMesh in a line-oriented text-based format popularized by the Prometheus open source monitoring toolkit.</p> <p>A Prometheus metric is typically represented as a single line of UTF-8 characters, optionally prepended with a <code>HELP</code> and a <code>TYPE</code> comment lines, starting with the name of the metric and ending with its value:</p> <pre><code># HELP event_processing_success_count The number of events successfully processed\n# TYPE event_processing_success_count counter\nevent_processing_success_count{event_source=\"my.cloud.storage\", event_type=\"object.created\"} 129389\n</code></pre> <p>The <code>HELP</code> comment provides a description of what the metric represents, whereas the <code>TYPE</code> comment carries information about the type of the metric (one of the four core metric types offered by Prometheus).</p> <p>As illustrated in the example above, the metric name may be directly followed by a list of comma-separated key-value pairs between curly brackets called labels. Labels allow differentiating the characteristics of what is being measured. Each unique combination of labels identifies a particular dimension of a metric. Labels, and metric dimensions by extension, vary from metric to metric.</p>","location":"guides/observability-metrics/#data-model"},{"title":"Enabling Metrics","text":"<p>By default TriggerMesh does not enable any metrics backend. Observability of TriggerMesh can be configured  via the <code>config-observability</code> ConfigMap object.</p> <p>For example, the following ConfigMap object enables the Prometheus metrics exporter in all TriggerMesh components:</p> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: config-observability\n  namespace: triggermesh\ndata:\n  metrics.backend-destination: prometheus\n</code></pre> <p>For a description of the configuration settings which are currently supported, please refer to the  <code>observability.yaml</code> manifest files inside the Knative Eventing source repository.</p>","location":"guides/observability-metrics/#enabling-metrics"},{"title":"Access to Metrics","text":"<p>Every TriggerMesh component exposes a set of telemetry metrics on the local HTTP endpoint <code>:9092/metrics</code>. Available measurements can be retrieved via a simple <code>GET</code> request. The returned values are an instant view of each measurement at the time of the request.</p> <p>This model is particularly suitable for a pull-based retrieval of metrics (\"scrape\") on a fixed interval by monitoring software, and for storage in a time-series database. Prometheus itself is a popular choice for this job, as it includes both a server for scraping telemetry metrics, and a time-series database optimized for the Prometheus data model. </p> <p></p> <p>Most of the available metrics fall into the categories described previously in this document, whenever applicable based on the type of component. Some components may expose additional, application-specific metrics. The data model presented in the previous section makes these metrics easily discoverable by consumers.</p>","location":"guides/observability-metrics/#access-to-metrics"},{"title":"Collection and Analysis with Prometheus and Grafana","text":"<p>This section provides examples of configurations for collecting metrics from TriggerMesh components using the Prometheus monitoring toolkit, and visualizing them using the observability platform Grafana.</p> <p>The rest of this document assumes that Prometheus and Grafana are both available in the Kubernetes cluster where TriggerMesh is deployed.</p>  <p>Tip</p> <p>If you don't already have Prometheus and Grafana set up in your TriggerMesh cluster, we recommend installing a pre-configured Prometheus-Grafana stack using the Helm application manager for Kubernetes by executing the commands below:</p> <pre><code>helm repo add prometheus-community https://prometheus-community.github.io/helm-charts\nhelm repo update\nhelm install -n monitoring prometheus-stack prometheus-community/kube-prometheus-stack\n</code></pre> <p>Detailed installation instructions are available in the <code>kube-prometheus-stack</code> chart's documentation.</p>","location":"guides/observability-metrics/#collection-and-analysis-with-prometheus-and-grafana"},{"title":"Scraping Metrics via Prometheus","text":"<p>The Prometheus Operator \u2014 which is included in the aforementioned kube-prometheus Stack and manages most Prometheus installations on Kubernetes \u2014 allows configuring Prometheus' scrape targets using familiar Kubernetes API objects.</p> <p>The manifest below contains a PodMonitor that instructs Prometheus to automatically discover and scrape TriggerMesh components:</p> <pre><code>apiVersion: monitoring.coreos.com/v1\nkind: PodMonitor\nmetadata:\n  name: triggermesh-components\n  namespace: monitoring\nspec:\n  selector:\n    matchLabels:  # (1)\n      app.kubernetes.io/part-of: triggermesh\n  namespaceSelector:  # (2)\n    any: true\n  podMetricsEndpoints:  # (3)\n  - port: metrics\n  - port: user-port\n    relabelings:\n    - action: replace\n      targetLabel: __address__\n      sourceLabels:\n      - __meta_kubernetes_pod_ip\n      replacement: $1:9092\n  jobLabel: app.kubernetes.io/name  # (4)\n</code></pre> <ol> <li>Selects all targets (Pods) that are labeled as being managed by TriggerMesh.</li> <li>Looks up targets (Pods) matching the above selector in all Kubernetes namespace.</li> <li>For targets that matched the above selectors, either scrape the port named <code>metrics</code> if it exists, or fall back to     the TCP port <code>9092</code>.</li> <li>Sets the value of the <code>job</code> label in collected metrics to the name of the component.</li> </ol> <p>After applying this configuration to the Kubernetes cluster using the <code>kubectl apply -f</code> command, a list of targets matching the name of the PodMonitor should be reported by Prometheus with the state <code>UP</code>.</p>  <p>Tip</p> <p>If you installed Prometheus via the <code>kube-prometheus-stack</code> Helm chart \u2014 as suggested in the introduction to this section \u2014 you should be able to forward the local port <code>9090</code> to the Prometheus instance running in the Kubernetes cluster:</p> <pre><code>kubectl -n monitoring port-forward svc/kube-prometheus-stack-prometheus 9090\n</code></pre> <p>Then, open your web browser at http://localhost:9090/targets.</p>  <p></p>","location":"guides/observability-metrics/#scraping-metrics-via-prometheus"},{"title":"Visualizing Metrics in a Grafana Dashboard","text":"<p>By combining the visualization power of Grafana with the query language of Prometheus, we are able to analyze trends in collected metrics using different types of graphs and charts.</p> <p>In the following example, we will create a dashboard like the one below where we analyze the latency distribution of a given measure \u2014 such as the processed or delivered events \u2014 over a selected period of time.</p> <p></p>  <p>Tip</p> <p>If you installed Grafana via the <code>kube-prometheus-stack</code> Helm chart \u2014 as suggested in the introduction to this section \u2014 you should be able to forward the local port <code>3000</code> to the Grafana instance running in the Kubernetes cluster:</p> <pre><code>kubectl -n monitoring port-forward svc/kube-prometheus-stack-grafana 3000:80\n</code></pre> <p>Then, open your web browser at http://localhost:3000.</p>","location":"guides/observability-metrics/#visualizing-metrics-in-a-grafana-dashboard"},{"title":"Number of Events Grouped by Latency Bucket","text":"<p>In this panel, we will use a bar gauge to display the distribution of the time spent by a component processing events over a selected period of time, organized in latency buckets.</p> <p>The chart will be based on a Prometheus metric of type histogram with a pre-configured bucket distribution in milliseconds, defined by TriggerMesh as follows:</p> <pre><code># HELP event_processing_latencies Time spent in the CloudEvents handler processing events\n# TYPE event_processing_latencies histogram\n</code></pre> <p>In a histogram metric, cumulative counters for each bucket are exposed as sub-metrics of the main histogram metric, with _bucket appended to the name, and a <code>le</code> (\"less than or equal\") label indicating the upper bound of the bucket, such as in the example below:</p> <pre><code>event_processing_latencies_bucket{le=\"1\"} 0\nevent_processing_latencies_bucket{le=\"2\"} 0\nevent_processing_latencies_bucket{le=\"5\"} 1541\nevent_processing_latencies_bucket{le=\"10\"} 6161\nevent_processing_latencies_bucket{le=\"20\"} 6776\nevent_processing_latencies_bucket{le=\"50\"} 6865\nevent_processing_latencies_bucket{le=\"100\"} 6868\n</code></pre> <p>We can start by charting the evolution of the raw counters corresponding to each latency bucket over time in a standard time series graph, before switching to bar gauges, in order to understand the metric's trend:</p> <pre><code>sum(\n  event_processing_latencies_bucket\n) by (le)\n</code></pre>  <p>Warning</p> <p>Always select the Heatmap format while working with Prometheus metrics of type <code>histogram</code>. This enables Grafana's intrinsic knowledge about Prometheus histograms, which results in buckets being sorted per <code>le</code> value and distinctive counts being shown for each bucket as one would expect.</p>  <p></p> <p>We can observe that counter values are cumulative. Some buckets have a steeper evolution than others, which already hints at a trend about the distribution of the component's processing latency.</p> <p>When switching from a time series chart to a bar gauge chart, we will want the summary value to correspond to the aggregation of all events processed in a given latency bucket. We could be tempted to simply summarize totals as the last value per bucket in the selected time period, but </p> <ol> <li>This would show the overall total of events processed by the component prior to the end of the time period, not the    total of events processed during the selected time period.</li> <li>This might result in skewed calculations if the counters were reset during that time period, as illustrated at the    very end of the range in the previous graph. Such situation isn't unusual and could occur for different reasons, such    as roll outs of new versions, horizontal scaling, Pod relocations, etc.</li> </ol> <p>We will instead calculate the increase in the time series in the selected time range using a query function which adjusts for breaks in monotonicity, such as counter resets:</p> <pre><code>sum(\n  increase(event_processing_latencies_bucket[$__range])\n) by (le)\n</code></pre> <p></p> <p>Selecting <code>Bar Gauge</code> in the list of visualizations instead of <code>Time Series</code> now shows a histogram which summary values accurately represent the number of events processed in each latency bucket for the selected time period:</p> <p></p> <p>The visualization options can be adjusted to one's preferences in order to obtain the desired result:</p> <p></p>","location":"guides/observability-metrics/#number-of-events-grouped-by-latency-bucket"},{"title":"Rate of Processed Events by Latency Bucket","text":"<p>In this panel, we will use a time series graph to display the rate of events processed by a component over time, and distributed in latency buckets.</p> <p>The chart will be based on the same Prometheus metric as in the previous example.</p> <p>This time around, we will stick with the default <code>Time Series</code> visualization, but replace the <code>increase()</code> function used previously with the <code>irate()</code> function:</p> <pre><code>sum(\n  irate(event_processing_latencies_bucket[$__rate_interval])\n) by (le)\n</code></pre> <p>The interval used to calculate the rate of change of the metric can be either</p> <ol> <li>Selected manually using an explicit time duration such as \"[3m]\".</li> <li>Delegated to Grafana using Grafana's <code>$__rate_interval</code> variable, which calculates an optimal value    based on the number of data points in the graph.</li> </ol> <p>The result of this calculation is a series of metrics (\"instant vectors\"), each representing the number of events per second processed by the component over time in a given latency bucket:</p> <p></p>","location":"guides/observability-metrics/#rate-of-processed-events-by-latency-bucket"},{"title":"90th Percentile of the Processing Latency Over Time","text":"<p>In this panel, we will use a time series graph to display the 90th percentile of processing durations of events handled by a component over time. This measure indicates the longest time it took to process an event, for 90% of all the events processed during each time interval on the graph.</p> <p>The chart will be based on the same Prometheus metric as in the previous example.</p> <p>We can reuse the query from the previous example, and pass it to the <code>histogram_quantile()</code> function with the desired quantile:</p> <pre><code>histogram_quantile(0.90,\n  sum(\n    irate(event_processing_latencies_bucket[$__rate_interval])\n  )\n) by (le)\n</code></pre> <p>The result of this calculation is a single metric (\"instant vector\"). An interesting exercise could be to compare this graph with the rate of processed events measured in the previous example, and observe whether or not spikes in the 90th latency percentile can be correlated with higher processing rates:</p> <p></p>","location":"guides/observability-metrics/#90th-percentile-of-the-processing-latency-over-time"},{"title":"Additional Notes and Takeaways","text":"<p>It can be noted that, in the previous examples, we generated three valuable types of visualizations from a single metric, by simply changing Prometheus queries to perform different types of calculations/aggregations.</p> <p>Thanks to the power of time series and the multi-dimensional aspect of Prometheus metrics, we could explore other types of visualizations based on this same metric, for example by filtering or grouping metrics by labels.</p> <p>For instance, the following query could be used to graph the event processing rate over time broken down by event type:</p> <pre><code>sum(\n  irate(event_processing_latencies_count[$__rate_interval])\n) by (event_type)\n</code></pre> <p>This other query could be used to graph the event processing rate over time for a specific event type:</p> <pre><code>sum(\n  irate(event_processing_latencies_count{event_type=\"object.created\"}[$__rate_interval])\n)\n</code></pre> <p>The same idea can be applied when it comes to visualizing metrics pertaining to a specific instance of a given component, or for example to all instances of that component within a specific Kubernetes namespace. There is a large amount of possibilities to be explored, the only limit is the choice of labels available for each metric. </p> <p></p>","location":"guides/observability-metrics/#additional-notes-and-takeaways"},{"title":"Observability","text":"<p>The TriggerMesh platform provides operational and usage insight into its various components via two types of instrumentations:</p> <ul> <li>Structured logging</li> <li>Telemetry metrics</li> </ul> <p>This observability data can be consumed and visualized using industry standard monitoring solutions.</p>","location":"guides/observability/"},{"title":"Using TIL","text":"<p>The TriggerMesh Integration Language (TIL) is a configuration language based on the HCL syntax which provides a user-friendly interface for describing TriggerMesh Bridges.</p>  <p>Use TIL with the TriggerMesh Platform</p> <p>The TriggerMesh Integration Language is easily usable with the <code>til</code> CLI which helps you generate the manifests describing your event-driven application. It is the perfect companion to the TriggerMesh controller. Go to the complete documentation for the detailed specification.</p>","location":"guides/tilgettingstarted/"},{"title":"Installation","text":"<p>Download the CLI from the GitHub release page. For example on Linux x86_64 architecture do:</p> <pre><code>wget https://github.com/triggermesh/til/releases/download/v0.1.0/til_v0.1.0_linux_amd64\n</code></pre> <p>Put it in your <code>PATH</code> and make the binary executable.</p> <pre><code>mv til_v0.1.0_linux_amd64 /usr/local/bin/til\nchmod +x /usr/local/bin/til\n</code></pre> <p>Check that you can run the command.</p> <pre><code>$ til -h\nInterpreter for TriggerMesh's Integration Language.\n\nUSAGE:\n    til &lt;command&gt;\n\nCOMMANDS:\n    generate     Generate Kubernetes manifests for deploying a Bridge.\n    validate     Validate a Bridge description.\n    graph        Represent a Bridge as a directed graph in DOT format.\n</code></pre> <p>For the complete usage reference go to the TIL documentation.</p>","location":"guides/tilgettingstarted/#installation"},{"title":"Example","text":"<p>With the <code>til</code> CLI installed you are ready to write your first Bridge.</p> <p>In this guide we take the simple example of a point to point connection between a GitHub repository and a Splunk index. This assumes:</p> <ul> <li>We are using a sample repository on GitHub called <code>triggermesh/bridges</code>. Pick one that you have access to</li> <li>We are using a GitHub token stored as a Kubernetes secret called <code>github-source-tokens</code>. See the GitHub secret class for details.</li> <li>We are using Splunk credentials stored as a Kubernettes secret called <code>my_splunk_credentials</code>. See the Splunk secret class for details.</li> <li>We want to receive all events related to <code>push</code> and <code>pull_requests</code> actions in our repository.</li> </ul> <p>Using the TIL syntax you may write this point to point connection in a file called <code>til-demo.brg.hcl</code>:</p> <pre><code>bridge \"github_to_splunk\" { }\n\n/* Event source block\n   Sources events from a GitHub repository\n*/\nsource github \"my_repo\" {\n  owner_and_repository = \"triggermesh/bridges\"\n  tokens = secret_name(\"github-source-tokens\")\n\n  event_types = [\n    \"push\",\n    \"pull_request\",\n  ]\n\n  to = target.github_archive_index\n}\n\n/* Event target block\n   Receives events and stores them into a Splunk index\n*/\ntarget splunk \"github_archive_index\" {\n  endpoint = \"https://prd-x-12345.splunkcloud.com\"\n  auth = secret_name(\"my-splunk-credentials\")\n\n  index = \"github_events\"\n}\n</code></pre> <p>To generate the manifest in YAML you issue the following command:</p> <pre><code>$ til generate ../til-demo.brg.hcl --yaml\napiVersion: targets.triggermesh.io/v1alpha1\nkind: SplunkTarget\nmetadata:\n  labels:\n    bridges.triggermesh.io/id: github_to_splunk\n  name: github-archive-index\nspec:\n  endpoint: https://prd-x-12345.splunkcloud.com\n  index: github_events\n  token:\n    valueFromSecret:\n      key: hec_token\n      name: my-splunk-credentials\n---\napiVersion: sources.knative.dev/v1alpha1\nkind: GitHubSource\nmetadata:\n  labels:\n    bridges.triggermesh.io/id: github_to_splunk\n  name: my-repo\nspec:\n  accessToken:\n    secretKeyRef:\n      key: access_token\n      name: github-source-tokens\n  eventTypes:\n  - push\n  - pull_request\n  ownerAndRepository: triggermesh/bridges\n  secretToken:\n    secretKeyRef:\n      key: webhook_secret\n      name: github-source-tokens\n  sink:\n    ref:\n      apiVersion: targets.triggermesh.io/v1alpha1\n      kind: SplunkTarget\n      name: github-archive-index\n</code></pre> <p>With these manifests ready you can deploy them easily. For example using kapp.</p>  <p>Deployment options for TIL</p> <p>TIL is a specification language and a CLI to help you author Kubernetes objects. It does not dictate how you deploy your Bridge. You may choose <code>helm</code>, <code>kapp</code> or simply <code>kubectl</code>. Check the deployment samples.</p>","location":"guides/tilgettingstarted/#example"},{"title":"Generate the diagram of your event flow","text":"<p>If you want to generate a diagram of your flow, you can create a <code>dot</code> file using <code>til</code>.</p> <pre><code>til graph til-demo.brg.hcl &gt; til-demo.dot\ndot -Tpng til-demo.dot &gt; til-demo.png\n</code></pre>  <p>Info</p> <p>To visualize your event flow you may install Graphviz on your local machine or use the on-line viewer.</p>  <p>The PNG file created will look similar to the one below.</p> <p></p>","location":"guides/tilgettingstarted/#generate-the-diagram-of-your-event-flow"},{"title":"Writing an Event Filter","text":"<p>Filters are an important part of TriggerMesh's event routing mechanism. They allow for filtering events based on the content of the payload. This content-based event filtering is expressed with Google's Common Expression Language within the TriggerMesh <code>Filter</code> API specification.</p>  <p>Tip</p> <p>You can verify that the API is available with the following command:</p> <p><pre><code>$ kubectl get crd filters.routing.triggermesh.io\nNAME                             CREATED AT\nfilters.routing.triggermesh.io   2021-10-06T09:01:33Z\n</code></pre> You can also explore the API specification with: <pre><code>$ kubectl explain filter\n</code></pre></p>  <p>To demonstrate filtering in TriggerMesh we are going to create the event flow depicted in the diagram below. Two sources of kind <code>PingSource</code> will send events on a repeating schedule, and only the events which pass the filter will be displayed on the final event target. The target is the Sockeye application, a microservice which displays the content of a CloudEvent.</p> <p></p> <p>Let's create all the required objects:</p> <ul> <li> The <code>sockeye</code> target which serves as an event display.</li> <li> Two <code>PingSource</code> to produce events.</li> <li> The <code>Filter</code> to discard unwanted events.</li> </ul>","location":"guides/writingafilter/"},{"title":"Event display","text":"<p>First we need to have a tool to see our filter results. Create a <code>sockeye</code> service by saving the following YAML manifest in a file called <code>sockeye.yaml</code> and applying it to your Kubernetes cluster:</p> <pre><code>apiVersion: serving.knative.dev/v1\nkind: Service\nmetadata:\n  name: sockeye\nspec:\n  template:\n    spec:\n      containers:\n        - image: docker.io/n3wscott/sockeye:v0.7.0@sha256:e603d8494eeacce966e57f8f508e4c4f6bebc71d095e3f5a0a1abaf42c5f0e48\n</code></pre> <pre><code>kubectl apply -f sockeye.yaml\n</code></pre> <p>Open the web interface in a browser at the URL found with the following command:</p> <pre><code>$ kubectl get ksvc sockeye -o=jsonpath='{.status.url}'\n</code></pre>","location":"guides/writingafilter/#event-display"},{"title":"Event producers","text":"<p>Next, create the two PingSources to produce CloudEvents by saving the following YAML manifests in two separate files and applying them to your Kubernetes cluster with <code>kubectl apply</code>:</p> <pre><code>apiVersion: sources.knative.dev/v1\nkind: PingSource\nmetadata:\n  name: ps-filter-demo-1\nspec:\n  schedule: \"*/1 * * * *\"\n  contentType: \"application/json\"\n  data: '{\n   \"name\": \"TriggerMesh\",\n    \"sub\": {\n        \"array\": [\"hello\", \"Filter\"]\n        }\n    }'\n  sink:\n    ref:\n      apiVersion: routing.triggermesh.io/v1alpha1\n      kind: Filter\n      name: filter-demo\n</code></pre> <p>The second source uses a different payload to show you how the <code>Filter</code> expression may be used to express complex filtering rules.</p> <pre><code>apiVersion: sources.knative.dev/v1\nkind: PingSource\nmetadata:\n  name: ps-filter-demo-2\nspec:\n  schedule: \"*/1 * * * *\"\n  contentType: \"application/json\"\n  data: '{\n      \"answer\": 42\n    }'\n  sink:\n    ref:\n      apiVersion: routing.triggermesh.io/v1alpha1\n      kind: Filter\n      name: filter-demo\n</code></pre>","location":"guides/writingafilter/#event-producers"},{"title":"Filter events","text":"<p>Finally, create the <code>Filter</code> object to filter out events from the first PingSource. Once again save the following YAML manifest in a file and apply it to your Kubernetes cluster with <code>kubectl apply</code>.</p> <pre><code>apiVersion: routing.triggermesh.io/v1alpha1\nkind: Filter\nmetadata:\n  name: filter-demo\nspec:\n  expression: $sub.array.0.(string) == \"hello\" &amp;&amp; $name.(string) != \"TriggerMesh\" || $answer.(int64) == 42\n  sink:\n    ref:\n      apiVersion: serving.knative.dev/v1\n      kind: Service\n      name: sockeye\n</code></pre> <p>Verify that your filter is ready with <code>kubectl</code> like so:</p> <pre><code>$ kubectl get filter\nNAME          ADDRESS                                                      READY   REASON\nfilter-demo   http://filter-adapter.sebgoa.svc.cluster.local/filter-demo   True\n</code></pre> <p>Only events from the second source should appear in the <code>sockeye</code> web interface as shown in the screenshot below:</p> <p></p>  <p>Test your Filter as Code</p> <p>You can test modifying the filter expression and re-applying it with <code>kubectl</code>. This gives you a declarative event filter which you can manage with your GitOps workflow</p>","location":"guides/writingafilter/#filter-events"},{"title":"More about Filters","text":"<p>Learn more about Filters on the Concepts page.</p>","location":"guides/writingafilter/#more-about-filters"},{"title":"Writing a Function","text":"<p>The TriggerMesh <code>Function</code> API provides opportunities to implement custom event flow logic and may act as a source, transformation, or a target. Currently, Python, NodeJS, and Ruby runtimes are supported.</p>  <p>Tip</p> <p>You can verify that the API is available with the following command:</p> <pre><code>$ kubectl get crd functions.extensions.triggermesh.io\nNAME                                  CREATED AT\nfunctions.extensions.triggermesh.io   2021-10-06T09:01:33Z\n</code></pre> <p>You can also explore the API specification with: <pre><code>$ kubectl explain functions\n</code></pre></p>   <p>Warning</p> <p>The TriggerMesh <code>Function</code> API is an opinionated, simple to consume, Function as a Service (FaaS) system. It is aimed to be used for event processing and does not support external dependencies. Functions that may need external dependencies are best served with Knative Serving.</p>","location":"guides/writingafunction/"},{"title":"Example: A Python function","text":"<p>As an example, let's write a Python function which reads a name from an incoming payload and returns a \"Hello\" message.</p> <p>Writing a function requires two steps:</p> <ul> <li> Writing a function manifest</li> <li> Applying the manifest to your Kubernetes cluster</li> </ul> <p>The Function object spec requires a minimal amount of configuration:</p> <ul> <li>The <code>runtime</code>, here we choose <code>python</code></li> <li>Whether the function is publicly accessible or not using the <code>public</code> keyword.</li> <li>The <code>entrypoint</code>, which specifies the name of the function</li> <li>The <code>code</code>, written in-line with the function manifest</li> </ul> <p>Save the YAML manifest below in a file called <code>function.yaml</code></p> <pre><code>apiVersion: extensions.triggermesh.io/v1alpha1\nkind: Function\nmetadata:\n  name: python-function-hello\nspec:\n  runtime: python\n  public: true\n  entrypoint: endpoint\n  code: |\n    def endpoint(event, context):\n      return \"Hello \" + event['name']\n</code></pre> <p>You can then create the function with:</p> <pre><code>kubectl apply -f function.yaml\n</code></pre> <p>You can find the public endpoint of your function and test it:</p> <pre><code>$ kubectl get function\nNAME                    ADDRESS                                                          READY   REASON\npython-function-hello   https://python-function-hello-mvf2bk.sebgoa.dev.triggermesh.io   True\n\n$ curl -ks -d '{\"name\":\"seb\"}' https://python-function-hello-mvf2bk.sebgoa.dev.triggermesh.io |jq\n{\n  \"id\": \"62402f5a-0a82-48e8-8e67-db68d57efdf9\",\n  \"type\": \"io.triggermesh.function.python\",\n  \"source\": \"source.py\",\n  \"specversion\": \"1.0\",\n  \"time\": \"2021-10-11T16:26:49Z\",\n  \"datacontenttype\": \"text/plain\",\n  \"data\": \"Hello seb\"\n}\n</code></pre>  <p>Note</p> <p>The returned event adheres to the CloudEvent specification.</p>","location":"guides/writingafunction/#example-a-python-function"},{"title":"More about Functions","text":"<p>Learn more about Functions on the Concepts page.</p>","location":"guides/writingafunction/#more-about-functions"},{"title":"Transforming XML to JSON","text":"<p>The TriggerMesh <code>XMLToJSONTransformation</code> API object can be used to process a Cloudevent containing XML and return a JSON representation.</p> <p></p>","location":"guides/xmltojsontransformation/"},{"title":"Configuring an XML to JSON event flow XML","text":"<p>This guide shows you how to configure an event flow that transforms an incoming CloudEvent in XML to their JSON representation. It has four steps:</p> <ul> <li>Deploy the <code>EventDisplay</code> service.</li> <li>Deploy the <code>XMlToJSONTransformation</code> object.</li> <li>Deploy a Source that emits XML data.</li> <li>Check the results in the logs of the <code>EventDisplay</code> Pod. </li> </ul> <p>An <code>XMLToJSONTransformation</code> object can be configured to either reply to the event sender or to send the transformed data to a <code>Sink</code> if one is provided. In this guide, we will use a <code>Sink</code> to send the transformed data to a so-called <code>EventDisplay</code> service. </p>","location":"guides/xmltojsontransformation/#configuring-an-xml-to-json-event-flow-xml"},{"title":"Deploying an Event Display","text":"<p>Let's first deploy the end of our event flow. The <code>EventDisplay</code> is a simple application that can be used to display CloudEvents. It can  be deployed by writing the following YAML in a file and using <code>kubectl apply -f &lt;manifest.yaml&gt;</code>:</p> <pre><code>apiVersion: serving.knative.dev/v1\nkind: Service\nmetadata:\n    name: event-display\nspec:\n  template:\n    spec:\n      containers:\n        - image: gcr.io/knative-releases/knative.dev/eventing-contrib/cmd/event_display@sha256:46d5a66f300c3ced590835d379a0e9badf413ae7ab60f21a2550ecedbc9eb9d3\n</code></pre>","location":"guides/xmltojsontransformation/#deploying-an-event-display"},{"title":"Deploying an XMLToJSONTransformation Object","text":"<p>With the <code>event-display</code> in place, the <code>XMLToJSONTransformation</code> object can now be deployed in the same manner using the following manifest:</p>  <p>Tip</p> <p>Below we use a <code>Sink</code> to declare where the response go. If you omit the <code>Sink</code> the response will go back to the Sender.</p>  <pre><code>apiVersion: flow.triggermesh.io/v1alpha1\nkind: XMLToJSONTransformation\nmetadata:\n  name: demo\nspec:\n  sink:\n    ref:\n      apiVersion: serving.knative.dev/v1\n      kind: Service\n      name: event-display\n</code></pre>","location":"guides/xmltojsontransformation/#deploying-an-xmltojsontransformation-object"},{"title":"Deploying a <code>PingSource</code> Object.","text":"<p>Finally, we deploy an event source that will emit CloudEvents with XML data in the payload. We can do this with the <code>PingSource</code> which sends Cloudevents on a  schedule.</p> <p>The YAML manifest below shows that we will send a note in XML every minute. Write the following YAML in a file and apply it with <code>kubectl apply -f &lt;manifest.yaml&gt;</code>.</p> <pre><code>apiVersion: sources.knative.dev/v1\nkind: PingSource\nmetadata:\n  name: pingxml\nspec:\n  schedule: \"*/1 * * * *\"\n  contentType: application/xml\n  data: '&lt;note&gt;&lt;to&gt;Tove&lt;/to&gt;&lt;from&gt;Jani&lt;/from&gt;&lt;heading&gt;Reminder&lt;/heading&gt;&lt;body&gt;Dont forget me this weekend&lt;/body&gt;&lt;/note&gt;'\n  sink:\n    ref:\n      apiVersion: flow.triggermesh.io/v1alpha1\n      kind: XMLToJSONTransformation\n      name: demo\n</code></pre>","location":"guides/xmltojsontransformation/#deploying-a-pingsource-object"},{"title":"Viewing the Transformation's Output in the Event Display","text":"<p>With our event flow in place, we can now view the transformed data in the <code>EventDisplay</code>.</p> <p>We need to retrieve the <code>EventDisplay</code> Pod name by running the following command:</p> <pre><code>kubectl get pods\nNAME                                                             READY   STATUS    RESTARTS   AGE\nxmltojsontransformation-demo-00001-deployment-7f45697d45-4bngq   2/2     Running   0          5m42s\nevent-display-00001-deployment-5c97f6c58c-ndjhl                  2/2     Running   0          5m2s\n</code></pre> <p>With the Pod name, we can run the following command to view the transformed data in the <code>EventDisplay</code> Pod logs:</p> <pre><code>kubectl logs event-display-00001-deployment-5c97f6c58c-ndjhl user-container\n\u2601\ufe0f  cloudevents.Event\nValidation: valid\nContext Attributes,\n  specversion: 1.0\n  type: dev.knative.sources.ping\n  source: /apis/v1/namespaces/t/pingsources/pingxml\n  id: be4a7e9f-a475-4555-895e-84bcf075a85c\n  time: 2022-01-21T17:29:00.426355338Z\n  datacontenttype: application/json\nData,\n  {\n    \"note\": {\n      \"body\": \"Dont forget me this weekend\",\n      \"to\": \"Tove\",\n      \"from\": \"Jani\",\n      \"heading\": \"Reminder\"\n    }\n  }\n</code></pre> <p>We see our beautiful sample note now in JSON format.</p>","location":"guides/xmltojsontransformation/#viewing-the-transformations-output-in-the-event-display"},{"title":"Transforming XML Using XSLT","text":"<p>The Trigermesh <code>XSLTTransformation</code> API object can be used to process a Cloudevent containing XML and transform the document using XSLT.</p>","location":"guides/xslttransformation/"},{"title":"Configuring a XSLT Transformation Event Flow","text":"<p>This guide shows you how to configure an event flow that transforms an incoming CloudEvent in XML by parsing it with an XSLT stylesheet. It has five steps:</p> <ul> <li>Deploy a Broker that will receive the transformed data.</li> <li>Deploy the <code>EventDisplay</code> service.</li> <li>Deploy the <code>XSLTTransformation</code> object.</li> <li>Configure the Triggers</li> <li>Deploy a curl pod that will allow us to send events to the broker.</li> </ul> <p></p> <p>An <code>XSLTTransformation</code> object can be configured to either reply to the event sender or to send the  transformed data to a <code>Sink</code>, if one is provided. In this guide, we will deploy without a <code>Sink</code> and  configure the replies from the transformation to route to the <code>EventDisplay</code> service using a <code>Trigger</code>.</p> <p>The transformation needs to be configured with a valid XSLT document. In this guide we will use the following XSLT:</p> <pre><code>&lt;xsl:stylesheet version=\"1.0\"   xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\"&gt;\n  &lt;xsl:template match=\"tests\"&gt;\n    &lt;output&gt;\n      &lt;xsl:apply-templates select=\"test\"&gt;\n        &lt;xsl:sort select=\"data/el1\"/&gt;\n        &lt;xsl:sort select=\"data/el2\"/&gt;\n      &lt;/xsl:apply-templates&gt;\n    &lt;/output&gt;\n  &lt;/xsl:template&gt;\n\n  &lt;xsl:template match=\"test\"&gt;\n    &lt;item&gt;\n      &lt;xsl:value-of select=\"data/el1\"/&gt;\n      &lt;xsl:value-of select=\"data/el2\"/&gt;\n    &lt;/item&gt;\n  &lt;/xsl:template&gt;\n&lt;/xsl:stylesheet&gt;\n</code></pre> <p>It transforms the following XML: <pre><code>&lt;tests&gt;\n  &lt;test&gt;\n    &lt;data&gt;\n      &lt;el1&gt;A&lt;/el1&gt;\n      &lt;el2&gt;1&lt;/el2&gt;\n    &lt;/data&gt;\n  &lt;/test&gt;\n  &lt;test&gt;\n    &lt;data&gt;\n      &lt;el1&gt;B&lt;/el1&gt;\n      &lt;el2&gt;2&lt;/el2&gt;\n    &lt;/data&gt;\n  &lt;/test&gt;\n  &lt;test&gt;\n    &lt;data&gt;\n      &lt;el1&gt;C&lt;/el1&gt;\n      &lt;el2&gt;3&lt;/el2&gt;\n    &lt;/data&gt;\n  &lt;/test&gt;\n&lt;/tests&gt;\n</code></pre></p> <p>Into this new XML document: <pre><code>&lt;?xml version=\"1.0\"?&gt;\n&lt;output&gt;\n  &lt;item&gt;A1&lt;/item&gt;\n  &lt;item&gt;B2&lt;/item&gt;\n  &lt;item&gt;C3&lt;/item&gt;\n&lt;/output&gt;\n</code></pre></p> <p>Let's go step by step.</p>","location":"guides/xslttransformation/#configuring-a-xslt-transformation-event-flow"},{"title":"Deploy the Broker","text":"<p>Deploy a Broker by writing the following YAML in a file: <pre><code>apiVersion: eventing.knative.dev/v1\nkind: Broker\nmetadata:\n  name: demo\n</code></pre></p> <p>Create the Broker with the following command: <pre><code>kubectl apply -f &lt;manifest.yaml&gt;\n</code></pre></p>","location":"guides/xslttransformation/#deploy-the-broker"},{"title":"Deploying the <code>EventDisplay</code> Service","text":"<p>Let's now deploy the end of our event flow. The <code>EventDisplay</code> is a simple application that can be used to display CloudEvents. It can  be deployed by writing the following YAML in a file and using <code>kubectl apply -f &lt;manifest.yaml&gt;</code>:</p> <pre><code>apiVersion: serving.knative.dev/v1\nkind: Service\nmetadata:\n    name: event-display\nspec:\n  template:\n    spec:\n      containers:\n        - image: gcr.io/knative-releases/knative.dev/eventing-contrib/cmd/event_display@sha256:46d5a66f300c3ced590835d379a0e9badf413ae7ab60f21a2550ecedbc9eb9d3\n</code></pre>","location":"guides/xslttransformation/#deploying-the-eventdisplay-service"},{"title":"Deploy the <code>XSLTTransformation</code> Object","text":"<p>With the <code>event-display</code> in place, the <code>XSLTTransformation</code> object can now be deployed in the same manner using the following manifest:</p>  <p>Note</p> <p>The XSLT is written in-line within the YAML manifest</p>  <pre><code>apiVersion: flow.triggermesh.io/v1alpha1\nkind: XSLTTransformation\nmetadata:\n  name: demo\nspec:\n  allowPerEventXSLT: true\n  xslt:\n    value: |\n      &lt;xsl:stylesheet version=\"1.0\" xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\"&gt;\n        &lt;xsl:template match=\"tests\"&gt;\n          &lt;output&gt;\n            &lt;xsl:apply-templates select=\"test\"&gt;\n              &lt;xsl:sort select=\"data/el1\"/&gt;\n              &lt;xsl:sort select=\"data/el2\"/&gt;\n            &lt;/xsl:apply-templates&gt;\n          &lt;/output&gt;\n        &lt;/xsl:template&gt;\n\n        &lt;xsl:template match=\"test\"&gt;\n          &lt;item&gt;\n            &lt;xsl:value-of select=\"data/el1\"/&gt;\n            &lt;xsl:value-of select=\"data/el2\"/&gt;\n          &lt;/item&gt;\n        &lt;/xsl:template&gt;\n      &lt;/xsl:stylesheet&gt;\n</code></pre>","location":"guides/xslttransformation/#deploy-the-xslttransformation-object"},{"title":"Configure the Triggers","text":"<p>Next, Triggers need to be configured to route our Cloudevents to the <code>XSLTTransformation</code> and <code>EventDisplay</code> objects. This can be done by writing the following YAML in a file and using <code>kubectl apply -f &lt;manifest.yaml&gt;</code>. We have two triggers, one to send events containing XML to the transformation and one to send all events to the event display.</p> <pre><code>kind: Trigger\napiVersion: eventing.knative.dev/v1\nmetadata:\n  name: event-display\nspec:\n  broker: demo\n  subscriber:\n    ref:\n      apiVersion: serving.knative.dev/v1\n      kind: Service\n      name: event-display\n---\nkind: Trigger\napiVersion: eventing.knative.dev/v1\nmetadata:\n  name: xslttransformation-xmldoc\nspec:\n  broker: demo\n  filter:\n    attributes:\n      # setting a filter to process only events of type `xml.document`\n      type: xml.document\n  subscriber:\n    ref:\n      apiVersion: flow.triggermesh.io/v1alpha1\n      kind: XSLTTransformation\n      name: demo\n</code></pre>","location":"guides/xslttransformation/#configure-the-triggers"},{"title":"Deploy a Curl Pod","text":"<p>Finally, an event source can be depoyed that will emit CloudEvents with XML data in the payload. We can do this in two steps:</p> <pre><code>1. Deploy a curl pod that will emit the CloudEvents by writing the following YAML in a file and apply it with `kubectl apply -f &lt;manifest.yaml&gt;`.\n</code></pre> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    run: curl\n  name: curl\nspec:\n  containers:\n  - image: radial/busyboxplus:curl\n    imagePullPolicy: IfNotPresent\n    name: curl\n    stdin: true\n    tty: true\n</code></pre> <pre><code>2. Execute the following command to emit a cloudevent to the broker we created:\n</code></pre> <pre><code>kubectl exec -ti curl -- curl -v \"http://broker-ingress.knative-eventing.svc.cluster.local/default/demo\" \\\n  -H \"Ce-Specversion: 1.0\" \\\n  -H \"Ce-Type: xml.document\" \\\n  -H \"Ce-Source: curl.shell\" \\\n  -H \"Content-Type: application/xml\" \\\n  -H \"Ce-Id: 1234-abcd\" \\\n  -d '&lt;tests&gt;&lt;test&gt;&lt;data&gt;&lt;el1&gt;A&lt;/el1&gt;&lt;el2&gt;1&lt;/el2&gt;&lt;/data&gt;&lt;/test&gt;&lt;test&gt;&lt;data&gt;&lt;el1&gt;B&lt;/el1&gt;&lt;el2&gt;2&lt;/el2&gt;&lt;/data&gt;&lt;/test&gt;&lt;test&gt;&lt;data&gt;&lt;el1&gt;C&lt;/el1&gt;&lt;el2&gt;3&lt;/el2&gt;&lt;/data&gt;&lt;/test&gt;&lt;/tests&gt;'\n</code></pre>","location":"guides/xslttransformation/#deploy-a-curl-pod"},{"title":"Viewing the Transformation's Output in the Event Display","text":"<p>With our event flow in place, we can now view the transformed data in the <code>EventDisplay</code>.</p> <p>We need to retrieve the <code>EventDisplay</code> Pod name by running the following command:</p> <p><pre><code>kubectl get pods                                                          \nNAME                                                   READY   STATUS    RESTARTS   AGE\ncurl                                                   1/1     Running   0          4m36s\nevent-display-00001-deployment-74bf8556b7-t7lxw        2/2     Running   0          3s\nxslttransformation-demo-00001-deployment-7d9fc458b5-6xfbw   2/2     Running   0          3s\n</code></pre> With the Pod name, we can run the following command to view the transformed data in the <code>EventDisplay</code> Pod logs:</p> <pre><code>kubectl logs event-display-00001-deployment-74bf8556b7-t7lxw user-container\n\u2601\ufe0f  cloudevents.Event\nValidation: valid\nContext Attributes,\n  specversion: 1.0\n  type: xml.document\n  source: curl.shell\n  id: 1234-abcd\n  datacontenttype: application/xml\nExtensions,\n  knativearrivaltime: 2022-01-27T17:36:12.563701467Z\nData,\n  &lt;tests&gt;&lt;test&gt;&lt;data&gt;&lt;el1&gt;A&lt;/el1&gt;&lt;el2&gt;1&lt;/el2&gt;&lt;/data&gt;&lt;/test&gt;&lt;test&gt;&lt;data&gt;&lt;el1&gt;B&lt;/el1&gt;&lt;el2&gt;2&lt;/el2&gt;&lt;/data&gt;&lt;/test&gt;&lt;test&gt;&lt;data&gt;&lt;el1&gt;C&lt;/el1&gt;&lt;el2&gt;3&lt;/el2&gt;&lt;/data&gt;&lt;/test&gt;&lt;/tests&gt;\n\u2601\ufe0f  cloudevents.Event\nValidation: valid\nContext Attributes,\n  specversion: 1.0\n  type: xml.document.response\n  source: xslttransform-adapter\n  id: c15e1cf7-ac98-4c3b-8ee6-1d0f5185c7cb\n  time: 2022-01-27T17:36:14.90562873Z\n  datacontenttype: application/xml\nExtensions,\n  category: success\n  knativearrivaltime: 2022-01-27T17:36:14.929243269Z\nData,\n  &lt;?xml version=\"1.0\"?&gt;\n&lt;output&gt;\n  &lt;item&gt;A1&lt;/item&gt;\n  &lt;item&gt;B2&lt;/item&gt;\n  &lt;item&gt;C3&lt;/item&gt;\n&lt;/output&gt;\n</code></pre> <p>We now see the incoming event and the transformed data, as expected. </p>","location":"guides/xslttransformation/#viewing-the-transformations-output-in-the-event-display"},{"title":"Slack to Confluent Bridge","text":"<p>This Guide will help you creating a Bridge that sends Slack events to a Confluent Kafka instance.</p> <p>You will need:</p> <ul> <li>Admin privileges on an Slack workspace. You can create one here</li> <li>A Confluent instance admin user.</li> </ul>","location":"guides/bridges/slack-to-confluent/"},{"title":"Contents","text":"<ul> <li>Slack to Confluent Bridge</li> <li>Contents</li> <li>Create Confluent User</li> <li>Create The Slack to Confluent Bridge</li> <li>Retrieve Slack Source Exposed URL</li> <li>Subscribe to Slack Events</li> <li>Testing the Integration</li> </ul>","location":"guides/bridges/slack-to-confluent/#contents"},{"title":"Create Confluent User","text":"<ul> <li>Create a user for the integration that can produce messages to a topic. Potentially that user could also create the topic if it doesn't exists.</li> <li> <p>We will require for this example Bridge a target component configured with this data:</p> </li> <li> <p>SASL/PLAIN mechanism</p> </li> <li>SASL/SSL protocol</li> <li>Topic (to be written to, and to be created if not existing)</li> <li>Bootstrap Servers</li> <li>User name</li> <li>User password</li> </ul> <p>From that list above <code>password</code> is a sensible field which we require to be inserted through a secret. It is required that the created key is named <code>password</code>:</p> <p></p>","location":"guides/bridges/slack-to-confluent/#create-confluent-user"},{"title":"Create the Slack to Confluent Bridge","text":"<p>We can proceed to create the Bridge now. Slack Event API needs the URL to send data to, that means we need to provide the URL first, then head to Slack Admin site to configure the bot that will serve for this integration.</p> <p>Create a new Bridge, click on <code>Source</code>, and look for Slack.</p> <p></p> <p>We are using the <code>default</code> broker for this demo, select it, add a name to the component and press <code>Save</code>.</p> <p>Now click on the <code>Target</code> block at the bottom of the page, a list of targets to connect to will be shown, look for Confluent and fill</p> <ul> <li>Name of component at the bridge (your choice).</li> <li>Bootstrap servers for your Confluent instance, at least one entry.</li> <li>A topic to write to. If it doesn't exists the target will create it.</li> <li>Username for the integration.</li> <li>The secret containing the password created at a previous step.</li> </ul> <p></p> <p>Press <code>Submit Bridge</code> and you are done with TriggerMesh configuration.</p>","location":"guides/bridges/slack-to-confluent/#create-the-slack-to-confluent-bridge"},{"title":"Retrieve Slack Source Exposed URL","text":"<p>The Slack Source component creates an external URL that should be used as the <code>Request URL</code> callback when configuring the Slack Bot App. In order to obtain it, open the <code>Services</code> area at TriggerMesh and look for a service by the name of the Slack Source you just created. Then copy the exposing URL.</p> <p></p>","location":"guides/bridges/slack-to-confluent/#retrieve-slack-source-exposed-url"},{"title":"Subscribe to Slack Events","text":"<p>Open the Slack web site at the Apps home anc click on <code>Create New App</code></p> <ul> <li>Enter a name for your App and the workspace where it will be hosted.</li> <li>Once create navigate to <code>Basic Information</code>.</li> <li>Click on the <code>Event Subscriptions</code> pane.</li> <li>Slide the <code>Enable Events</code> slide button.</li> <li>At the <code>Request URL</code> field set the Slack Source URL that TriggerMesh is exposing. The Slack Source is a serverless service, it could happen that the verification process expires waiting for the first request to succeed. If that happens, please try again to do the verification.</li> </ul> <p></p> <p>Scroll down and expand the Subscribe to bot events. Select which events you want your bot to subscribe to. Once you have selected them, press save changes at the bottom of the page.</p> <p></p> <p>Your application needs to get deployed to your workspace. For that to happen click on Install App, select the workspace and review permissions. Once you allow the App to be deployed, you are all set.</p>","location":"guides/bridges/slack-to-confluent/#subscribe-to-slack-events"},{"title":"Testing the Integration","text":"<p>At our example we subscribed out App bot to the <code>app_mention</code> event, we just need to mention by its name and the message should make its way from Slack to Confluent:</p> <p></p>","location":"guides/bridges/slack-to-confluent/#testing-the-integration"},{"title":"Writing a Webhook to Slack Bridge","text":"<p>This Bridge connects an HTTP endpoint to Slack. Every time the webhook is called a message will be produced, which we will validate and transform into an Slack message.</p> <p>We will be calling the exposed HTTP endpoint using <code>curl</code>, in a real world scenario the caller would be an application configuring a webhook callback.</p>","location":"guides/bridges/webhook-to-slack/"},{"title":"Events","text":"<p>Webhook Source produce arbitrary events based on configuration and received requests.</p> <ul> <li><code>type</code> attribute is set to the one configured by user.</li> <li><code>source</code> attribute is set to the one configured by user.</li> <li><code>datacontenttype</code> is set to the <code>Content-Type</code> received at the incoming request.</li> <li><code>data</code> is set to the body of the received request.</li> </ul> <p>Slack Target expect one of these 3 event types along with their related payload:</p> <ul> <li><code>com.slack.webapi.chat.postMessage</code> for consuming chat.postMessage</li> <li><code>com.slack.webapi.chat.scheduleMessage</code> for consuming chat.scheduleMessage</li> <li><code>com.slack.webapi.chat.update</code> for consuming chat.update</li> </ul> <p>This fictional scenario will send the following data to the Webhook Source using <code>curl</code>. <pre><code>{\"message\": \"Hello Slack!\"}\n</code></pre></p> <p>The Webhook Source is expected to produce this event.</p> <pre><code>type: webhook.slack.postmessage\ndata: {\"message\": \"Hello Slack!\"}\nothers: ...\n</code></pre> <p>We will be using TriggerMesh's Function to perform a transformation which will consume the event above and produce this one.</p> <pre><code>type: com.slack.webapi.chat.postMessage\ndata: {\"channel\":\"ABCDE12345\", \"text\": \"Hello Slack!\"}\nothers: ...\n</code></pre> <p>This event will finally be consumed by the Slack Target that will in turn call the Slack API to post the message.</p>","location":"guides/bridges/webhook-to-slack/#events"},{"title":"Webhook Source","text":"<p>For simplicity we are setting up a non authenticated Webhook and using the default Kubernetes namespace.</p> <pre><code>apiVersion: sources.triggermesh.io/v1alpha1\nkind: WebhookSource\nmetadata:\n  name: post-message\nspec:\n  eventType: webhook.slack.postmessage\n  eventSource: webhook.post-message\n\n  sink:\n    ref:\n      apiVersion: eventing.knative.dev/v1\n      kind: Broker\n      name: default\n</code></pre> <p>The <code>eventType</code> and <code>eventSource</code> CloudEvents attributes are being set for further event filtering. There is a reference to a Broker sink object where events will be sent, we will get to that one later.</p>","location":"guides/bridges/webhook-to-slack/#webhook-source"},{"title":"Slack Target","text":"<p>Slack Target requires:</p> <ul> <li>Creating a new Slack App: add the <code>chat:write</code> permission under <code>Bot Token Scopes</code>, then install the application at your workspace.</li> <li>A Slack API token: from the Install App menu retrieve the OAuth Access token that begins with <code>xoxb-</code>.</li> </ul> <p>Create a secret using the Slack API token</p> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: slack-tm\ntype: Opaque\nstringData:\n  token: xoxb-12345-abcde\n</code></pre> <p>Create the Slack Target referencing the API token.</p> <pre><code>apiVersion: targets.triggermesh.io/v1alpha1\nkind: SlackTarget\nmetadata:\n  name: slack-tm\nspec:\n  token:\n    secretKeyRef:\n      name: slack-tm\n      key: token\n</code></pre>","location":"guides/bridges/webhook-to-slack/#slack-target"},{"title":"Transformation Component","text":"<p>To bridge the gap between the event produced by the Webhook Source and the one expected at the Slack Target we need to perform a transformation, which we can do using a declarative or coded approach. We will use the later here.</p> <p>Replace the channel ID in this transformation with the one you want to use. The channel ID can be retrieved from the URL either at the browser or selecting the <code>copy link</code> option at the Slack app. Please make sure that the bot user is added to the Slack channel.</p> <pre><code>apiVersion: extensions.triggermesh.io/v1alpha1\nkind: Function\nmetadata:\n  name: webhook-to-slack\nspec:\n  runtime: python\n  public: false\n  entrypoint: transformToSlack\n  ceOverrides:\n    extensions:\n      type: com.slack.webapi.chat.postMessage\n  code: |\n    from random import randrange\n\n    def transformToSlack(event, context):\n      return {\n        \"channel\":\"REPLACE-CHANNEL-ID\",\n        \"text\": event['message']\n      }\n</code></pre>","location":"guides/bridges/webhook-to-slack/#transformation-component"},{"title":"Routing Components","text":"<p>In order to connect all components we will setup these elements:</p> <ul> <li>A central Broker that receives messages from the Source</li> <li>A Trigger that consumes Webhook events filtered by the <code>webhook.slack.postmessage</code> type and sends them to the transformation Function.</li> <li>A Trigger that consumes transformed events filtered by the <code>com.slack.webapi.chat.postMessage</code> type and sends them to the Slack target.</li> </ul> <p>The Broker name is set to <code>default</code> to match the one used at the Webhook Source earlier.</p> <pre><code>apiVersion: eventing.knative.dev/v1\nkind: Broker\nmetadata:\n  name: default\n</code></pre> <p>Both Triggers are setup on the Broker and subscribe their corresponding destination filtering by types.</p> <pre><code>apiVersion: eventing.knative.dev/v1\nkind: Trigger\nmetadata:\n  name: webhook-to-transform\nspec:\n  broker: default\n  filter:\n    attributes:\n      type: webhook.slack.postmessage\n  subscriber:\n    ref:\n      apiVersion: extensions.triggermesh.io/v1alpha1\n      kind: Function\n      name: webhook-to-slack\n\n---\n\napiVersion: eventing.knative.dev/v1\nkind: Trigger\nmetadata:\n  name: slack-post-messages\nspec:\n  broker: default\n  filter:\n    attributes:\n      type: com.slack.webapi.chat.postMessage\n  subscriber:\n    ref:\n      apiVersion: targets.triggermesh.io/v1alpha1\n      kind: SlackTarget\n      name: slack-tm\n</code></pre>","location":"guides/bridges/webhook-to-slack/#routing-components"},{"title":"Done","text":"<p>Retrieve the URL where the Webhook is listening for incoming requests.</p> <pre><code>$ kubectl get webhooksources.sources.triggermesh.io post-message\nNAME           READY   REASON   URL                                                                  SINK                                                                            AGE\npost-message   True             https://webhooksource-post-message.woodford.dev.triggermesh.io   http://broker-ingress.knative-eventing.svc.cluster.local/woodford/default   61s\n</code></pre> <p>Use <code>curl</code> or any HTTP capable client to post messages at Slack.</p> <pre><code>curl -d '{\"message\":\"test my bridge\"}' https://webhooksource-post-message.woodford.dev.triggermesh.io\n</code></pre> <p>This Bridge can be extended in many different ways:</p> <ul> <li>Validation and error handling at the transformation Function.</li> <li>The Channel could be provided as a parameter from the WebhookSource, defaulting to a channel provided by the Function.</li> <li>AWS Comprehend could be used for sentiment analysis.</li> <li>Messages could be enriched if they contain word <code>avocado</code> with \ud83e\udd51</li> <li>Add a Twilio Source that will also feed incoming messages to the Broker.</li> <li>Add a Datadog Target that will convert a subset of filtered messages into alerts.</li> </ul> <p>If you have any questions on how to build this Bridge or how to modify it to suit your needs, join our Community Slack and contact us.</p>","location":"guides/bridges/webhook-to-slack/#done"},{"title":"Bridge Description Files","text":"<p>Bridges are described in source files called Bridge Description Files with the extension <code>.brg.hcl</code>.</p> <p>Bridge descriptions are written in a configuration language called TriggerMesh Integration Language, which is based on the HCL syntax, as explained in the Concepts section of the documentation.</p> <p>Each Bridge Description File contains the description of a single Bridge.</p>","location":"til/Bridge-Description-Files/"},{"title":"Syntax Highlighting","text":"<p>The following extensions enable support for syntax highlighting of HCL files (any <code>*.hcl</code> file extension) in various popular IDEs/Text editors:</p> <ul> <li>Visual Studio Code: hashicorp/vscode-terraform</li> <li>IntelliJ: Terraform/HCL language support</li> <li>Sublime Text: alexlouden/Terraform</li> <li>Atom: fd/language-hcl</li> <li>Vim: jvirtanen/vim-hcl</li> <li>Emacs: purcell/emacs-hcl-mode</li> </ul>","location":"til/Bridge-Description-Files/#syntax-highlighting"},{"title":"Code Formatting","text":"<p>The GitHub repository of the HCL toolkit contains the source code of a command-line tool called <code>hclfmt</code>, which can be used for formatting HCL files.</p> <p>Binary releases of this tool are available at teamon/hclfmt (GitHub).</p>","location":"til/Bridge-Description-Files/#code-formatting"},{"title":"Visual Studio Code Extension","text":"","location":"til/Bridge-Description-Files/#visual-studio-code-extension"},{"title":"Bridges Operator","text":"<p>Bridges are first-class citizens on the TriggerMesh platform. Every TriggerMesh installation includes a Kubernetes operator which reconciles Kubernetes API objects of kind <code>Bridge</code>. Such object is an aggregate of multiple children Kubernetes objects, much like a List-manifest, with extra lifecycle capabilities such as status reporting and garbage collection.</p>","location":"til/Bridges-Operator/"},{"title":"Data Format","text":"<p>The Kubernetes API objects which compose a TriggerMesh Bridge are nested under the <code>spec.components</code> key of a <code>Bridge</code> object. Such object can be generated directly from the <code>til generate</code> command using the <code>--bridge</code> flag:</p> <pre><code>$ til generate my-bridge.brg.hcl --bridge\n</code></pre> <p>The example below shows the shape of a <code>Bridge</code> object that is equivalent to the sample List-manifest from the Output format page:</p> <pre><code>{\n  \"apiVersion\": \"flow.triggermesh.io/v1alpha1\",\n  \"kind\": \"Bridge\",\n  \"metadata\": {\n    \"name\": \"my-bridge\",\n  },\n  \"spec\": {\n    \"components\": [\n      {\n        \"object\": {\n          \"apiVersion\": \"example/v1\",\n          \"kind\": \"SomeKind\",\n          \"metadata\": {\n            \"name\": \"some-name\",\n          },\n          // ...\n        },\n      },\n      {\n        \"object\": {\n          \"apiVersion\": \"example/v1\",\n          \"kind\": \"OtherKind\",\n          \"metadata\": {\n            \"name\": \"other-name\",\n          },\n          // ...\n        },\n      },\n      /*\n         more Kubernetes API objects\n      */\n    ]\n  }\n}\n</code></pre>","location":"til/Bridges-Operator/#data-format"},{"title":"Deployment","text":"<p>A <code>Bridge</code> object can be deployed using kubectl like any other Kubernetes API object:</p> <pre><code>$ til generate my-bridge.brg.hcl --bridge | kubectl create -f -\nbridge.flow.triggermesh.io/my-bridge created\n</code></pre> <p>A successfully deployed Bridge will be displayed with a \"Ready\" status:</p> <pre><code>$ kubectl get bridge my-bridge\nNAME        READY   REASON   AGE\nmy-bridge   True             7m\n</code></pre>","location":"til/Bridges-Operator/#deployment"},{"title":"Termination","text":"<p>It is possible to terminate an entire Bridge by deleting its corresponding <code>Bridge</code> object:</p> <pre><code>$ kubectl delete -f my-bridge-manifest.json\nbridge.flow.triggermesh.io/my-bridge deleted\n</code></pre>","location":"til/Bridges-Operator/#termination"},{"title":"Using Carvel kapp","text":"<p>kapp is a CLI tool backed by VMware which can deploy groups of Kubernetes objects as independent applications in a safe and predictable manner.</p> <p>The example below demonstrates how to use kapp to deploy a TriggerMesh Bridge and manage its lifecycle.</p>","location":"til/Carvel-kapp/"},{"title":"Deployment","text":"<p>The kapp tool allows deploying a Bridge List-manifest directly using the <code>kapp deploy</code> command. In a Bash-compatible shell, this can be achieved in a single step using a process substitution:</p> <pre><code>$ kapp deploy -a my-bridge --yes -f &lt;(til generate my-bridge.brg.hcl)\nTarget cluster 'https://my-cluster.example.com' (nodes: node-1, 2+)\n\nChanges\n\nNamespace  Name        Kind       Conds.  Age  Op      Op st.  Wait to    Rs  Ri\ndefault    some-name   SomeKind   -       -    create  -       reconcile  -   -\n^          other-name  OtherKind  -       -    create  -       reconcile  -   -\n[...]\n\nOp:      6 create, 0 delete, 0 update, 0 noop\nWait to: 6 reconcile, 0 delete, 0 noop\n\nContinue? [yN]: y\n\n2:51:35PM: ---- applying 6 changes [0/6 done] ----\n2:51:37PM: create somekind/some-name (example/v1) namespace: default\n2:51:37PM: create otherkind/other-name (example/v1) namespace: default\n[...]\n2:51:39PM: ---- waiting on 6 changes [0/6 done] ----\n2:51:40PM: ok: reconcile somekind/some-name (example/v1) namespace: default\n2:51:40PM: ok: reconcile otherkind/other-name (example/v1) namespace: default\n[...]\n2:51:40PM: ---- applying complete [6/6 done] ----\n2:51:40PM: ---- waiting complete [6/6 done] ----\n\nSucceeded\n</code></pre> <p>The command shown in the previous example is equivalent to saving the generated List-manifest to a file prior to deploying it:</p> <p><pre><code>$ til generate my-bridge.brg.hcl &gt; my-bridge-manifest.json\n</code></pre> <pre><code>$ kapp deploy -a my-bridge -f my-bridge-manifest.json\n</code></pre></p> <p>Alternatively, a List-manifest can be piped to the <code>kapp deploy</code> command by using the <code>-</code> notation as the file name, which corresponds to the standard input. Please note that piping data to kapp requires the usage of the <code>--yes</code> flag, which bypasses the interactive user approval:</p> <pre><code>$ til generate my-bridge.brg.hcl | kapp deploy -a my-bridge --yes -f -\n</code></pre> <p>The deployed Bridge should appear in the list of kapp applications:</p> <pre><code>$ kapp list\nTarget cluster 'https://my-cluster.example.com' (nodes: node-1, 2+)\n\nApps in namespace 'default'\n\nName       Namespaces  Lcs   Lca\nmy-bridge  default     true  6m\n\nLcs: Last Change Successful\nLca: Last Change Age\n\n1 apps\n\nSucceeded\n</code></pre>","location":"til/Carvel-kapp/#deployment"},{"title":"Updates","text":"<p>Any future modification to the Bridge description can be applied to the deployed application using the same <code>deploy</code> command and parameters used during the initial deployment. All pending changes are printed in the terminal and must be approved by the user, unless the <code>--yes</code> flag is set:</p> <pre><code>$ kapp deploy -a my-bridge -f my-bridge-manifest.json\nTarget cluster 'https://my-cluster.example.com' (nodes: node-1, 2+)\n\nChanges\n\nNamespace  Name        Kind       Conds.  Age  Op      Op st.  Wait to    Rs  Ri\ndefault    some-name   SomeKind   5/5 t   14m  update  -       reconcile  ok  -\n^          other-name  OtherKind  5/5 t   14m  delete  -       delete     ok  -\n\nOp:      0 create, 1 delete, 1 update, 0 noop\nWait to: 1 reconcile, 1 delete, 0 noop\n\nContinue? [yN]: y\n\n3:05:57PM: ---- applying 2 changes [0/2 done] ----\n3:05:58PM: update somekind/some-name (example/v1) namespace: default\n3:05:58PM: delete otherkind/other-name (example/v1) namespace: default\n3:05:59PM: ---- waiting on 2 changes [0/2 done] ----\n3:06:00PM: ok: reconcile somekind/some-name (example/v1) namespace: default\n3:06:01PM: ok: delete otherkind/other-name (example/v1) namespace: default\n3:06:01PM: ---- applying complete [2/2 done] ----\n3:06:01PM: ---- waiting complete [2/2 done] ----\n\nSucceeded\n</code></pre>","location":"til/Carvel-kapp/#updates"},{"title":"Termination","text":"<p>To undo the deployment of an entire Bridge, simply uninstall its kapp application:</p> <pre><code>$ kapp delete -a my-bridge\nTarget cluster 'https://my-cluster.example.com' (nodes: node-1, 2+)\n\nChanges\n\nNamespace  Name        Kind       Conds.  Age  Op      Op st.  Wait to    Rs  Ri\ndefault    some-name   SomeKind   5/5 t   20m  delete  -       reconcile  ok  -\n[...]\n\nOp:      0 create, 5 delete, 0 update, 0 noop\nWait to: 0 reconcile, 5 delete, 0 noop\n\nContinue? [yN]: y\n\n3:12:02PM: ---- applying 5 changes [0/5 done] ----\n3:12:04PM: delete somekind/some-name (example/v1) namespace: default\n[...]\n3:12:04PM: ---- waiting on 5 changes [0/5 done] ----\n3:12:04PM: ok: delete somekind/some-name (example/v1) namespace: default\n[...]\n3:12:04PM: ---- applying complete [5/5 done] ----\n3:12:04PM: ---- waiting complete [5/5 done] ----\n\nSucceeded\n</code></pre>","location":"til/Carvel-kapp/#termination"},{"title":"Channels","text":"","location":"til/Channels/"},{"title":"Full list","text":"<ul> <li>Point-to-Point</li> <li>Publish/Subscribe</li> </ul>","location":"til/Channels/#full-list"},{"title":"Point-to-Point","text":"<p>Enables asynchronous data exchanges between an event sender and a single event receiver, with control over delivery settings.</p> <pre><code>channel point_to_point \"async_data\" {\n  delivery {\n    retries = 1 // optional\n    dead_letter_sink = &lt;component&gt;.&lt;identifier&gt; // optional\n  }\n\n  //to = &lt;component&gt;.&lt;identifier&gt;\n}\n</code></pre>","location":"til/Channels/#point-to-point"},{"title":"Publish/Subscribe","text":"<p>Fans out events to selected subscribers.</p> <pre><code>channel pubsub \"fan_out\" {\n  subscribers = [\n    //&lt;component&gt;.&lt;identifier&gt;,\n    //&lt;component&gt;.&lt;identifier&gt;,\n    //&lt;component&gt;.&lt;identifier&gt;,\n  ]\n}\n</code></pre>","location":"til/Channels/#publishsubscribe"},{"title":"CLI","text":"<p>This document describes the usage of the <code>til</code> CLI.</p> <p>It is also possible to print some usage instructions about any command directly via the CLI by appending the <code>-h</code> or <code>--help</code> flag to the specified command:</p> <pre><code>$ til --help\nInterpreter for TriggerMesh's Integration Language.\n\nUSAGE:\n    til &lt;command&gt;\n\nCOMMANDS:\n    generate     Generate Kubernetes manifests for deploying a Bridge.\n    validate     Validate a Bridge description.\n    graph        Represent a Bridge as a directed graph in DOT format.\n</code></pre>","location":"til/Commands/"},{"title":"List of commands","text":"<ul> <li>generate</li> <li>validate</li> <li>graph</li> </ul>","location":"til/Commands/#list-of-commands"},{"title":"<code>generate</code> Command","text":"<p>Usage: <code>til generate FILE [OPTION]...</code></p> <p>The <code>til generate</code> command generates the Kubernetes manifests that allow the Bridge described in <code>FILE</code> to be deployed to TriggerMesh. The default output is a Kubernetes <code>List</code> of individual Kubernetes objects written to standard output in JSON format.</p> <p>Options:</p> <ul> <li><code>--bridge</code> Output a Bridge object instead of a List-manifest.</li> <li><code>--yaml</code> Output generated manifests in YAML format.</li> </ul>","location":"til/Commands/#generate-command"},{"title":"<code>validate</code> Command","text":"<p>Usage: <code>til validate FILE</code></p> <p>The <code>til validate</code> command verifies that the Bridge described in <code>FILE</code> is syntactically valid and can be generated, in which case it returns with an exit code of <code>0</code>. If the Bridge description contains errors, those errors are printed to standard output and the command returns with an exit code of <code>1</code>.</p> <p>Options:</p> <ul> <li><code>--quiet</code> Suppress non-error output.</li> </ul>","location":"til/Commands/#validate-command"},{"title":"<code>graph</code> Command","text":"<p>Usage: <code>til graph FILE</code></p> <p>The <code>til graph</code> command generates a DOT Language representation of the Bridge parsed from FILE, and writes it to standard output.</p> <p>Drawings in the DOT language can be rendered in different graphic formats using the <code>dot</code> command-line tool from the Graphviz visualization software, or visualized directly via a web interface such as the Graphviz Visual Editor.</p>","location":"til/Commands/#graph-command"},{"title":"Component Categories","text":"<p>This document provides a description of the five categories of messaging components available in the TriggerMesh Integration Language.</p>","location":"til/Component-Categories/"},{"title":"Channel","text":"<p>A channel enables asynchronous data communication between event senders and event receivers.</p> <pre><code>channel &lt;CHANNEL TYPE&gt; &lt;CHANNEL IDENTIFIER&gt; {\n    # component-type-specific configuration\n}\n</code></pre>","location":"til/Component-Categories/#channel"},{"title":"Router","text":"<p>A router consumes events which it republishes to one or more event receivers depending on a set of conditions, without modifying the content of the message. Filters fall into this category.</p> <pre><code>router &lt;ROUTER TYPE&gt; &lt;ROUTER IDENTIFIER&gt; {\n    # component-type-specific configuration\n}\n</code></pre>","location":"til/Component-Categories/#router"},{"title":"Transformer","text":"<p>A transformer translates the message contained in incoming events into a different format, and publishes transformed events to a designated event receiver.</p> <pre><code>transformer &lt;TRANSFORMER TYPE&gt; &lt;TRANSFORMER IDENTIFIER&gt; {\n    to = &lt;block reference&gt;\n\n    # component-type-specific configuration\n}\n</code></pre>","location":"til/Component-Categories/#transformer"},{"title":"Source","text":"<p>A source emits events into the messaging system (Bridge) by sending to a designated event receiver. An event source often acts as a gateway between an external service and the messaging system.</p> <pre><code>source &lt;SOURCE TYPE&gt; &lt;SOURCE IDENTIFIER&gt; {\n    to = &lt;block reference&gt;\n\n    # component-type-specific configuration\n}\n</code></pre>","location":"til/Component-Categories/#source"},{"title":"Target","text":"<p>A target is an event receiver which performs some processing on messages. An event target may act as a gateway between the messaging system (Bridge) and an external service.</p> <p>Although a target can be considered as the final destination of an event, it may reply with another event (acknowledgment, error, ...) to an arbitrary event destination.</p> <pre><code>target &lt;TARGET TYPE&gt; &lt;TARGET IDENTIFIER&gt; {\n    reply_to = &lt;block reference&gt; // optional\n\n    # component-type-specific configuration\n}\n</code></pre>","location":"til/Component-Categories/#target"},{"title":"Concepts","text":"<p>The TriggerMesh Integration Language allows to declaratively express a messaging system called a Bridge. At its core, a Bridge is composed of interconnected messaging components that exchange data via Events, often asynchronously over data channels.</p> <p>This document describes the main concepts of the language.</p>","location":"til/Concepts/"},{"title":"Contents","text":"<ul> <li>Syntax</li> <li>Component Blocks</li> <li>Identifiers</li> <li>References</li> <li>Expressions</li> </ul>","location":"til/Concepts/#contents"},{"title":"Syntax","text":"<p>The constructs of the TriggerMesh Integration Language build upon the HCL syntax, which was created by HashiCorp Inc. and popularized by products such as Terraform, Nomad or Packer.</p> <p>The different components of a given Bridge are represented as configuration blocks which are identified by labels and contain configuration attributes.</p> <p>An example of direct point-to-point integration between two services could be expressed with the following code snippet:</p> <pre><code>bridge \"github_to_splunk\" { }\n\n/* Event source block \n   Sources events from a GitHub repository\n*/\nsource github \"my_repo\" {\n  owner_and_repository = \"triggermesh/bridges\"\n  tokens = secret_name(\"github-source-tokens\")\n\n  event_types = [\n    \"push\", \n    \"pull_request\",\n  ]\n\n  to = target.github_archive_index\n}\n\n/* Event target block \n   Receives events and stores them into a Splunk index\n*/\ntarget splunk \"github_archive_index\" {\n  endpoint = \"https://prd-x-12345.splunkcloud.com\"\n  auth = secret_name(\"my-splunk-credentials\")\n\n  index = \"github_events\"\n}\n</code></pre> <p>Most configuration attributes are component-specific. All available attributes are documented in details in the Availaible Implementations section of the documentation.</p> <p>The rest of this document focuses on the general language constructs available in the TriggerMesh Integration Language, some of which are demonstrated in the previous snippet.</p>","location":"til/Concepts/#syntax"},{"title":"Component Blocks","text":"<p>Each configuration block represents a logical messaging component within a Bridge. These components are expressed as HCL blocks.</p> <p>The first keyword in a component block definition is the category of the component to represent. There are five categories of components available in the TriggerMesh Integration Language, which are described in details in the Component Categories section of the documentation.</p> <p>For example, the following component, taken from the previous code snippet, falls into the <code>source</code> category:</p> <pre><code>source github \"my_repo\" { }\n</code></pre> <p>NOTE: While all components are ultimately translated to Kubernetes manifests, there is not always a 1:1 relationship between a Bridge component and a Kubernetes API object.</p>","location":"til/Concepts/#component-blocks"},{"title":"Identifiers","text":"<p>A Bridge component accepts exactly two labels after the category keyword.</p> <p>The first label is the component type. It determines the schema of the configuration within the component block: its nested blocks and attributes, their type, whether they are mandatory or optional, etc. Its value must be a supported component type.</p> <p>The second label is the component identifier. It is used to uniquely identify the instance of a component within a given component category. Its value can be arbitrarily chosen.</p> <p>For example, the following component, taken from the previous code snippet, is of type <code>github</code> and is identified as <code>my_repo</code>:</p> <pre><code>source github \"my_repo\" { }\n</code></pre> <p>NOTE: Labels that appear in component blocks must be valid HCL identifiers, and can therefore be written either as quoted literal strings or naked identifiers (unquoted). By convention, all examples in this documentation use a naked identifier for the type label, and a quoted identifier for the component identifier label.</p>","location":"til/Concepts/#identifiers"},{"title":"References","text":"<p>Any messaging component that can send events is required to support references to other components. These references are used to determine the dependencies between components of a Bridge, and are automatically resolved to event addresses.</p> <p>A block reference is always expressed as a HCL variable expression in the format <code>&lt;CATEGORY&gt;.&lt;IDENTIFIER&gt;</code>. The referenced component must be defined within the Bridge.</p> <p>For example, the following component, taken from the previous code snippet, sends events to a component of type <code>target</code> identified as <code>github_archive_index</code>:</p> <pre><code>source github \"my_repo\" {\n  to = target.github_archive_index\n}\n</code></pre> <p>NOTE: Although there is no restriction in the language about what attribute name may represent a block reference, most component implementations use the attribute name <code>to</code> or <code>reply_to</code> by convention to represent such reference.</p>","location":"til/Concepts/#references"},{"title":"Expressions","text":"<p>In some contexts, the value of a given attribute may be determined by evaluating a HCL expression.</p> <p>For example, the following component, taken from the previous code snippet, has a <code>tokens</code> attribute which value is evaluated by calling a function named <code>secret_name</code>:</p> <pre><code>source github \"my_repo\" {\n  tokens = secret_name(\"github-source-tokens\")\n}\n</code></pre> <p>NOTE: Function expressions are documented in details in the Function Expressions section of the documentation.</p>","location":"til/Concepts/#expressions"},{"title":"Function Expresssions","text":"<p>The TriggerMesh Integration Language supports a few function expressions which can be used inside configuration blocks to generate attribute values. Those functions are executed at the time a Bridge description is evaluated.</p> <p>This document provides information about the syntax to use for calling functions inside a Bridge Description File, as well as a reference of all supported functions. </p>","location":"til/Function-Expressions/"},{"title":"Syntax","text":"<p>A function is represented as an expression composed of an identifier (function name) directly followed by a comma-separated list of arguments between parenthesis, such as:</p> <pre><code>function(argument1, argument2, ...)\n</code></pre> <p>The number and types of arguments as well as the type of the returned value depends on the function.</p>","location":"til/Function-Expressions/#syntax"},{"title":"Functions Reference","text":"<ul> <li>file</li> <li>secret_name</li> <li>secret_ref</li> </ul>","location":"til/Function-Expressions/#functions-reference"},{"title":"<code>file</code> Function","text":"<p>The <code>file</code> function reads a file from the local filesystem and returns its contents as a string.</p> <pre><code>file(path)\n</code></pre> <p>It is particularly relevant for attributes that accept multi-line data, such as in types of <code>target</code> or <code>transformer</code> blocks which embed inline code.</p>","location":"til/Function-Expressions/#file-function"},{"title":"Argument(s)","text":"<ul> <li><code>path</code>: path of the file, either absolute or relative to the directory of the Bridge Description file which calls the function.</li> </ul>","location":"til/Function-Expressions/#arguments"},{"title":"Example","text":"<pre><code>code = file(\"functions/my_function.js\")\n</code></pre>","location":"til/Function-Expressions/#example"},{"title":"<code>secret_name</code> Function","text":"<p>The sole purpose of the <code>secret_name</code> function is to expand a block's attribute into one or more references to Kubernetes Secrets.</p> <pre><code>secret_name(name)\n</code></pre> <p>It is used in very specific contexts, namely in attributes which represent secrets (e.g. credentials). The result of this function is typically expanded to SecretKeySelectors by implementations that know how to interpret its returned value.</p>","location":"til/Function-Expressions/#secret_name-function"},{"title":"Argument(s)","text":"<ul> <li><code>name</code>: name of the Secret object. Must be a valid Kubernetes object name (RFC 1123 subdomain).</li> </ul>","location":"til/Function-Expressions/#arguments_1"},{"title":"Example","text":"<pre><code>api_credentials = secret_name(\"my-api-credentials\")\n</code></pre>","location":"til/Function-Expressions/#example_1"},{"title":"<code>secret_ref</code> Function","text":"<p>The <code>secret_ref</code> function allows referencing a value from a Kubernetes Secret in attributes which support or require such property.</p> <pre><code>secret_ref(name, key)\n</code></pre> <p>It is used in very specific contexts, such as populating environment variables values in custom applications. The result of this function is an internal representation of a SecretKeySelector.</p>","location":"til/Function-Expressions/#secret_ref-function"},{"title":"Argument(s)","text":"<ul> <li><code>name</code>: name of the Secret object. Must be a valid Kubernetes object name (RFC 1123 subdomain).</li> <li><code>key</code>: data key to reference. Must consist of alphanumeric characters, '-', '_' or '.'.</li> </ul>","location":"til/Function-Expressions/#arguments_2"},{"title":"Example","text":"<pre><code>API_TOKEN: secret_ref(\"my-api-credentials\", \"token\")\n</code></pre>","location":"til/Function-Expressions/#example_2"},{"title":"Global Settings","text":"<p>The content of this document hasn't been finalized yet.</p> <p>Temporary redirect to the TriggerMesh Integration Language Specification (section 7. Component Categories)</p>","location":"til/Global-Settings/"},{"title":"Using Helm","text":"<p>Helm is one of the most popular package managers for Kubernetes. It uses a packaging format called chart which is used to version and deploy applications.</p> <p>The example below demonstrates how to use Helm to deploy a TriggerMesh Bridge and manage its lifecycle.</p>","location":"til/Helm/"},{"title":"Chart Initialization","text":"<p>Initialize a new Helm chart using the <code>helm</code> command-line tool:</p> <pre><code>$ helm create bridge-chart\nCreating bridge-chart\n</code></pre> <p>A file structure similar to the one below is automatically generated with multiple sample files:</p> <pre><code>bridge-chart\n\u251c\u2500\u2500 Chart.yaml\n\u251c\u2500\u2500 charts\n\u251c\u2500\u2500 templates\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 NOTES.txt\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 _helpers.tpl\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 deployment.yaml\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 hpa.yaml\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 ingress.yaml\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 service.yaml\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 serviceaccount.yaml\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 tests\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 test-connection.yaml\n\u2514\u2500\u2500 values.yaml\n</code></pre> <p>This file structure is explained in details in the Helm documentation at Charts &gt; The Chart File Structure. In this example, we simply replace all samples contained in the <code>templates</code> directory with the Bridge List-manifest generated by <code>til</code>:</p> <p><pre><code>$ rm -rf bridge-chart/templates/*\n</code></pre> <pre><code>$ til generate my-bridge.brg.hcl &gt; bridge-chart/templates/my-bridge-manifest.json\n</code></pre></p>","location":"til/Helm/#chart-initialization"},{"title":"Deployment","text":"<p>The chart can be deployed to the destination cluster using the command:</p> <pre><code>$ helm install my-bridge bridge-chart/\nNAME: my-bridge\nLAST DEPLOYED: Tue Apr 20 12:59:09 2021\nNAMESPACE: default\nSTATUS: deployed\nREVISION: 1\nTEST SUITE: None\n</code></pre> <p>The chart should appear as \"deployed\" in the list of Helm releases:</p> <pre><code>$ helm list\nNAME        NAMESPACE   REVISION   UPDATED               STATUS     CHART                APP VERSION\nmy-bridge   default     1          2021-04-20 12:59:09   deployed   bridge-chart-0.1.0   1.16.0\n</code></pre>","location":"til/Helm/#deployment"},{"title":"Updates","text":"<p>Any future modification to the Bridge description can be applied to the deployed release using the following command:</p> <pre><code>$ helm upgrade my-bridge bridge-chart/\nRelease \"my-bridge\" has been upgraded. Happy Helming!\nNAME: my-bridge\nLAST DEPLOYED: Tue Apr 20 13:18:47 2021\nNAMESPACE: default\nSTATUS: deployed\nREVISION: 2\nTEST SUITE: None\n</code></pre> <p>Under the hood, <code>helm upgrade</code> takes care of all lifecycle actions such as:</p> <ul> <li>Updating existing objects so they match the desired state described in the Bridge description.</li> <li>Creating objects that were added since the last Bridge release.</li> <li>Deleting objects that should no longer be part of the Bridge release.</li> </ul>","location":"til/Helm/#updates"},{"title":"Termination","text":"<p>To undo the deployment of an entire Bridge, simply uninstall its Helm release:</p> <pre><code>$ helm uninstall my-bridge\nrelease \"my-bridge\" uninstalled\n</code></pre>","location":"til/Helm/#termination"},{"title":"TriggerMesh Integration Language","text":"<p>The TriggerMesh Integration Language is a configuration language based on the HCL syntax which purpose is to provide a user-friendly interface for describing TriggerMesh Bridges.</p> <p>Using the <code>til</code> CLI tool, it is possible to turn Bridge descriptions into deployment manifests which can run complete messaging systems on the TriggerMesh platform.</p>  <p>Get Started with <code>til</code></p> <p>To learn how to install <code>til</code> and get started quickly with your first bridge go the TIL getting started guide.</p>","location":"til/Introduction/"},{"title":"CLI Features","text":"<ul> <li>Commands</li> </ul>","location":"til/Introduction/#cli-features"},{"title":"Language","text":"<ul> <li>Concepts</li> <li>Bridge Description Files</li> <li>Component Categories</li> <li>Global Settings</li> <li>Secret References</li> <li>Function Expressions</li> </ul>","location":"til/Introduction/#language"},{"title":"Available Implementations","text":"<ul> <li>Channels</li> <li>Routers</li> <li>Transformers</li> <li>Sources</li> <li>Targets</li> </ul>","location":"til/Introduction/#available-implementations"},{"title":"Deployment","text":"<p>The <code>til</code> CLI tool does not impose any particular deployment method on the user. Instead, it outputs deployment manifests in a format that is generic enough to be deployable by a variety of third-party tools. Pages in this section describe the format of the data generated by <code>til</code>, and provide concrete examples of using popular Kubernetes deployment tools to materialize a Bridge onto the TriggerMesh platform.</p> <ul> <li>Output format</li> <li>Using the TriggerMesh Bridges Operator</li> <li>Using Helm</li> <li>Using Carvel kapp</li> <li>Using kubectl</li> <li>Using kustomize</li> </ul>","location":"til/Introduction/#deployment"},{"title":"Using kubectl","text":"<p>kubectl is Kubernetes' standard command-line tool. It allows controlling Kubernetes clusters and interact with their resources.</p> <p>The example below demonstrates how to use kubectl to deploy a TriggerMesh Bridge.</p>","location":"til/Kubectl/"},{"title":"Deployment","text":"<p>A Bridge List-manifest can be piped directly to kubectl commands such as <code>kubectl create</code>, <code>kubectl apply</code> and <code>kubectl delete</code>, by using the <code>-</code> notation as the file name, which corresponds to the standard input:</p> <pre><code>$ til generate my-bridge.brg.hcl | kubectl create -f -\n</code></pre> <p>Alternatively, one can perform this same operation in two steps by saving the generated List-manifest to a file before applying it:</p> <p><pre><code>$ til generate my-bridge.brg.hcl &gt; my-bridge-manifest.json\n</code></pre> <pre><code>$ kubectl create -f my-bridge-manifest.json\nsomekind.example/some-name created\notherkind.example/other-name created\n[...]\n</code></pre></p>","location":"til/Kubectl/#deployment"},{"title":"Termination","text":"<p>It is possible to undo the deployment of an entire Bridge by deleting its Kubernetes objects:</p> <pre><code>$ til generate my-bridge.brg.hcl | kubectl delete -f -\nsomekind.example/some-name deleted\notherkind.example/other-name deleted\n[...]\n</code></pre>","location":"til/Kubectl/#termination"},{"title":"Important Considerations","text":"<p>One important aspect of kubectl to consider is that it doesn't keep track of the Kubernetes API objects related to a certain application. This applies to TriggerMesh Bridges too. Due to this limitation, re-applying a Bridge manifest after performing modifications to the Bridge description does not guarantee that the deployed state of this Bridge will remain consistent. In particular:</p> <ul> <li>Removing a block from the Bridge description does not cause a deletion of the corresponding Kubernetes objects in the destination cluster.</li> <li>Renaming a component causes the creation of new Kubernetes objects, but does not cause the deletion of objects previously created under a different name.</li> </ul> <p>For these reasons, TriggerMesh does not recommend using kubectl to maintain Bridges that may evolve over time. Its usage should be reserved for ephemeral Bridges resulting from experiments.</p>","location":"til/Kubectl/#important-considerations"},{"title":"Using kustomize","text":"<p>kustomize is a manifest customization tool built into kubectl. It allows performing template-free, structured customizations of Kubernetes manifests through generators and transformers defined in kustomization files.</p> <p>The example below demonstrates how to use kustomize to automatically add custom labels to all objects that compose a Bridge at deployment time, without touching the original List-manifest.</p>","location":"til/Kustomize/"},{"title":"Project Structure","text":"<p>Consider the project structure below, where:</p> <ul> <li><code>my-bridge-manifest.json</code> is a Bridge List-manifest generated by <code>til generate</code>.</li> <li><code>kustomization.yaml</code> is a kustomization file describing the desired transformations to perform on Kubernetes objects which compose the Bridge.</li> </ul> <pre><code>project\n\u251c\u2500\u2500 kustomization.yaml\n\u2514\u2500\u2500 my-bridge-manifest.json\n</code></pre> <p>In the kustomization file, we define:</p> <ul> <li>The labels to be injected under a <code>commonLabels</code> field (in this case, an ID and a revision).</li> <li>The resources these transformations apply to under a <code>resources</code> field (the generated Bridge List-manifest).</li> </ul> <pre><code>apiVersion: kustomize.config.k8s.io/v1beta1\nkind: Kustomization\n\ncommonLabels:\n  bridges.triggermesh.io/id: my-bridge\n  bridges.triggermesh.io/revision: \"1\"\n\nresources:\n- my-bridge-manifest.json\n</code></pre>","location":"til/Kustomize/#project-structure"},{"title":"Deployment","text":"<p>The resulting Kubernetes manifests can either be generated to standard output using the command:</p> <pre><code>$ kubectl kustomize project/\napiVersion: example/v1\nkind: SomeKind\nmetadata:\n  labels:\n    bridges.triggermesh.io/id: my-bridge\n    bridges.triggermesh.io/revision: \"1\"\n  name: some-name\n[...]\n</code></pre> <p>Or they can be deployed directly to the destination cluster using the command:</p> <pre><code>$ kubectl create -k project/\nsomekind.example/some-name created\notherkind.example/other-name created\n[...]\n</code></pre>","location":"til/Kustomize/#deployment"},{"title":"Termination","text":"<p>To undo the deployment of a Bridge, simply delete its Kubernetes objects:</p> <pre><code>$ kubectl delete -k project/\nsomekind.example/some-name deleted\notherkind.example/other-name deleted\n[...]\n</code></pre>","location":"til/Kustomize/#termination"},{"title":"Important Considerations","text":"<p>Please note that using kustomize for deploying complex applications, including TriggerMesh Bridges, has the same limitations as the ones described in the kubectl page.</p>","location":"til/Kustomize/#important-considerations"},{"title":"Output Format","text":"<p>By default, a Bridge gets generated as a collection of Kubernetes API objects under a parent Kubernetes object of kind <code>List</code>. If you are already familiar with kubectl, a <code>List</code> object is what gets returned by the <code>kubectl get</code> command when its arguments are object kinds without object names (as in <code>kubectl get pods</code>). This object is referred to as List-manifest in the rest of this documentation.</p> <p>Alternatively, <code>til</code> can output Kubernetes objects as a sequence of YAML documents, or as a TriggerMesh <code>Bridge</code> object. Please refer to the documentation about CLI commands for more information.</p>","location":"til/Output-Format/"},{"title":"List-manifest","text":"<p>A List-manifest is serialized in the JSON format, which is the canonical data format to interact with the Kubernetes REST API. JSON is also more portable than YAML, another data format popular among Kubernetes users, which support is lacking in the standard library of most programming languages.</p> <p>Below is an example of output produced by <code>til</code>. Each element of the array represented by the <code>items</code> key is an individual Kubernetes API object:</p> <pre><code>{\n  \"apiVersion\": \"v1\",\n  \"kind\": \"List\",\n  \"items\": [\n    {\n      \"apiVersion\": \"example/v1\",\n      \"kind\": \"SomeKind\",\n      \"metadata\": {\n        \"name\": \"some-name\",\n      },\n      // ...\n    },\n    {\n      \"apiVersion\": \"example/v1\",\n      \"kind\": \"OtherKind\",\n      \"metadata\": {\n        \"name\": \"other-name\",\n      },\n      // ...\n    },\n    /*\n       more Kubernetes API objects\n    */\n  ]\n}\n</code></pre>","location":"til/Output-Format/#list-manifest"},{"title":"Routers","text":"","location":"til/Routers/"},{"title":"Full list","text":"<ul> <li>Content-Based</li> <li>Data Expression Filter</li> <li>Splitter</li> </ul>","location":"til/Routers/#full-list"},{"title":"Content-Based","text":"<p>Fans out events to selected destinations, with optional filtering conditions based on context attributes and/or the data payload.</p> <pre><code>router content_based \"dispatch\" {\n\n  route {\n    //to = &lt;component&gt;.&lt;identifier&gt;\n  }\n\n  route {\n    attributes = {\n      type: \"com.amazon.sqs.message\"\n      source: \"arn:aws:sqs:us-east-2:123456789012:my-queue\"\n    }\n\n    //to = &lt;component&gt;.&lt;identifier&gt;\n  }\n\n  route {\n    condition = \"$user.id.(int64) % 2 == 0\"\n\n    //to = &lt;component&gt;.&lt;identifier&gt;\n  }\n\n}\n</code></pre>","location":"til/Routers/#content-based"},{"title":"Data Expression Filter","text":"<pre><code>router data_expression_filter \"uid_is_even\" {\n  condition = \"$user.id.(int64) % 2 == 0\"\n\n  //to = &lt;component&gt;.&lt;identifier&gt;\n}\n</code></pre>","location":"til/Routers/#data-expression-filter"},{"title":"Splitter","text":"<pre><code>router splitter \"split_users\" {\n  path = \".items\"\n\n  ce_context {\n    type = \"ldap.user\"\n    source = \"ldap://mycompany\"\n    extensions = {\n      uid: \"{.details.user_id}\"\n    }\n  }\n\n  //to = &lt;component&gt;.&lt;identifier&gt;\n}\n</code></pre>","location":"til/Routers/#splitter"},{"title":"Secret References","text":"<p>Some Bridge components require access to secret values, such as credentials, in order to operate. These values are, in most cases, stored inside Kubernetes Secret objects, which administrators are responsible for making readily available to integrations which require them.</p> <p>The TriggerMesh Integration Language relies on the notion of secret class to support the multitude of integrations available within TriggerMesh Bridges. Similarly to Kubernetes built-in secret types, a secret class is simply a list of requirements which must be satisfied by a Secret object, such as the number, name and format of the values present in the data of this Secret.</p>","location":"til/Secret-References/"},{"title":"Usage of Secret References","text":"<p>Inside a component configuration body, secrets are referenced by name using the <code>secret_name</code> function. The Secret corresponding to the given name parameter is expected to be deployed in the same Kubernetes namespace as the deployed Bridge.</p> <p>Example:</p> <pre><code>source example \"my_source\" {\n  api_credentials = secret_name(\"my-credentials\")\n}\n</code></pre> <p>Please refer to the documentation of individual components in order to know what secret class to use in a certain context, and which data keys are supported/required by each component.</p>","location":"til/Secret-References/#usage-of-secret-references"},{"title":"Secret Classes Reference","text":"<p>Below is a reference of all secret classes currently used by component implementations available in <code>til</code>. For each class, an example of kubectl command is provided to help you create an instance of this particular type of secret in the destination cluster.</p>  <ul> <li>aws</li> <li>azure_sp</li> <li>basic_auth</li> <li>datadog</li> <li>gcloud_service_account</li> <li>github</li> <li>kafka</li> <li>logz</li> <li>salesforce_oauth_jwt</li> <li>sendgrid</li> <li>slack</li> <li>slack_app</li> <li>splunk_hec</li> <li>tls</li> <li>twilio</li> <li>zendesk</li> </ul>","location":"til/Secret-References/#secret-classes-reference"},{"title":"<code>aws</code> Secret Class","text":"<p>Used to authenticate to Amazon Web Services (AWS) with access keys.</p>","location":"til/Secret-References/#aws-secret-class"},{"title":"Data Key(s)","text":"<ul> <li><code>access_key_id</code>: access key ID (example: \"AKIAIOSFODNN7EXAMPLE\")</li> <li><code>secret_access_key</code>: secret access key (example: \"wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\")</li> </ul>","location":"til/Secret-References/#data-keys"},{"title":"Create Command","text":"<pre><code>kubectl create secret generic &lt;SECRET_NAME&gt; \\\n  --from-literal=access_key_id=&lt;ACCESS_KEY_ID&gt; \\\n  --from-literal=secret_access_key=&lt;SECRET_ACCESS_KEY&gt;\n</code></pre>","location":"til/Secret-References/#create-command"},{"title":"<code>azure_sp</code> Secret Class","text":"<p>Used to authenticate to Microsoft Azure services with a service principal.</p>","location":"til/Secret-References/#azure_sp-secret-class"},{"title":"Data Key(s)","text":"<ul> <li><code>tenant_id</code>: tenant ID of the Azure application represented by the service principal (example: \"1a23b45c-6789-1a2b-3c4d-00000EXAMPLE\")</li> <li><code>client_id</code>: client ID of the Azure application (example: \"1a23b45c-6789-1a2b-3c4d-00000EXAMPLE\")</li> <li><code>client_secret</code>: client secret of the Azure application</li> </ul>","location":"til/Secret-References/#data-keys_1"},{"title":"Create Command","text":"<pre><code>kubectl create secret generic &lt;SECRET_NAME&gt; \\\n  --from-literal=tenant_id=&lt;TENANT_ID&gt; \\\n  --from-literal=client_id=&lt;CLIENT_ID&gt; \\\n  --from-literal=client_secret=&lt;CLIENT_SECRET&gt;\n</code></pre>","location":"til/Secret-References/#create-command_1"},{"title":"<code>basic_auth</code> Secret Class","text":"<p>Used to serve or authenticate against a web endpoint which supports basic authentication.</p>","location":"til/Secret-References/#basic_auth-secret-class"},{"title":"Data Key(s)","text":"<ul> <li><code>username</code>: name of the user to authenticate as</li> <li><code>password</code>: password of the selected user</li> </ul>","location":"til/Secret-References/#data-keys_2"},{"title":"Create Command","text":"<pre><code>kubectl create secret generic &lt;SECRET_NAME&gt; \\\n  --from-literal=username=&lt;USERNAME&gt; \\\n  --from-literal=password=&lt;PASSWORD&gt;\n</code></pre>","location":"til/Secret-References/#create-command_2"},{"title":"<code>datadog</code> Secret Class","text":"<p>Used to authenticate to the Datadog API.</p>","location":"til/Secret-References/#datadog-secret-class"},{"title":"Data Key(s)","text":"<ul> <li><code>apiKey</code>: API key (example: \"1a23b45c-6789-1a2b-3c4d-00000EXAMPLE\")</li> </ul>","location":"til/Secret-References/#data-keys_3"},{"title":"Create Command","text":"<pre><code>kubectl create secret generic &lt;SECRET_NAME&gt; \\\n  --from-literal=apiKey=&lt;API_KEY&gt;\n</code></pre>","location":"til/Secret-References/#create-command_3"},{"title":"<code>gcloud_service_account</code> Secret Class","text":"<p>Used to authenticate to Google Cloud services with a service account.</p>","location":"til/Secret-References/#gcloud_service_account-secret-class"},{"title":"Data Key(s)","text":"<ul> <li><code>key.json</code>: service account key in JSON format (example: \"{\\\"type\\\":\\\"service_account\\\", ...}\")</li> </ul>","location":"til/Secret-References/#data-keys_4"},{"title":"Create Command","text":"<pre><code>kubectl create secret generic &lt;SECRET_NAME&gt; \\\n  --from-literal=key.json=&lt;KEY&gt;\n</code></pre>","location":"til/Secret-References/#create-command_4"},{"title":"<code>github</code> Secret Class","text":"<p>Used to authenticate to the GitHub API and validate requests originating from GitHub Apps.</p>","location":"til/Secret-References/#github-secret-class"},{"title":"Data Key(s)","text":"<ul> <li><code>access_token</code>: access token to interact with the API</li> <li><code>webhook_secret</code>: secret token for securing webhooks</li> </ul>","location":"til/Secret-References/#data-keys_5"},{"title":"Create Command","text":"<pre><code>kubectl create secret generic &lt;SECRET_NAME&gt; \\\n  --from-literal=access_token=&lt;ACCESS_TOKEN&gt; \\\n  --from-literal=webhook_secret=&lt;WEBHOOK_SECRET&gt;\n</code></pre>","location":"til/Secret-References/#create-command_5"},{"title":"<code>kafka</code> Secret Class","text":"<p>Used to authenticate to Kafka brokers using different types of authentication mechanisms and protocols. Please consult the documentation of the Kafka Sink (Knative) for more details.</p>","location":"til/Secret-References/#kafka-secret-class"},{"title":"Data Key(s)","text":"<ul> <li><code>protocol</code>: protocol to use for communicating with Kafka brokers (example: \"SASL_PLAINTEXT\", \"SASL_SSL\")</li> <li><code>sasl.mechanism</code>: SASL authentication mechanism to use, if supported (example: \"PLAIN\", \"SCRAM-SHA-256\")</li> <li><code>ca.crt</code>: certificate chain of a Certificate Authority (CA) for checking the authenticity of TLS connections (if enabled)</li> <li><code>user</code>: (SASL authentication) name of the user to authenticate</li> <li><code>password</code>: (SASL authentication) password of the selected user</li> <li><code>user.crt</code>: (TLS authentication) X.509 certificate, in PEM format (example: \"-----BEGIN CERTIFICATE-----\\nMIIH...\\n-----END CERTIFICATE-----\")</li> <li><code>user.key</code>: (TLS authentication) private key associated with the certificate, in PEM format (example: \"-----BEGIN PRIVATE KEY-----\\nMIIE...\\n-----END PRIVATE KEY-----\")</li> <li><code>user.skip</code>: skip user authentication</li> </ul>","location":"til/Secret-References/#data-keys_6"},{"title":"Create Command","text":"<pre><code>kubectl create secret generic &lt;SECRET_NAME&gt; \\\n  --from-literal=protocol=&lt;PROTOCOL&gt; \\\n  --from-literal=sasl.mechanism=&lt;SASL_MECHANISM&gt; \\\n  --from-file=ca.crt=&lt;CA_CERTIFICATE&gt; \\\n  --from-literal=user=&lt;USER&gt; \\\n  --from-literal=password=&lt;PASSWORD&gt; \\\n  --from-file=user.crt=&lt;USER_CERTIFICATE&gt; \\\n  --from-file=user.key=&lt;CERTIFICATE_KEY&gt; \\\n  --from-literal=user.skip=&lt;BOOLEAN&gt;\n</code></pre>","location":"til/Secret-References/#create-command_6"},{"title":"<code>logz</code> Secret Class","text":"<p>Used to authenticate to the Logz.io with an API token.</p>","location":"til/Secret-References/#logz-secret-class"},{"title":"Data Key(s)","text":"<ul> <li><code>token</code>: API token (example: \"VF2ZTc1R73SMtoN3CLiSDuG1nEXAMPLEAPITOKEN\")</li> </ul>","location":"til/Secret-References/#data-keys_7"},{"title":"Create Command","text":"<pre><code>kubectl create secret generic &lt;SECRET_NAME&gt; \\\n  --from-literal=token=&lt;TOKEN&gt;\n</code></pre>","location":"til/Secret-References/#create-command_7"},{"title":"<code>salesforce_oauth_jwt</code> Secret Class","text":"<p>Used to authenticate requests to the Salesforce API using the OAuth 2.0 JWT bearer token flow.</p>","location":"til/Secret-References/#salesforce_oauth_jwt-secret-class"},{"title":"Data Key(s)","text":"<ul> <li><code>secret_key</code>: private key associated with the certificate used as the JWT signing secret (example: \"-----BEGIN PRIVATE KEY-----\\nMIIE...\\n-----END PRIVATE KEY-----\")</li> </ul>","location":"til/Secret-References/#data-keys_8"},{"title":"Create Command","text":"<pre><code>kubectl create secret generic &lt;SECRET_NAME&gt; \\\n  --from-literal=secret_key=&lt;SECRET_KEY&gt;\n</code></pre>","location":"til/Secret-References/#create-command_8"},{"title":"<code>sendgrid</code> Secret Class","text":"<p>Used to authenticate to the Sendgrid API.</p>","location":"til/Secret-References/#sendgrid-secret-class"},{"title":"Data Key(s)","text":"<ul> <li><code>apiKey</code>: API key (example: \"SG.1FF3NpJbSPiD7kg04l9rXw.qLVd-PwJWX6tkEIJ2EXAMPLEKEY\")</li> </ul>","location":"til/Secret-References/#data-keys_9"},{"title":"Create Command","text":"<pre><code>kubectl create secret generic &lt;SECRET_NAME&gt; \\\n  --from-literal=apiKey=&lt;API_KEY&gt;\n</code></pre>","location":"til/Secret-References/#create-command_9"},{"title":"<code>slack</code> Secret Class","text":"<p>Used to authenticate to Slack APIs with a bearer token.</p>","location":"til/Secret-References/#slack-secret-class"},{"title":"Data Key(s)","text":"<ul> <li><code>token</code>: bearer token (example: \"xoxb-000000000000-00EXAMPLETOKEN\")</li> </ul>","location":"til/Secret-References/#data-keys_10"},{"title":"Create Command","text":"<pre><code>kubectl create secret generic &lt;SECRET_NAME&gt; \\\n  --from-literal=token=&lt;SIGNING_SECRET&gt;\n</code></pre>","location":"til/Secret-References/#create-command_10"},{"title":"<code>slack_app</code> Secret Class","text":"<p>Used to verify requests originating from Slack in Slack apps.</p>","location":"til/Secret-References/#slack_app-secret-class"},{"title":"Data Key(s)","text":"<ul> <li><code>signing_secret</code>: signing secret of the app (example: \"8f742231b10e8888abcd99yyyzzz85a5\")</li> </ul>","location":"til/Secret-References/#data-keys_11"},{"title":"Create Command","text":"<pre><code>kubectl create secret generic &lt;SECRET_NAME&gt; \\\n  --from-literal=signing_secret=&lt;SIGNING_SECRET&gt;\n</code></pre>","location":"til/Secret-References/#create-command_11"},{"title":"<code>splunk_hec</code> Secret Class","text":"<p>Used to authenticate to a Splunk HTTP Event Collector.</p>","location":"til/Secret-References/#splunk_hec-secret-class"},{"title":"Data Key(s)","text":"<ul> <li><code>hec_token</code>: HEC token (example: \"1a23b45c-6789-1a2b-3c4d-00000EXAMPLE\")</li> </ul>","location":"til/Secret-References/#data-keys_12"},{"title":"Create Command","text":"<pre><code>kubectl create secret generic &lt;SECRET_NAME&gt; \\\n  --from-literal=hec_token=&lt;HEC_TOKEN&gt;\n</code></pre>","location":"til/Secret-References/#create-command_12"},{"title":"<code>tls</code> Secret Class","text":"<p>Used to authenticate to HTTP(S) endpoints using TLS Client Authentication.</p>","location":"til/Secret-References/#tls-secret-class"},{"title":"Data Key(s)","text":"<ul> <li><code>certificate</code>: X.509 certificate, usually in PEM format (example: \"-----BEGIN CERTIFICATE-----\\nMIIH...\\n-----END CERTIFICATE-----\")</li> <li><code>key</code>: private key associated with the certificate, usually in PEM format (example: \"-----BEGIN PRIVATE KEY-----\\nMIIE...\\n-----END PRIVATE KEY-----\")</li> <li><code>ca_certificate</code>: certificate chain of a Certificate Authority (CA) for checking the authenticity of TLS connections</li> </ul>","location":"til/Secret-References/#data-keys_13"},{"title":"Create Command","text":"<pre><code>kubectl create secret generic &lt;SECRET_NAME&gt; \\\n  --from-literal=certificate=&lt;CERTIFICATE&gt; \\\n  --from-literal=key=&lt;KEY&gt; \\\n  --from-literal=ca_certificate=&lt;CA_CERTIFICATE&gt;\n</code></pre>","location":"til/Secret-References/#create-command_13"},{"title":"<code>twilio</code> Secret Class","text":"<p>Used to authenticate to the Twilio API with an auth token.</p>","location":"til/Secret-References/#twilio-secret-class"},{"title":"Data Key(s)","text":"<ul> <li><code>sid</code>: account SID (example: \"AC0000000000000000000EXAMPLESID\")</li> <li><code>token</code>: auth token</li> </ul>","location":"til/Secret-References/#data-keys_14"},{"title":"Create Command","text":"<pre><code>kubectl create secret generic &lt;SECRET_NAME&gt; \\\n  --from-literal=sid=&lt;ACCOUNT_SID&gt; \\\n  --from-literal=token=&lt;AUTH_TOKEN&gt;\n</code></pre>","location":"til/Secret-References/#create-command_14"},{"title":"<code>zendesk</code> Secret Class","text":"<p>Used to authenticate to Zendesk APIs with an API token.</p>","location":"til/Secret-References/#zendesk-secret-class"},{"title":"Data Key(s)","text":"<ul> <li><code>token</code>: API token (example: \"VF2ZTc1R73SMtoN3CLiSDuG1nEXAMPLEAPITOKEN\")</li> </ul>","location":"til/Secret-References/#data-keys_15"},{"title":"Create Command","text":"<pre><code>kubectl create secret generic &lt;SECRET_NAME&gt; \\\n  --from-literal=token=&lt;TOKEN&gt;\n</code></pre>","location":"til/Secret-References/#create-command_15"},{"title":"Sources","text":"","location":"til/Sources/"},{"title":"Full list","text":"<ul> <li>Amazon CloudWatch</li> <li>Amazon CloudWatch Logs</li> <li>Amazon CodeCommit</li> <li>Amazon Cognito User Pool</li> <li>Amazon DynamoDB</li> <li>Amazon Kinesis</li> <li>Amazon RDS Performance Insights</li> <li>Amazon S3</li> <li>Amazon SNS</li> <li>Amazon SQS</li> <li>Azure Activity Logs</li> <li>Azure Blob Storage</li> <li>Azure Event Hubs</li> <li>GitHub</li> <li>HTTP Poller</li> <li>Kafka</li> <li>Ping</li> <li>Salesforce</li> <li>Slack</li> <li>Webhook</li> <li>Zendesk</li> </ul>","location":"til/Sources/#full-list"},{"title":"Amazon CloudWatch","text":"<pre><code>source aws_cloudwatch \"my_metrics\" {\n  region = \"us-east-2\"\n\n  polling_interval = \"5m\" // optional\n\n  metric_query \"query1\" {\n    // mutually exclusive with \"metric\"\n    expression = \"SEARCH(' {AWS/EC2} MetricName=\\\"CPUUtilization\\\" ', 'Average', 300)\"\n  }\n\n  metric_query \"query2\" {\n    // mutually exclusive with \"expression\"\n    metric {\n      period = 60\n      stat = \"p90\"\n      unit = \"Milliseconds\"\n\n      name = \"Duration\"\n      namespace = \"AWS/Lambda\"\n\n      dimension \"FunctionName\" {\n        value = \"lambdadumper\"\n      }\n    }\n  }\n\n  credentials = secret_name(\"my-aws-access-keys\")\n\n  //to = &lt;component&gt;.&lt;identifier&gt;\n}\n</code></pre> <p>Secret class: aws</p>","location":"til/Sources/#amazon-cloudwatch"},{"title":"Amazon CloudWatch Logs","text":"<pre><code>source aws_cloudwatch_logs \"my_logs\" {\n  arn = \"arn:aws:logs:us-east-2:123456789012:log-group:/my/log/group:*\"\n\n  polling_interval = \"5m\" // optional\n\n  credentials = secret_name(\"my-aws-access-keys\")\n\n  //to = &lt;component&gt;.&lt;identifier&gt;\n}\n</code></pre> <p>Secret class: aws</p>","location":"til/Sources/#amazon-cloudwatch-logs"},{"title":"Amazon CodeCommit","text":"<pre><code>source aws_codecommit \"my_repo\" {\n  arn = \"arn:aws:codecommit:us-east-2:123456789012:my-repo\"\n\n  branch = \"main\"\n  event_types = [\"push\", \"pull_request\"]\n\n  credentials = secret_name(\"my-aws-access-keys\")\n\n  //to = &lt;component&gt;.&lt;identifier&gt;\n}\n</code></pre> <p>Secret class: aws</p>","location":"til/Sources/#amazon-codecommit"},{"title":"Amazon Cognito User Pool","text":"<pre><code>source aws_cognito_userpool \"my_userpool\" {\n  arn = \"arn:aws:cognito-idp:us-east-2:123456789012:userpool/my-pool\"\n\n  credentials = secret_name(\"my-aws-access-keys\")\n\n  //to = &lt;component&gt;.&lt;identifier&gt;\n}\n</code></pre> <p>Secret class: aws</p>","location":"til/Sources/#amazon-cognito-user-pool"},{"title":"Amazon DynamoDB","text":"<pre><code>source aws_dynamodb \"my_table\" {\n  arn = \"arn:aws:dynamodb:us-east-2:123456789012:table/my-table\"\n\n  credentials = secret_name(\"my-aws-access-keys\")\n\n  //to = &lt;component&gt;.&lt;identifier&gt;\n}\n</code></pre> <p>Secret class: aws</p>","location":"til/Sources/#amazon-dynamodb"},{"title":"Amazon Kinesis","text":"<pre><code>source aws_kinesis \"my_stream\" {\n  arn = \"arn:aws:kinesis:us-east-2:123456789012:stream/my-stream\"\n\n  credentials = secret_name(\"my-aws-access-keys\")\n\n  //to = &lt;component&gt;.&lt;identifier&gt;\n}\n</code></pre> <p>Secret class: aws</p>","location":"til/Sources/#amazon-kinesis"},{"title":"Amazon RDS Performance Insights","text":"<pre><code>source aws_pi \"my_db_metrics\" {\n  arn = \"arn:aws:rds:us-east-2:123456789012:db:my-instance\"\n\n  polling_interval = \"5m\"\n\n  metric_queries = [\n    \"os.cpuUtilization.user.avg\",\n    \"os.fileSys.used.avg\",\n  ]\n\n  credentials = secret_name(\"my-aws-access-keys\")\n\n  //to = &lt;component&gt;.&lt;identifier&gt;\n}\n</code></pre> <p>Secret class: aws</p>","location":"til/Sources/#amazon-rds-performance-insights"},{"title":"Amazon S3","text":"<pre><code>source aws_s3 \"my_bucket\" {\n  arn = \"arn:aws:s3:us-east-2:123456789012:my-bucket\"\n\n  event_types = [\n    \"s3:ObjectCreated:*\",\n    \"s3:ObjectRemoved:*\",\n  ]\n\n  credentials = secret_name(\"my-aws-access-keys\")\n\n  //to = &lt;component&gt;.&lt;identifier&gt;\n}\n</code></pre> <p>Secret class: aws</p>","location":"til/Sources/#amazon-s3"},{"title":"Amazon SNS","text":"<pre><code>source aws_sns \"my_topic\" {\n  arn = \"arn:aws:sns:us-east-2:123456789012:my-topic\"\n\n  credentials = secret_name(\"my-aws-access-keys\")\n\n  //to = &lt;component&gt;.&lt;identifier&gt;\n}\n</code></pre> <p>Secret class: aws</p>","location":"til/Sources/#amazon-sns"},{"title":"Amazon SQS","text":"<pre><code>source aws_sqs \"my_queue\" {\n  arn = \"arn:aws:sqs:us-east-2:123456789012:my-queue\"\n\n  credentials = secret_name(\"my-aws-access-keys\")\n\n  //to = &lt;component&gt;.&lt;identifier&gt;\n}\n</code></pre> <p>Secret class: aws</p>","location":"til/Sources/#amazon-sqs"},{"title":"Azure Activity Logs","text":"<pre><code>source azure_activity_logs \"audit_logs\" {\n  subscription_id = \"1234\"\n\n  event_hubs_namespace_id = \"/subscriptions/1234/resourceGroups/my-group/providers/Microsoft.EventHub/namespaces/mylogs\"\n  event_hub_name = \"activity-logs\" //optional\n  event_hubs_sas_policy = \"RootManageSharedAccessKey\" // optional\n\n  categories = [\"Administrative\", \"Security\", \"Policy\"] // optional\n\n  auth = secret_name(\"my-azure-service-principal\")\n\n  //to = &lt;component&gt;.&lt;identifier&gt;\n}\n</code></pre> <p>Secret class: azure_sp</p>","location":"til/Sources/#azure-activity-logs"},{"title":"Azure Blob Storage","text":"<pre><code>source azure_blob_storage \"my_files\" {\n  storage_account_id = \"/subscriptions/1234/resourceGroups/my-group/providers/Microsoft.Storage/storageAccounts/myfiles\"\n\n  event_hubs_namespace_id = \"/subscriptions/1234/resourceGroups/my-group/providers/Microsoft.EventHub/namespaces/myevents\"\n  event_hub_name = \"files-events\" //optional\n\n  event_types = [\"Microsoft.Storage.BlobCreated\", \"Microsoft.Storage.BlobDeleted\"] // optional\n\n  auth = secret_name(\"my-azure-service-principal\")\n\n  //to = &lt;component&gt;.&lt;identifier&gt;\n}\n</code></pre> <p>Secret class: azure_sp</p>","location":"til/Sources/#azure-blob-storage"},{"title":"Azure Event Hubs","text":"<pre><code>source azure_event_hubs \"user_events\" {\n  hub_namespace = \"myapp\"\n  hub_name = \"users\"\n\n  auth = secret_name(\"my-azure-service-principal\")\n\n  //to = &lt;component&gt;.&lt;identifier&gt;\n}\n</code></pre> <p>Secret class: azure_sp</p>","location":"til/Sources/#azure-event-hubs"},{"title":"GitHub","text":"<pre><code>source github \"my_repo\" {\n  owner_and_repository = \"triggermesh/bridges\"\n\n  event_types = [ \"push\", \"pull_request\" ]\n\n  tokens = secret_name(\"github-source-tokens\")\n\n  //to = &lt;component&gt;.&lt;identifier&gt;\n}\n</code></pre> <p>Secret class: github</p>","location":"til/Sources/#github"},{"title":"HTTP Poller","text":"<pre><code>source httppoller \"scrape_weather\" {\n  endpoint = \"https://api.weather.gov/alerts/active?area=KS\"\n  method = \"GET\"\n  interval = \"5m\"\n\n  event_type = \"weather.alert\"\n  event_source = \"weather.gov/alerts/kansas\" // optional\n\n  //to = &lt;component&gt;.&lt;identifier&gt;\n}\n</code></pre>","location":"til/Sources/#http-poller"},{"title":"Kafka","text":"<pre><code>source kafka \"my_topics\" {\n  topics = [ \"users\", \"transactions\" ]\n\n  bootstrap_servers = [\n    \"kafka1.example.com:9092\",\n    \"kafka2.example.com:9092\",\n  ]\n\n  consumer_group = \"knative\" // optional\n\n  sasl_auth = secret_name(\"kafka-credentials\") // optional\n\n  tls = secret_name(\"kafka-tls\") // optional\n  tls = true // optional - enables TLS without referencing additional certificates\n\n  //to = &lt;component&gt;.&lt;identifier&gt;\n}\n</code></pre> <p>Secret class: kafka</p>","location":"til/Sources/#kafka"},{"title":"Ping","text":"<pre><code>source ping \"every_10_minutes\" {\n  data = \"{ \\\"msg\\\": \\\"Hello, World!\\\" }\"\n  content_type = \"application/json\" // optional\n\n  schedule = \"*/10 * * * *\" // optional\n\n  //to = &lt;component&gt;.&lt;identifier&gt;\n}\n</code></pre>","location":"til/Sources/#ping"},{"title":"Salesforce","text":"<pre><code>source salesforce \"my_leads\" {\n  channel = \"/data/ChangeEvents\"\n  replay_id = -2 // optional\n\n  client_id = \"my_client_id\"\n  server = \"https://login.salesforce.com\"\n  user = \"woodford@example.com\"\n  secret_key = secret_name(\"salesforce-oauth-cert-key\")\n\n  //to = &lt;component&gt;.&lt;identifier&gt;\n}\n</code></pre> <p>Secret class: salesforce</p>","location":"til/Sources/#salesforce"},{"title":"Slack","text":"<pre><code>source slack \"my_app\" {\n  signing_secret = secret_name(\"my-app-secret\") // optional\n  app_id = \"A12345\" // optional\n\n  //to = &lt;component&gt;.&lt;identifier&gt;\n}\n</code></pre> <p>Secret class: slack_app</p>","location":"til/Sources/#slack"},{"title":"Webhook","text":"<pre><code>source webhook \"my_webhook\" {\n  event_type = \"com.example.mysample.event\"\n  event_source = \"instance-abc123\" // optional\n\n  basic_auth_username = \"user\" // optional\n  basic_auth_password = \"abc123secret\" // optional\n\n  //to = &lt;component&gt;.&lt;identifier&gt;\n}\n</code></pre>","location":"til/Sources/#webhook"},{"title":"Zendesk","text":"<pre><code>source zendesk \"my_tickets\" {\n  subdomain = \"mycompany\"\n\n  email = \"woodford@example.com\"\n  api_auth = secret_name(\"my-zendesk-api-token\")\n\n  webhook_username = \"user\"\n  webhook_password = \"abc123secret\"\n\n  //to = &lt;component&gt;.&lt;identifier&gt;\n}\n</code></pre> <p>Secret class: zendesk</p>","location":"til/Sources/#zendesk"},{"title":"Targets","text":"","location":"til/Targets/"},{"title":"Full list","text":"<ul> <li>Amazon DynamoDB</li> <li>Amazon Kinesis</li> <li>Amazon Lambda</li> <li>Amazon S3</li> <li>Amazon SNS</li> <li>Amazon SQS</li> <li>Container</li> <li>Datadog</li> <li>Event Display</li> <li>Function</li> <li>Google Cloud Firestore</li> <li>Google Cloud Storage</li> <li>Kafka</li> <li>Logz</li> <li>Sendgrid</li> <li>Slack</li> <li>Sockeye</li> <li>Splunk</li> <li>Twilio</li> <li>Zendesk</li> </ul>","location":"til/Targets/#full-list"},{"title":"Amazon DynamoDB","text":"<pre><code>target aws_dynamodb \"my_table\" {\n  arn = \"arn:aws:dynamodb:us-east-2:123456789012:table/my-table\"\n\n  credentials = secret_name(\"my-aws-access-keys\")\n\n  //reply_to = &lt;component&gt;.&lt;identifier&gt;\n}\n</code></pre> <p>Secret class: aws</p>","location":"til/Targets/#amazon-dynamodb"},{"title":"Amazon Kinesis","text":"<pre><code>target aws_kinesis \"my_stream\" {\n  arn = \"arn:aws:kinesis:us-east-2:123456789012:stream/my-stream\"\n\n  credentials = secret_name(\"my-aws-access-keys\")\n\n  //reply_to = &lt;component&gt;.&lt;identifier&gt;\n}\n</code></pre> <p>Secret class: aws</p>","location":"til/Targets/#amazon-kinesis"},{"title":"Amazon Lambda","text":"<pre><code>target aws_lambda \"my_userpool\" {\n  arn = \"arn:aws:cognito-idp:us-east-2:123456789012:userpool/my-pool\"\n\n  credentials = secret_name(\"my-aws-access-keys\")\n\n  //reply_to = &lt;component&gt;.&lt;identifier&gt;\n}\n</code></pre> <p>Secret class: aws</p>","location":"til/Targets/#amazon-lambda"},{"title":"Amazon S3","text":"<pre><code>target aws_s3 \"my_bucket\" {\n  arn = \"arn:aws:s3:::my-bucket\"\n\n  credentials = secret_name(\"my-aws-access-keys\")\n\n  //reply_to = &lt;component&gt;.&lt;identifier&gt;\n}\n</code></pre> <p>Secret class: aws</p>","location":"til/Targets/#amazon-s3"},{"title":"Amazon SNS","text":"<pre><code>target aws_sns \"my_topic\" {\n  arn = \"arn:aws:sns:us-east-2:123456789012:my-topic\"\n\n  credentials = secret_name(\"my-aws-access-keys\")\n\n  //reply_to = &lt;component&gt;.&lt;identifier&gt;\n}\n</code></pre> <p>Secret class: aws</p>","location":"til/Targets/#amazon-sns"},{"title":"Amazon SQS","text":"<pre><code>target aws_sqs \"my_queue\" {\n  arn = \"arn:aws:sqs:us-east-2:123456789012:my-queue\"\n\n  credentials = secret_name(\"my-aws-access-keys\")\n\n  //reply_to = &lt;component&gt;.&lt;identifier&gt;\n}\n</code></pre> <p>Secret class: aws</p>","location":"til/Targets/#amazon-sqs"},{"title":"Container","text":"<p>A single-container CloudEvents receiver which scales out automatically according to the number of concurrent requests, and scales down to zero when it doesn't receive any request for a certain amount of time.</p> <pre><code>target container \"my_app\" {\n  image = \"registry.example.com/myapp:v1\"\n  public = false // optional\n\n  // optional\n  env_var \"ENV_VAR_LITERAL\" {\n    value = \"some value\"\n  }\n  env_var \"ENV_VAR_FROM_SECRET\" {\n    value = secret_ref(\"secret-name\", \"secret-key\")\n  }\n}\n</code></pre> <p>This alternative, more compact syntax can be used for declaring environment variables, as long as all values have the same type (either literal string OR secret reference):</p> <pre><code>  env_vars = {\n    ENV_VAR_1: \"some value\"\n    ENV_VAR_2: \"another value\"\n  }\n</code></pre>","location":"til/Targets/#container"},{"title":"Datadog","text":"<pre><code>target datadog \"my_metrics\" {\n  metric_prefix = \"myapp\" // optional\n\n  auth = secret_name(\"my-datadog-credentials\")\n\n  //reply_to = &lt;component&gt;.&lt;identifier&gt;\n}\n</code></pre> <p>Secret class: datadog</p>","location":"til/Targets/#datadog"},{"title":"Event Display","text":"<p>A CloudEvent receiver that logs received events to standard output. The service scales down to zero when it doesn't receive any request for a certain amount of time.</p> <pre><code>target event_display \"debug\" { }\n</code></pre>","location":"til/Targets/#event-display"},{"title":"Function","text":"<pre><code>target function \"my_function\" {\n  runtime = \"python\"\n  entrypoint = \"main\" // optional\n\n  code = file(\"funcs/handler.py\")\n\n  // optional, applies to functions that send CloudEvent responses\n  ce_context {\n    type = \"my.target.v1.event\"\n\n    source = \"my_function\" // optional\n    subject = \"some_subject\" // optional\n  }\n\n  public = false // optional\n\n  //reply_to = &lt;component&gt;.&lt;identifier&gt;\n}\n</code></pre>","location":"til/Targets/#function"},{"title":"Google Cloud Firestore","text":"<pre><code>target gcloud_firestore \"my_bucket\" {\n  default_collection = \"users\"\n  project_id = \"my-project\"\n\n  service_account = secret_name(\"my-gcloud-service-account\")\n\n  //reply_to = &lt;component&gt;.&lt;identifier&gt;\n}\n</code></pre> <p>Secret class: gcloud_service_account</p>","location":"til/Targets/#google-cloud-firestore"},{"title":"Google Cloud Storage","text":"<pre><code>target gcloud_storage \"my_bucket\" {\n  bucket_name = \"my-bucket\"\n\n  service_account = secret_name(\"my-gcloud-service-account\")\n\n  //reply_to = &lt;component&gt;.&lt;identifier&gt;\n}\n</code></pre> <p>Secret class: gcloud_service_account</p>","location":"til/Targets/#google-cloud-storage"},{"title":"Kafka","text":"<pre><code>target kafka \"my_topic\" {\n  topic = \"test1\"\n\n  bootstrap_servers = [\"server1:9092\", \"server2:9092\"]\n\n  auth = secret_name(\"kafka-security-settings\")\n\n  //reply_to = &lt;component&gt;.&lt;identifier&gt;\n}\n</code></pre> <p>Secret class: kafka</p>","location":"til/Targets/#kafka"},{"title":"Logz","text":"<pre><code>target logz \"my_logs\" {\n  logs_listener_url = \"listener.logz.io\"\n\n  auth = secret_name(\"my-logz-credentials\")\n\n  //reply_to = &lt;component&gt;.&lt;identifier&gt;\n}\n</code></pre> <p>Secret class: logz</p>","location":"til/Targets/#logz"},{"title":"Sendgrid","text":"<pre><code>target sendgrid \"email_notifications\" {\n  default_from_email = \"jane@example.com\" // optional\n  default_from_name = \"Jane\" // optional\n\n  default_to_email = \"woodford@example.com\" // optional\n  default_to_name = \"Woodford\" // optional\n\n  default_subject = \"Notification\" // optional\n\n  auth = secret_name(\"my-sendgrid-credentials\")\n\n  //reply_to = &lt;component&gt;.&lt;identifier&gt;\n}\n</code></pre> <p>Secret class: sendgrid</p>","location":"til/Targets/#sendgrid"},{"title":"Slack","text":"<pre><code>target slack \"my_channel\" {\n  auth = secret_name(\"my-slack-credentials\")\n\n  //reply_to = &lt;component&gt;.&lt;identifier&gt;\n}\n</code></pre> <p>Secret class: slack</p>","location":"til/Targets/#slack"},{"title":"Sockeye","text":"<p>A CloudEvent receiver that embeds a web UI which allows visualizing received events in real time. The service is exposed at a public URL via an ingress gateway, and scales down to zero when it doesn't receive any request for a certain amount of time.</p> <pre><code>target sockeye \"debug\" { }\n</code></pre>","location":"til/Targets/#sockeye"},{"title":"Splunk","text":"<pre><code>target splunk \"my_event_collector\" {\n  endpoint = \"https://prd-x-12345.splunkcloud.com\"\n  index = \"default\" // optional\n\n  skip_tls_verify = false // optional\n\n  auth = secret_name(\"my-splunk-credentials\")\n\n  //reply_to = &lt;component&gt;.&lt;identifier&gt;\n}\n</code></pre> <p>Secret class: splunk_hec</p>","location":"til/Targets/#splunk"},{"title":"Twilio","text":"<pre><code>target twilio \"sms_notifications\" {\n  default_phone_from = \"+10000000000\" // optional\n  default_phone_to = \"+10000000000\"   // optional\n\n  auth = secret_name(\"my-twilio-credentials\")\n\n  //reply_to = &lt;component&gt;.&lt;identifier&gt;\n}\n</code></pre> <p>Secret class: twilio</p>","location":"til/Targets/#twilio"},{"title":"Zendesk","text":"<pre><code>target zendesk \"customer_tickets\" {\n  subdomain = \"mycompany\"\n\n  email = \"woodford@example.com\"\n  api_auth = secret_name(\"my-zendesk-api-token\")\n\n  subject = \"Ticket from TriggerMesh\"\n\n  //reply_to = &lt;component&gt;.&lt;identifier&gt;\n}\n</code></pre> <p>Secret class: zendesk</p>","location":"til/Targets/#zendesk"},{"title":"Transformers","text":"","location":"til/Transformers/"},{"title":"Full list","text":"<ul> <li>Bumblebee</li> <li>Function</li> </ul>","location":"til/Transformers/#full-list"},{"title":"Bumblebee","text":"<pre><code>transformer bumblebee \"to_user_info\" {\n\n  context {\n    operation \"store\" {\n      path {\n        key = \"$ceSource\"\n        value = \"source\"\n      }\n      path {\n        key = \"$ceType\"\n        value = \"type\"\n      }\n    }\n    operation \"add\" {\n      path {\n        key = \"origsourcetype\"\n        value = \"$${ceSource}-$${ceType}\"\n      }\n      path {\n        key = \"type\"\n        value = \"com.example.user\"\n      }\n    }\n  }\n\n  data {\n    operation \"delete\" {\n      path {\n        key = \"\"\n      }\n    }\n    operation \"shift\" {\n      path {\n        key = \"user.first_name:name\"\n      }\n    }\n  }\n\n  //to = &lt;component&gt;.&lt;identifier&gt;\n}\n</code></pre>","location":"til/Transformers/#bumblebee"},{"title":"Function","text":"<pre><code>transformer function \"my_function\" {\n  runtime = \"python\"\n  entrypoint = \"main\" // optional\n\n  code = file(\"funcs/handler.py\")\n\n  ce_context {\n    type = \"my.transformation.v1.event\"\n\n    source = \"my_function\" // optional\n    subject = \"some_subject\" // optional\n  }\n\n  public = false // optional\n\n  //to = &lt;component&gt;.&lt;identifier&gt;\n}\n</code></pre>","location":"til/Transformers/#function"},{"title":"Configuration","text":"","location":"tm/configuration/"},{"title":"Configuration","text":"<p>On TriggerMesh:</p> <ol> <li>If you do not yet have access, Login to the TriggerMesh cloud at https://cloud.triggermesh.com</li> <li>Download your TriggerMesh configuration file by clicking on the <code>download</code> button in the upper right corner</li> </ol> <p></p> <ol> <li>Save the file as <code>$HOME/.tm/config.json</code> and you are ready to use the <code>tm</code> CLI</li> </ol> <p>On Your Own Knative Cluster:</p> <p>Assuming you have access to the Kubernetes API and have a working <code>kubectl</code> setup, <code>tm</code> should work out of the box.</p>","location":"tm/configuration/#configuration"},{"title":"Installation","text":"<p>The <code>tm</code> binary can be installed from pre-built binary releases or can be built directly from source.</p>","location":"tm/install/"},{"title":"From binary releases","text":"<p>Releases are available for 64-bit versions of Linux, macOS and Windows platforms.</p> <ol> <li>Download the desired version from the releases page.</li> <li>Move it to its desired destination (<code>mv tm-linux-amd64 /usr/local/bin/tm</code>)</li> <li>Make it executable <code>chmod +x /usr/local/bin/tm</code></li> </ol>","location":"tm/install/#from-binary-releases"},{"title":"From Homebrew (macOS and Linux)","text":"<pre><code>brew install tm\n</code></pre>","location":"tm/install/#from-homebrew-macos-and-linux"},{"title":"From source (Linux / macOS)","text":"<p>To build the <code>tm</code> binary from source you need the Go compiler toolchain.</p> <pre><code>go get github.com/triggermesh/tm\n</code></pre>","location":"tm/install/#from-source-linux-macos"},{"title":"Registry","text":"","location":"tm/registry/"},{"title":"Docker Registry","text":"<p>Docker images are used to run functions code in Knative services. This means that image registry is important part of service deployment scheme. Depending on type of service, Knative controller may either only pull or also push service image from and to registry. TriggerMesh CLI provides simple configuration interface to setup registry address and user access credentials.</p>","location":"tm/registry/#docker-registry"},{"title":"Service from Pre-Built Image","text":"<p>Most simple type of service deployment uses service based on pre-built Docker image available in public registry. This kind of service doesn't require any additional configuration and may be started with following command:</p> <pre><code>tm deploy service foo -f gcr.io/google-samples/hello-app:1.0 --wait\n</code></pre> <p>This case doesn't produce any images so no authentication is required.</p> <p>If pre-built image stored in private registry, you must specify access credentials by running following command before starting deployment:</p> <pre><code>tm set registry-auth foo-registry\n</code></pre> <p>You will be asked to enter registry address, username and password - they will saved to k8s secret and used to pull images deployed under you service account.</p> <p>Besides pulling, this secret may be used to push new images for service deployment based on function source code and build template. Name of one particular k8s secret should be passed to deployment command to make CLI work with private registry:</p> <pre><code>tm deploy service foo-private -f https://github.com/serverless/examples \\\n                              --build-template knative-node4-runtime \\\n                              --build-argument DIRECTORY=aws-node-serve-dynamic-html-via-http-endpoint \\\n                              --build-argument HANDLER=handler.landingPage \\\n                              --registry-secret foo-registry \\\n                              --wait\n</code></pre> <p>If user whose credentials are specified in <code>foo-registry</code> have \"write\" permissions, resulting service image will be pushed to URL composed as <code>registry/username/service_name</code></p> <p>&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD</p>","location":"tm/registry/#service-from-pre-built-image"},{"title":"GitLab CI Registry","text":"<p>=======</p>","location":"tm/registry/#gitlab-ci-registry"},{"title":"GitLab CI registry","text":"<p>chore: fix spelling mistakes</p>        <p>TriggerMesh CLI can be used as deployment step in GitLab CI pipeline, but considering tokens security policy, user must manually create CI deployment token as described here. Deployment token must have registry read permission and should be valid for as long as the service expected to be active. If token is created, <code>tm</code> deployment step must include following commands:</p> <p><pre><code>...\nscript:\n  - tm -n \"$KUBE_NAMESPACE\" set registry-auth gitlab-registry --registry \"$CI_REGISTRY\" --username \"$CI_REGISTRY_USER\" --password \"$CI_JOB_TOKEN\" --push\n  - tm -n \"$KUBE_NAMESPACE\" set registry-auth gitlab-registry --registry \"$CI_REGISTRY\" --username \"$CI_DEPLOY_USER\" --password \"$CI_DEPLOY_PASSWORD\" --pull\n...\n</code></pre> After this, you may pass <code>--registry-secret gitlab-registry</code> parameter to <code>tm deploy</code> command (or in serverless.yml) so that Knative could authenticate against GitLab registry.  GitLab registry doesn't provide permanent read-write token that can be used in CI, but it has job-specific <code>CI_JOB_TOKEN</code> with \"write\" permission which is valid only while CI job running and <code>CI_DEPLOY_PASSWORD</code> with read permission which we created before. Considering this, we can see that CLI <code>set registry-auth</code> command supports <code>--push</code> and <code>--pull</code> flags that indicates which secret must be used to push image and which for \"pull\" operations only. Resulting images will be stored under <code>registry.gitlab.com/username/project/function_name</code> path</p>","location":"tm/registry/#gitlab-ci-registry_1"},{"title":"Unauthenticated Registry","text":"<p>Besides hosted registries, TriggerMesh CLI may work with unauthenticated registries which does not require setting access credentials. For such cases, you may simply add <code>--registry-host</code> argument to deployment command with registry domain name parameter and resulting image will be pushed to <code>registry-host/namespace/service_name</code> URL</p>","location":"tm/registry/#unauthenticated-registry"},{"title":"Serverless Manifest","text":"","location":"tm/serverless/"},{"title":"Generate the Scaffolding","text":"<p>To ease user on-boarding <code>tm</code> has a currently experimental feature to generate a scaffolding. To generate the scaffolding for a simple Python function do:</p> <pre><code>tm generate python\n</code></pre> <p>Currently it creates a directory named <code>python</code>, this will soon be customizable. Check the scaffolding:</p> <pre><code>tree python\npython\n\u251c\u2500\u2500 handler.py\n\u2514\u2500\u2500 serverless.yaml\n</code></pre>","location":"tm/serverless/#generate-the-scaffolding"},{"title":"Deploy the Function","text":"<p>To deploy the function you use a single command:</p> <pre><code>tm deploy -f python --wait\n</code></pre> <p>The <code>--wait</code> allows you to wait till all resources enter ready state. Shortly thereafter you will be presented with a URL for your function (i.e a Knative service):</p> <pre><code>$ tm deploy -f python --wait\nUploading \"python\" to demo-service-python-function-mcsgp-pod-6dfb31\nWaiting for taskrun \"demo-service-python-function-mcsgp\" ready state\nCreating \"demo-service-python-function\" service\nWaiting for service \"demo-service-python-function\" ready state\nService demo-service-python-function URL: http://demo-service-python-function-sebgoa.k.triggermesh.io\n</code></pre> <p>You will be able to call it easily:</p> <pre><code>$ curl http://demo-service-python-function-sebgoa.k.triggermesh.io\n{\"message\": \"Hello, the current time is 07:51:46.853233\"}\n</code></pre>","location":"tm/serverless/#deploy-the-function"},{"title":"How Does This Work","text":"<p>While this seems straightforward there is a bit of magic being the scene. That's because the Python function being deployed does not have any invoker, it needs to be wrapped into a function runtime.</p> <p>At TriggerMesh we have developed the Knative Lambda Runtime (https://github.com/triggermesh/knative-lambda-runtime) which can deploy an AWS Lambda function to a Knative cluster. We discussed it at length on the AWS blog.</p> <p>With the scaffolding in place, the <code>serverless.yaml</code> manifest makes a reference to the KLR runtime:</p> <pre><code>service: demo-service\ndescription: Sample knative service\n\nprovider:\n  name: triggermesh\n  registry: knative.registry.svc.cluster.local\n\nfunctions:\n  python-function:\n    source: handler.py\n    runtime: https://raw.githubusercontent.com/triggermesh/runtime-build-tasks/master/aws-lambda/python37-runtime.yaml\n    buildargs:\n    - HANDLER=handler.endpoint\n    environment:\n      EVENT: API_GATEWAY\n</code></pre> <p>In this runtime you will see a <code>Task</code> object that comes from the Tekton project. Hence in one command <code>tm deploy</code> we create a Task and execute it to build a container image that injects the function into our KLR AWS compatible runtime. This allows us to take an existing lambda function and deploy it to Knative in a Serverless framework manner.</p> <p>Check the runtime URL to see how Tekton comes into play.</p>","location":"tm/serverless/#how-does-this-work"},{"title":"Tear Everything Down","text":"<p>Deleting everything is straightforward:</p> <pre><code>$ tm delete -f python\nDeleting demo-service-python-function\n</code></pre> <p>We hope you enjoyed it, if you have any feedback on the use of <code>tm</code> or Knative and Tekton don't hesitate to leave us an issue or contact us at info@triggermesh.com</p>","location":"tm/serverless/#tear-everything-down"},{"title":"Usage","text":"","location":"tm/usage/"},{"title":"Examples","text":"<p>Deploy service from Docker image <pre><code>tm deploy service foo -f gcr.io/google-samples/hello-app:1.0 --wait\n</code></pre></p> <p>If you have Dockerfile for your service, you can use Kaniko runtime to deploy it <pre><code>tm deploy service foobar \\\n    -f https://github.com/knative/docs \\\n    --runtime https://raw.githubusercontent.com/triggermesh/knative-lambda-runtime/master/kaniko/runtime.yaml \\\n    --build-argument DIRECTORY=docs/serving/samples/hello-world/helloworld-go \\\n    --wait\n</code></pre></p> <p>or deploy service straight from Go source using OpenFaaS runtime <pre><code>tm deploy service bar \\\n    -f https://github.com/golang/example \\\n    --runtime https://raw.githubusercontent.com/triggermesh/openfaas-runtime/master/go/openfaas-go-runtime.yaml \\\n    --build-argument DIRECTORY=hello \\\n    --wait\n</code></pre></p> <p>Moreover, for more complex deployments, tm CLI supports function definition parsing from YAML file and ability to combine multiple functions, runtimes and repositories</p> <pre><code>tm deploy -f https://github.com/tzununbekov/serverless\n</code></pre>","location":"tm/usage/#examples"},{"title":"AWS Lambda Compatible Functions","text":"<p>With the TriggerMesh CLI you can easily deploy AWS Lambda functions on Kubernetes:</p> <p>Prepare local source for Golang function</p> <pre><code>mkdir lambda\ncd lambda\ncat &gt; main.go &lt;&lt;EOF\npackage main\n\nimport (\n        \"fmt\"\n        \"context\"\n        \"github.com/aws/aws-lambda-go/lambda\"\n)\n\ntype MyEvent struct {\n        Name string\n}\n\nfunc HandleRequest(ctx context.Context, name MyEvent) (string, error) {\n        return fmt.Sprintf(\"Hello %s!\", name.Name ), nil\n}\n\nfunc main() {\n        lambda.Start(HandleRequest)\n}\nEOF\n</code></pre> <p>Deploy function using Knative Lambda Go runtime</p> <pre><code>tm deploy service go-lambda -f . --runtime https://raw.githubusercontent.com/triggermesh/knative-lambda-runtime/master/go/runtime.yaml --wait\n</code></pre> <p>Lambda function available via http events</p> <pre><code>curl http://go-lambda.default.dev.triggermesh.io --data '{\"Name\": \"Foo\"}'\n\"Hello Foo!\"\n</code></pre> <p>Here you can find more information about Knative lambda runtimes</p>","location":"tm/usage/#aws-lambda-compatible-functions"}]}